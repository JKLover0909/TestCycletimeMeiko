2025-06-05T04:09:44,324 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,324 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,328 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - A module that was compiled using NumPy 1.x cannot be run in
2025-06-05T04:09:44,328 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
2025-06-05T04:09:44,329 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - A module that was compiled using NumPy 1.x cannot be run in
2025-06-05T04:09:44,329 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - versions of NumPy, modules must be compiled with NumPy 2.0.
2025-06-05T04:09:44,329 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
2025-06-05T04:09:44,329 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - versions of NumPy, modules must be compiled with NumPy 2.0.
2025-06-05T04:09:44,329 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
2025-06-05T04:09:44,329 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,330 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
2025-06-05T04:09:44,330 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - If you are a user of the module, the easiest solution will be to
2025-06-05T04:09:44,330 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,330 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - If you are a user of the module, the easiest solution will be to
2025-06-05T04:09:44,330 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - downgrade to 'numpy<2' or try to upgrade the affected module.
2025-06-05T04:09:44,330 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - downgrade to 'numpy<2' or try to upgrade the affected module.
2025-06-05T04:09:44,331 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - We expect that some modules will need time to support NumPy 2.
2025-06-05T04:09:44,331 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - We expect that some modules will need time to support NumPy 2.
2025-06-05T04:09:44,331 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,331 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,331 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - Traceback (most recent call last):  File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 17, in <module>
2025-06-05T04:09:44,331 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -     from ts.model_loader import ModelLoaderFactory
2025-06-05T04:09:44,331 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - Traceback (most recent call last):  File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 17, in <module>
2025-06-05T04:09:44,332 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -     from ts.model_loader import ModelLoaderFactory
2025-06-05T04:09:44,332 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 14, in <module>
2025-06-05T04:09:44,332 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -     from ts.service import Service
2025-06-05T04:09:44,332 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 14, in <module>
2025-06-05T04:09:44,332 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 11, in <module>
2025-06-05T04:09:44,332 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -     from ts.protocol.otf_message_handler import create_predict_response
2025-06-05T04:09:44,332 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/protocol/otf_message_handler.py", line 14, in <module>
2025-06-05T04:09:44,332 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -     from ts.service import Service
2025-06-05T04:09:44,332 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -     import torch
2025-06-05T04:09:44,333 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
2025-06-05T04:09:44,333 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 11, in <module>
2025-06-05T04:09:44,333 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -     from .functional import *  # noqa: F403
2025-06-05T04:09:44,333 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
2025-06-05T04:09:44,333 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -     from ts.protocol.otf_message_handler import create_predict_response
2025-06-05T04:09:44,333 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -     import torch.nn.functional as F
2025-06-05T04:09:44,334 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/protocol/otf_message_handler.py", line 14, in <module>
2025-06-05T04:09:44,334 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -     import torch
2025-06-05T04:09:44,334 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
2025-06-05T04:09:44,334 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
2025-06-05T04:09:44,334 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -     from .modules import *  # noqa: F403
2025-06-05T04:09:44,334 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
2025-06-05T04:09:44,334 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -     from .functional import *  # noqa: F403
2025-06-05T04:09:44,335 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
2025-06-05T04:09:44,335 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -     from .transformer import TransformerEncoder, TransformerDecoder, \
2025-06-05T04:09:44,335 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -     import torch.nn.functional as F
2025-06-05T04:09:44,335 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
2025-06-05T04:09:44,335 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,335 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
2025-06-05T04:09:44,335 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -     from .modules import *  # noqa: F403
2025-06-05T04:09:44,336 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/torch/csrc/utils/tensor_numpy.cpp:84.)
2025-06-05T04:09:44,336 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
2025-06-05T04:09:44,336 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -     from .transformer import TransformerEncoder, TransformerDecoder, \
2025-06-05T04:09:44,336 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,336 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
2025-06-05T04:09:44,337 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,337 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/torch/csrc/utils/tensor_numpy.cpp:84.)
2025-06-05T04:09:44,337 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,385 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,386 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - A module that was compiled using NumPy 1.x cannot be run in
2025-06-05T04:09:44,386 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
2025-06-05T04:09:44,386 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - versions of NumPy, modules must be compiled with NumPy 2.0.
2025-06-05T04:09:44,386 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
2025-06-05T04:09:44,386 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,386 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - If you are a user of the module, the easiest solution will be to
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - downgrade to 'numpy<2' or try to upgrade the affected module.
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - We expect that some modules will need time to support NumPy 2.
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - Traceback (most recent call last):  File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 17, in <module>
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -     from ts.model_loader import ModelLoaderFactory
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 14, in <module>
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -     from ts.service import Service
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 11, in <module>
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -     from ts.protocol.otf_message_handler import create_predict_response
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/protocol/otf_message_handler.py", line 14, in <module>
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -     import torch
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
2025-06-05T04:09:44,387 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -     from .functional import *  # noqa: F403
2025-06-05T04:09:44,388 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
2025-06-05T04:09:44,388 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -     import torch.nn.functional as F
2025-06-05T04:09:44,388 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
2025-06-05T04:09:44,388 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -     from .modules import *  # noqa: F403
2025-06-05T04:09:44,388 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
2025-06-05T04:09:44,388 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -     from .transformer import TransformerEncoder, TransformerDecoder, \
2025-06-05T04:09:44,388 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
2025-06-05T04:09:44,389 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,389 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/torch/csrc/utils/tensor_numpy.cpp:84.)
2025-06-05T04:09:44,389 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,440 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,440 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - A module that was compiled using NumPy 1.x cannot be run in
2025-06-05T04:09:44,440 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
2025-06-05T04:09:44,440 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - versions of NumPy, modules must be compiled with NumPy 2.0.
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - If you are a user of the module, the easiest solution will be to
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - downgrade to 'numpy<2' or try to upgrade the affected module.
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - We expect that some modules will need time to support NumPy 2.
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - Traceback (most recent call last):  File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 17, in <module>
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -     from ts.model_loader import ModelLoaderFactory
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 14, in <module>
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -     from ts.service import Service
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 11, in <module>
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -     from ts.protocol.otf_message_handler import create_predict_response
2025-06-05T04:09:44,441 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/protocol/otf_message_handler.py", line 14, in <module>
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -     import torch
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -     from .functional import *  # noqa: F403
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -     import torch.nn.functional as F
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -     from .modules import *  # noqa: F403
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -     from .transformer import TransformerEncoder, TransformerDecoder, \
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/torch/csrc/utils/tensor_numpy.cpp:84.)
2025-06-05T04:09:44,442 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,573 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,573 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - A module that was compiled using NumPy 1.x cannot be run in
2025-06-05T04:09:44,573 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
2025-06-05T04:09:44,573 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - versions of NumPy, modules must be compiled with NumPy 2.0.
2025-06-05T04:09:44,574 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
2025-06-05T04:09:44,574 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,574 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - If you are a user of the module, the easiest solution will be to
2025-06-05T04:09:44,574 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - downgrade to 'numpy<2' or try to upgrade the affected module.
2025-06-05T04:09:44,574 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - We expect that some modules will need time to support NumPy 2.
2025-06-05T04:09:44,575 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,575 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - Traceback (most recent call last):  File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 17, in <module>
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -     from ts.model_loader import ModelLoaderFactory
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 14, in <module>
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -     from ts.service import Service
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 11, in <module>
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -     from ts.protocol.otf_message_handler import create_predict_response
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/protocol/otf_message_handler.py", line 14, in <module>
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -     import torch
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -     from .functional import *  # noqa: F403
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -     import torch.nn.functional as F
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -     from .modules import *  # noqa: F403
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -     from .transformer import TransformerEncoder, TransformerDecoder, \
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,576 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/torch/csrc/utils/tensor_numpy.cpp:84.)
2025-06-05T04:09:44,576 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - A module that was compiled using NumPy 1.x cannot be run in
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - versions of NumPy, modules must be compiled with NumPy 2.0.
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - If you are a user of the module, the easiest solution will be to
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - downgrade to 'numpy<2' or try to upgrade the affected module.
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - We expect that some modules will need time to support NumPy 2.
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - 
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - Traceback (most recent call last):  File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 17, in <module>
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -     from ts.model_loader import ModelLoaderFactory
2025-06-05T04:09:44,577 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 14, in <module>
2025-06-05T04:09:44,578 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -     from ts.service import Service
2025-06-05T04:09:44,578 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 11, in <module>
2025-06-05T04:09:44,578 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -     from ts.protocol.otf_message_handler import create_predict_response
2025-06-05T04:09:44,578 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/protocol/otf_message_handler.py", line 14, in <module>
2025-06-05T04:09:44,578 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -     import torch
2025-06-05T04:09:44,578 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/__init__.py", line 1477, in <module>
2025-06-05T04:09:44,578 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -     from .functional import *  # noqa: F403
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/functional.py", line 9, in <module>
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -     import torch.nn.functional as F
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -     from .modules import *  # noqa: F403
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -     from .transformer import TransformerEncoder, TransformerDecoder, \
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -     device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/torch/csrc/utils/tensor_numpy.cpp:84.)
2025-06-05T04:09:44,579 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
2025-06-05T04:09:44,699 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=38925
2025-06-05T04:09:44,699 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:09:44,701 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=38915
2025-06-05T04:09:44,702 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:09:44,703 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:09:44,703 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]38925
2025-06-05T04:09:44,703 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:09:44,703 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:09:44,705 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:09:44,706 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]38915
2025-06-05T04:09:44,706 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:09:44,706 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:09:44,711 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:09:44,711 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:09:44,728 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=38920
2025-06-05T04:09:44,729 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:09:44,729 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:09:44,729 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]38920
2025-06-05T04:09:44,729 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:09:44,729 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:09:44,730 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=38902
2025-06-05T04:09:44,730 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:09:44,731 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:09:44,733 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:09:44,733 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]38902
2025-06-05T04:09:44,733 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:09:44,734 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:09:44,738 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:09:44,751 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:09:44,751 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:09:44,751 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:09:44,752 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:09:44,781 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:09:44,781 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:09:44,781 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:09:44,782 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:09:44,781 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:09:44,782 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:09:44,782 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:09:44,782 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:09:44,845 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=38935
2025-06-05T04:09:44,846 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:09:44,850 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:09:44,850 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]38935
2025-06-05T04:09:44,850 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:09:44,850 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:09:44,850 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=38930
2025-06-05T04:09:44,850 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:09:44,851 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:09:44,854 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:09:44,854 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]38930
2025-06-05T04:09:44,854 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:09:44,854 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:09:44,857 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:09:44,868 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:09:44,873 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:09:44,884 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:09:44,884 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:09:44,889 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:09:44,889 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:09:44,899 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:09:44,899 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:09:44,899 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:09:44,899 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:09:44,899 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:09:44,899 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:09:44,899 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:09:44,900 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:09:44,915 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:09:44,915 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:09:44,915 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:09:44,915 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:09:44,915 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:09:44,915 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:09:44,915 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:09:44,915 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:09:44,915 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:09:44,915 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:09:44,915 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:09:44,915 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:09:44,916 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:09:44,916 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:09:44,916 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:09:44,916 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:09:44,916 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:09:44,916 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:09:44,916 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:09:44,916 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:09:44,916 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/0f4f119b775248f6af72bad0de494bd1/onnx_handler.py", line 11, in initialize
2025-06-05T04:09:44,916 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:09:44,916 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:09:44,916 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:09:44,916 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:09:44,916 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:09:44,916 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:09:44,916 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:09:44,916 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:09:44,916 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:09:44,916 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:09:44,916 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:09:44,916 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:09:44,917 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:09:44,917 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:09:44,917 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:09:44,917 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:09:44,917 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:09:44,917 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:09:44,917 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:09:44,917 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:09:44,917 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:09:44,917 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:09:44,917 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:09:44,917 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:09:44,917 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:09:44,917 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/96f63eab27bd4c968b17abe12d355c5d/onnx_handler.py", line 11, in initialize
2025-06-05T04:09:44,917 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:09:44,917 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:09:44,917 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/227b799c2f89462fbb022ef5ffa8e00b/onnx_handler.py", line 11, in initialize
2025-06-05T04:09:44,917 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/81883d3de4d4495db3a7abf44d5f6600/onnx_handler.py", line 11, in initialize
2025-06-05T04:09:44,917 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:09:44,917 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:09:44,917 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:09:44,917 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:09:44,918 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:09:44,918 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:09:44,944 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:09:44,944 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:09:44,952 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:09:44,952 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:09:44,956 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:09:44,956 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:09:44,956 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:09:44,956 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e73e927528004f819b824cd33084e334/onnx_handler.py", line 11, in initialize
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:09:44,957 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:09:44,964 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:09:44,964 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:09:44,964 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/3c9a8fa383ec4f04821a74be18f6a9eb/onnx_handler.py", line 11, in initialize
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:09:44,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:11,865 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=40347
2025-06-05T04:14:11,866 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:14:11,870 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:11,870 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]40347
2025-06-05T04:14:11,871 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:11,871 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:11,881 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:14:11,899 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=40352
2025-06-05T04:14:11,899 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:14:11,902 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:11,902 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]40352
2025-06-05T04:14:11,903 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:11,903 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:11,904 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=40343
2025-06-05T04:14:11,904 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:14:11,906 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:14:11,907 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:14:11,908 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:11,908 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]40343
2025-06-05T04:14:11,908 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:11,908 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:11,911 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:14:11,923 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:14:11,927 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:14:11,943 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:11,943 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:11,945 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:11,946 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:11,949 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:11,950 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:11,982 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=40371
2025-06-05T04:14:11,982 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:14:11,986 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:11,986 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]40371
2025-06-05T04:14:11,986 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:11,986 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:11,988 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:14:11,995 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=40357
2025-06-05T04:14:11,995 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:14:11,998 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:11,999 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]40357
2025-06-05T04:14:11,999 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:11,999 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:12,000 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:14:12,001 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:14:12,012 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:14:12,018 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:12,018 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:12,031 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:12,032 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:12,043 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:12,043 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:12,043 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:12,043 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:12,043 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:12,043 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:12,059 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:12,059 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:12,059 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:12,059 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:12,059 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:12,059 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:12,060 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:12,060 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:12,060 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:12,060 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:12,060 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:12,060 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:12,060 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:12,060 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:12,060 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:12,060 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:12,061 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:12,060 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:12,061 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:12,061 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:12,061 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:12,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:12,061 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:12,061 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:12,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:12,061 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:12,061 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:12,062 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:12,062 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:12,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:12,062 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:12,062 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:12,062 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:12,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:12,062 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:12,062 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:12,062 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:12,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:12,063 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:12,063 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:12,063 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:12,063 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:12,063 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:12,063 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:12,063 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:12,063 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:12,063 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:12,063 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:12,063 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:12,063 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:12,063 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:12,086 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:12,086 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:12,096 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:12,096 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:12,099 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:12,099 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:12,099 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:12,099 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:12,099 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:12,099 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:12,099 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:12,099 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:12,099 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:12,100 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:12,100 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:12,100 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:12,100 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:12,100 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:12,100 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:12,100 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:12,100 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:12,107 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:12,108 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:12,109 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:12,109 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:12,166 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=40430
2025-06-05T04:14:12,167 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:14:12,170 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:12,170 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]40430
2025-06-05T04:14:12,170 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:12,170 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:12,179 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:14:12,188 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:14:12,206 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:12,207 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:12,313 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:12,313 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:12,323 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:12,323 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:12,323 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:12,323 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:12,323 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:12,323 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:12,324 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:13,784 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=40602
2025-06-05T04:14:13,785 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:14:13,788 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:13,788 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]40602
2025-06-05T04:14:13,788 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:13,788 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:13,789 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:14:13,798 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=40601
2025-06-05T04:14:13,799 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=40603
2025-06-05T04:14:13,799 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:14:13,799 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:14:13,803 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:13,803 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]40601
2025-06-05T04:14:13,804 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:13,804 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:14:13,804 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:13,805 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:13,805 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]40603
2025-06-05T04:14:13,805 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:13,805 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:13,805 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:14:13,813 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:14:13,813 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=40613
2025-06-05T04:14:13,814 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:14:13,818 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=40610
2025-06-05T04:14:13,818 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:14:13,818 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:13,818 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]40613
2025-06-05T04:14:13,818 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:13,818 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:13,822 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:13,822 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]40610
2025-06-05T04:14:13,822 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:13,822 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:13,824 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:14:13,828 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:13,829 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:13,829 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:14:13,833 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:14:13,834 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:14:13,849 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:14:13,853 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:14:13,854 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:13,854 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:13,855 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:13,856 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:13,868 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:13,869 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:13,871 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:13,872 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:13,929 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:13,929 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:13,929 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:13,929 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:13,929 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:13,930 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:13,930 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:13,930 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:13,932 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:13,932 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:13,942 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:13,942 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:13,943 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:13,943 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:13,943 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:13,943 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:13,943 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:13,943 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:13,943 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:13,943 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:13,943 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:13,943 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:13,944 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:13,944 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:13,944 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:13,944 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:13,944 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:13,944 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:13,944 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:13,944 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:13,944 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:13,944 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:13,945 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:13,945 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:13,945 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:13,945 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:13,945 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:13,945 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:13,945 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:13,945 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:13,945 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:13,945 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:13,945 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:13,945 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:13,946 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:13,946 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:13,946 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:13,946 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:13,946 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:13,947 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:13,947 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:13,947 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:13,947 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:13,947 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:13,947 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:13,947 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:13,947 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:13,947 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:13,947 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:13,947 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:13,948 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:13,948 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:13,948 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:13,948 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:13,948 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:13,949 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:13,949 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:13,949 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:13,951 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:14,086 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=40627
2025-06-05T04:14:14,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:14:14,090 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:14,090 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]40627
2025-06-05T04:14:14,090 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:14,090 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:14,092 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:14:14,100 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:14:14,117 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:14,118 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:14,197 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:14,197 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:14,211 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:14,211 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:14,211 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:14,212 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:15,656 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=40833
2025-06-05T04:14:15,657 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:14:15,663 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:15,663 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]40833
2025-06-05T04:14:15,663 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:15,664 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:15,666 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:14:15,669 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=40826
2025-06-05T04:14:15,669 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:14:15,669 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=40827
2025-06-05T04:14:15,670 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:14:15,674 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:15,675 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]40826
2025-06-05T04:14:15,675 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:15,676 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:15,677 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:15,677 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]40827
2025-06-05T04:14:15,677 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:15,677 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:15,678 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:14:15,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=40832
2025-06-05T04:14:15,686 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=40838
2025-06-05T04:14:15,686 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:14:15,686 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:15,686 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:14:15,686 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]40832
2025-06-05T04:14:15,687 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:14:15,687 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:15,687 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:15,687 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:15,687 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:14:15,687 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]40838
2025-06-05T04:14:15,687 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:15,687 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:15,696 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:14:15,696 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:14:15,697 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:14:15,716 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:15,717 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:14:15,717 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:14:15,717 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:15,717 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:14:15,722 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:15,722 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:15,735 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:15,735 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:15,735 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:15,736 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:15,736 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:15,736 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:15,827 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:15,827 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:15,827 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:15,827 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:15,827 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:15,827 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:15,827 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:15,827 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:15,827 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:15,827 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:15,839 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:15,839 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:15,839 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:15,839 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:15,839 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:15,839 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:15,839 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:15,839 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:15,839 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:15,839 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:15,840 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:15,840 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:15,840 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:15,840 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:15,840 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:15,840 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:15,840 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:15,840 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:15,840 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:15,840 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:15,840 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:15,840 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:15,840 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:15,840 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:15,840 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:15,840 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:15,840 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:15,840 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:15,841 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:15,841 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:15,841 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:15,841 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:15,841 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:15,841 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:15,841 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:15,841 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:15,841 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:15,841 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:15,841 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:15,841 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:15,841 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:15,841 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:15,841 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:15,841 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:15,842 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:15,842 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:15,842 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:15,842 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:15,842 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:15,842 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:15,842 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:15,842 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:15,842 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:15,842 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:15,843 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:15,844 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:15,844 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:15,845 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:15,971 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=40841
2025-06-05T04:14:15,971 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:14:15,974 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:15,974 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]40841
2025-06-05T04:14:15,974 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:15,974 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:15,975 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:14:15,986 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:14:16,000 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:16,001 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:16,064 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:16,064 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:16,075 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:18,526 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=41037
2025-06-05T04:14:18,526 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:14:18,532 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:18,532 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]41037
2025-06-05T04:14:18,532 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:18,532 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:18,537 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:14:18,562 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:14:18,563 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=41040
2025-06-05T04:14:18,563 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:14:18,569 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:18,570 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]41040
2025-06-05T04:14:18,570 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:18,570 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:18,571 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:14:18,587 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:18,588 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:18,592 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:14:18,604 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=41038
2025-06-05T04:14:18,604 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:14:18,608 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:18,608 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]41038
2025-06-05T04:14:18,608 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:18,608 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:18,609 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:14:18,615 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:18,616 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:18,618 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=41036
2025-06-05T04:14:18,618 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:14:18,624 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:18,624 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=41041
2025-06-05T04:14:18,624 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]41036
2025-06-05T04:14:18,624 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:14:18,624 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:18,624 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:18,625 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:14:18,626 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:18,626 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]41041
2025-06-05T04:14:18,626 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:18,626 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:18,627 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:14:18,641 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:14:18,649 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:14:18,653 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:14:18,653 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:18,653 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:18,665 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:18,665 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:18,679 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:18,679 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:18,709 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:18,709 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:18,709 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:18,709 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:18,723 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:18,724 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:18,724 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:18,724 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:18,724 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:18,725 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:18,727 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:18,727 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:18,739 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:18,739 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:18,740 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:18,749 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:18,749 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:18,751 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:18,752 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:18,760 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:18,760 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:18,761 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:18,762 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:18,763 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:18,877 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=41051
2025-06-05T04:14:18,877 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:14:18,880 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:18,881 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]41051
2025-06-05T04:14:18,881 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:18,881 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:18,881 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:14:18,886 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:14:18,902 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:18,902 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:18,965 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:18,965 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:18,976 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:18,976 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:18,977 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:33,742 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=41264
2025-06-05T04:14:33,743 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:14:33,750 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:33,750 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]41264
2025-06-05T04:14:33,750 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:33,751 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:33,751 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:14:33,768 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:14:33,771 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=41259
2025-06-05T04:14:33,772 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:14:33,775 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:33,776 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]41259
2025-06-05T04:14:33,776 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:33,776 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:33,779 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:14:33,787 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:33,787 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:33,798 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:14:33,804 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=41258
2025-06-05T04:14:33,805 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:14:33,808 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=41270
2025-06-05T04:14:33,809 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:14:33,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=41267
2025-06-05T04:14:33,812 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:33,812 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:14:33,812 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]41258
2025-06-05T04:14:33,812 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:33,812 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:33,812 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:33,812 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]41270
2025-06-05T04:14:33,812 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:33,813 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:33,813 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:14:33,814 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:14:33,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:33,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]41267
2025-06-05T04:14:33,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:33,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:33,816 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:33,816 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:33,821 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:14:33,829 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:14:33,830 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:14:33,833 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:14:33,847 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:33,848 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:33,848 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:33,848 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:33,851 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:33,851 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:33,897 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:33,897 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:33,897 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:33,897 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:33,910 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:33,910 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:33,911 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:33,911 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:33,911 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:33,911 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:33,911 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:33,914 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:33,914 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:33,914 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:33,914 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:33,914 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:33,915 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:33,926 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:33,926 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:33,926 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:33,926 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:33,926 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:33,926 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:33,927 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:33,927 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:33,927 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:33,927 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:33,927 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:33,927 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:33,927 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:33,927 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:33,927 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:33,927 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:33,927 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:33,928 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:33,928 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:22,632 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:22,632 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:22,633 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:22,633 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:22,633 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:22,633 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:22,647 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:22,647 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:22,647 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:22,647 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:22,777 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=41273
2025-06-05T04:14:22,777 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:14:22,781 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:22,781 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]41273
2025-06-05T04:14:22,781 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:22,781 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:22,782 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:14:22,787 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:14:22,801 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:22,802 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:22,862 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:22,862 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:22,874 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:28,367 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=41500
2025-06-05T04:14:28,367 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:14:28,371 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:28,371 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]41500
2025-06-05T04:14:28,371 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:28,371 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:28,372 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:14:28,382 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=41499
2025-06-05T04:14:28,382 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:14:28,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:14:28,386 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:28,386 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]41499
2025-06-05T04:14:28,386 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:28,386 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:28,391 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:14:28,392 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=41506
2025-06-05T04:14:28,392 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:14:28,397 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:28,397 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]41506
2025-06-05T04:14:28,397 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:28,397 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:28,400 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:14:28,402 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:14:28,409 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:28,409 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:28,411 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:14:28,420 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:28,420 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:28,428 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:28,428 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:28,469 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=41505
2025-06-05T04:14:28,469 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:14:28,473 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:28,473 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]41505
2025-06-05T04:14:28,474 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:28,474 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:28,476 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:14:28,485 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=41507
2025-06-05T04:14:28,485 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:14:28,488 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:14:28,489 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:28,490 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]41507
2025-06-05T04:14:28,490 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:28,490 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:28,491 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:14:28,498 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:28,498 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:28,499 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:28,499 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:28,499 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:28,499 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:28,502 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:14:28,511 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:28,511 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:28,512 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:28,512 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:28,512 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:28,512 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:28,512 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:28,512 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:28,512 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:28,512 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:28,512 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:28,512 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:28,512 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:28,512 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:28,512 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:28,512 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:28,512 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:28,513 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:28,513 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:28,513 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:28,513 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:28,513 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:28,513 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:28,513 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:28,513 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:28,513 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:28,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:28,520 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:28,520 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:28,584 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:28,584 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:28,584 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:28,584 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:28,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:28,595 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:28,596 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:28,596 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:28,659 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=41515
2025-06-05T04:14:28,659 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:14:28,663 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:28,663 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]41515
2025-06-05T04:14:28,663 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:28,663 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:28,664 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:14:28,669 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:14:28,683 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:28,683 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:28,747 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:28,747 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:28,758 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:37,241 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=41754
2025-06-05T04:14:37,241 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:14:37,244 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:37,244 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]41754
2025-06-05T04:14:37,244 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:37,244 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:37,245 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=41753
2025-06-05T04:14:37,245 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:14:37,246 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:14:37,249 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:37,249 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]41753
2025-06-05T04:14:37,249 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:37,249 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:37,253 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:14:37,260 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:14:37,267 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:14:37,280 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:37,280 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:37,286 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:37,286 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:37,286 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=41752
2025-06-05T04:14:37,287 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:14:37,294 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:37,294 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]41752
2025-06-05T04:14:37,294 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:37,294 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:37,295 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:14:37,315 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:14:37,335 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:37,335 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:37,364 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=41761
2025-06-05T04:14:37,364 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:14:37,368 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:37,368 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]41761
2025-06-05T04:14:37,368 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:37,368 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:37,369 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:14:37,375 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:37,375 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:37,375 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:37,375 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:37,387 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:14:37,391 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:37,391 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:37,392 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:37,392 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:37,392 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:37,392 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:37,392 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:37,392 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:37,392 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:37,398 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:37,398 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:37,406 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:37,407 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:37,410 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:37,410 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:37,410 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:37,410 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:37,410 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:37,410 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:37,410 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:37,410 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:37,410 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:48,705 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:48,705 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:48,705 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:48,705 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:48,705 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:48,705 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:48,705 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:48,705 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:48,709 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=41762
2025-06-05T04:14:48,709 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:14:48,713 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:48,713 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]41762
2025-06-05T04:14:48,713 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:48,713 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:48,714 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:14:48,730 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:14:48,746 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:48,746 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:48,792 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=41767
2025-06-05T04:14:48,792 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:14:48,796 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:48,796 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]41767
2025-06-05T04:14:48,796 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:48,796 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:48,797 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:14:48,797 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:14:48,805 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:48,805 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:48,805 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:48,805 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:48,811 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:48,811 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:48,816 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:48,816 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:48,890 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:48,891 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:48,901 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:48,902 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:51,174 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=42020
2025-06-05T04:14:51,175 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:14:51,178 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:51,178 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]42020
2025-06-05T04:14:51,179 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:51,179 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:51,179 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:14:51,180 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:14:51,196 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:51,196 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:51,214 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=42014
2025-06-05T04:14:51,214 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:14:51,217 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:51,218 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]42014
2025-06-05T04:14:51,218 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:51,218 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:51,219 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:14:51,220 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:14:51,227 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=42015
2025-06-05T04:14:51,227 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:14:51,231 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:51,231 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]42015
2025-06-05T04:14:51,231 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:51,231 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:51,232 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:14:51,233 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:14:51,236 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:51,236 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:51,248 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:51,249 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:51,308 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:51,308 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:51,308 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:51,308 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:51,308 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:51,308 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:51,321 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:51,321 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:51,321 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:51,321 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:51,321 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:51,321 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:51,321 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:51,321 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:51,321 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:51,321 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:51,321 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:51,321 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:51,321 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:51,322 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:51,322 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:51,322 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:51,322 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:51,322 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:51,322 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:51,322 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:51,322 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:51,322 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:51,322 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:51,322 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:51,322 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:51,322 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:51,322 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:51,323 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:51,323 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:51,323 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:51,323 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:51,323 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:51,323 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:51,323 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:51,323 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:51,323 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:51,323 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:51,323 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:51,324 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:51,324 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:51,324 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:51,340 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=42023
2025-06-05T04:14:51,340 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:14:51,344 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:51,344 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]42023
2025-06-05T04:14:51,344 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:51,344 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:51,345 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:14:51,345 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:14:51,353 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=42024
2025-06-05T04:14:51,353 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:14:51,357 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:51,357 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]42024
2025-06-05T04:14:51,357 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:51,357 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:51,358 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:14:51,358 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:14:51,360 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:51,360 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:51,373 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:51,373 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:51,439 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=42029
2025-06-05T04:14:51,439 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:14:51,442 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:14:51,443 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]42029
2025-06-05T04:14:51,443 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:14:51,443 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:14:51,443 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:51,443 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:51,443 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:14:51,443 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:51,443 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:51,444 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:14:51,454 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:51,454 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:51,454 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:51,454 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:51,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:51,455 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:51,455 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:51,455 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:51,455 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:51,455 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:14:51,460 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:14:51,460 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:14:51,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:14:51,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:14:51,561 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:13,148 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=42302
2025-06-05T04:15:13,148 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:15:13,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=42303
2025-06-05T04:15:13,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:15:13,151 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:13,151 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]42302
2025-06-05T04:15:13,151 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:13,152 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:13,153 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:15:13,154 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:15:13,154 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:13,154 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]42303
2025-06-05T04:15:13,154 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:13,154 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:13,155 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:15:13,155 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:15:13,170 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:13,170 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:13,172 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:13,172 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:13,174 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=42305
2025-06-05T04:15:13,174 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:15:13,178 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:13,178 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]42305
2025-06-05T04:15:13,178 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:13,178 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:13,179 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:15:13,180 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:15:13,200 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:13,200 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:13,261 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:13,261 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:13,261 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:13,261 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:13,261 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:13,261 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:13,274 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:13,274 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:13,275 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:13,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:13,277 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:13,277 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:13,277 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:13,318 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=42314
2025-06-05T04:15:13,318 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:15:13,322 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:13,322 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]42314
2025-06-05T04:15:13,322 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:13,322 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:13,323 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:15:13,324 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:15:13,327 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=42311
2025-06-05T04:15:13,327 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:15:13,331 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:13,331 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]42311
2025-06-05T04:15:13,331 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:13,331 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:13,332 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:15:13,333 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:15:13,340 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:13,340 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:13,348 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:13,348 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:13,415 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:13,415 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:13,415 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:13,415 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:13,420 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=42317
2025-06-05T04:15:13,420 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:15:13,424 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:13,424 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]42317
2025-06-05T04:15:13,424 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:13,424 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:13,425 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:13,425 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:13,426 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:13,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:13,426 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:13,427 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:13,427 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:13,427 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:13,427 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:13,427 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:13,427 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:13,442 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:13,443 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:13,539 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:13,539 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:13,550 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:48,057 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=42641
2025-06-05T04:15:48,057 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:15:48,064 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:48,064 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]42641
2025-06-05T04:15:48,064 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:48,065 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:48,066 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:15:48,066 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:15:48,093 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:48,094 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:48,112 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=42637
2025-06-05T04:15:48,112 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:15:48,118 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:48,118 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]42637
2025-06-05T04:15:48,118 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:48,118 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:48,120 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:15:48,120 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:15:48,136 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:48,136 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:48,148 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=42636
2025-06-05T04:15:48,148 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:15:48,155 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:48,155 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]42636
2025-06-05T04:15:48,155 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:48,155 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:48,155 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:15:48,156 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:15:48,174 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:48,174 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:48,210 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:48,210 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:48,211 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:48,211 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:48,223 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:48,223 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:48,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:48,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:48,225 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:48,225 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:48,225 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:48,235 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:48,235 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:48,244 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=42646
2025-06-05T04:15:48,244 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:48,246 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:48,247 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:48,247 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:48,250 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:48,250 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]42646
2025-06-05T04:15:48,250 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:48,250 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:48,251 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:15:48,251 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:15:48,266 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:48,266 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:48,284 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=42645
2025-06-05T04:15:48,284 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:15:48,287 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:48,287 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]42645
2025-06-05T04:15:48,287 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:48,287 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:48,288 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:15:48,288 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:15:48,303 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:48,303 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:48,340 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:48,340 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:48,345 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:48,345 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:48,350 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:48,350 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:48,350 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:48,351 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:48,356 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:48,356 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:48,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:48,358 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:15:48,439 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=42656
2025-06-05T04:15:48,439 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:15:48,442 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:15:48,442 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]42656
2025-06-05T04:15:48,442 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:15:48,442 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:15:48,443 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:15:48,443 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:15:48,457 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:15:48,457 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:15:48,520 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:15:48,520 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:15:48,531 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:16:44,017 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=43090
2025-06-05T04:16:44,017 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:16:44,018 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=43095
2025-06-05T04:16:44,018 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:16:44,024 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:16:44,024 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:16:44,024 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]43090
2025-06-05T04:16:44,024 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:16:44,024 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]43095
2025-06-05T04:16:44,025 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:16:44,025 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:16:44,025 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:16:44,025 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:16:44,026 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:16:44,026 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:16:44,026 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:16:44,047 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=43089
2025-06-05T04:16:44,048 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:16:44,047 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:16:44,048 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:16:44,051 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:16:44,051 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:16:44,054 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:16:44,054 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]43089
2025-06-05T04:16:44,054 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:16:44,055 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:16:44,055 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:16:44,056 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:16:44,074 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:16:44,074 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:16:44,135 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:16:44,135 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:16:44,135 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:16:44,135 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:16:44,135 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:16:44,135 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:16:44,148 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:16:44,148 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:16:44,148 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:16:44,148 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:16:44,148 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:16:44,148 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:16:44,149 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:16:44,149 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/c30eafbf06e94e9c8dbd82b4e06f003b/onnx_handler.py", line 11, in initialize
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:16:44,149 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:16:44,149 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:16:44,149 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:16:44,149 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:16:44,149 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:16:44,149 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:16:44,149 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:16:44,149 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:16:44,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:16:44,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:16:44,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:16:44,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:16:44,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:16:44,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:16:44,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/d9cd4fdee8124e4cb80b1ac3b1e818f3/onnx_handler.py", line 11, in initialize
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:16:44,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:16:44,150 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/f15efda26d74457088ad0e93ced94330/onnx_handler.py", line 11, in initialize
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:16:44,150 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:16:44,180 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=43098
2025-06-05T04:16:44,181 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:16:44,185 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:16:44,185 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]43098
2025-06-05T04:16:44,185 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:16:44,185 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:16:44,186 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:16:44,186 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:16:44,192 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=43101
2025-06-05T04:16:44,192 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:16:44,196 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:16:44,196 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]43101
2025-06-05T04:16:44,197 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:16:44,197 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:16:44,198 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:16:44,198 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:16:44,206 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:16:44,206 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:16:44,216 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:16:44,216 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:16:44,282 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:16:44,282 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:16:44,282 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:16:44,282 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/9750190e0f7c4b7c9f34ae1bec004dc2/onnx_handler.py", line 11, in initialize
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:16:44,294 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:16:44,294 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:16:44,295 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:16:44,295 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:16:44,295 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:16:44,295 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/617fd611ef674ece9e8e957d5497fb49/onnx_handler.py", line 11, in initialize
2025-06-05T04:16:44,295 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:16:44,295 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:16:44,399 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=43158
2025-06-05T04:16:44,400 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:16:44,404 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:16:44,404 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]43158
2025-06-05T04:16:44,404 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:16:44,404 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:16:44,404 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:16:44,405 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:16:44,423 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:16:44,423 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:16:44,489 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:16:44,489 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:16:44,501 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/1899e7f3554441df9f0581f2c6459d99/onnx_handler.py", line 11, in initialize
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(ctx.model_uri, providers=providers)
2025-06-05T04:16:44,502 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - AttributeError: 'Context' object has no attribute 'model_uri'
2025-06-05T04:21:41,900 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=47770
2025-06-05T04:21:41,901 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:21:41,908 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:41,909 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]47770
2025-06-05T04:21:41,909 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:41,912 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:41,918 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:21:41,952 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:21:41,964 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:41,965 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:41,980 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=47774
2025-06-05T04:21:41,981 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:21:41,984 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:41,984 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]47774
2025-06-05T04:21:41,984 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:41,984 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:41,986 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:21:42,002 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:21:42,024 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:42,024 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:42,053 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:42,053 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:42,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=47779
2025-06-05T04:21:42,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:21:42,058 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:42,058 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]47779
2025-06-05T04:21:42,059 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:42,059 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:42,061 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:21:42,068 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:42,068 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:42,076 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:21:42,080 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=47784
2025-06-05T04:21:42,081 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:21:42,084 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:42,084 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:42,084 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:42,084 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:42,084 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:42,084 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:42,084 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:42,084 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:42,084 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:42,085 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:42,085 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:42,085 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:42,085 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:42,085 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:42,085 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:42,085 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:42,086 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:42,086 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:42,086 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:21:42,087 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:42,087 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:42,088 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:42,088 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]47784
2025-06-05T04:21:42,088 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:42,088 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:42,090 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:21:42,096 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:42,098 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:42,103 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:42,103 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:42,104 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:21:42,106 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:42,107 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:42,107 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:42,107 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:42,107 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:42,107 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:42,107 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:42,107 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:42,107 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:42,107 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:42,108 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:42,108 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:42,108 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:42,108 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:42,108 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:42,109 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:42,109 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:42,109 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:42,110 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:21:42,121 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:42,122 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:42,181 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:42,181 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:42,182 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:42,182 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:42,192 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:42,192 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:42,195 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:42,196 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:21:42,198 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:42,198 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:42,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:42,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:42,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:42,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:42,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:42,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:42,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:42,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:42,201 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:42,201 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:42,201 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:42,201 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:42,201 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:42,201 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:42,201 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:42,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:42,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:42,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:42,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:21:42,245 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=47816
2025-06-05T04:21:42,246 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:21:42,250 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:42,250 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]47816
2025-06-05T04:21:42,250 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:42,250 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:42,251 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:21:42,257 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:21:42,270 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:42,271 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:42,280 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=47854
2025-06-05T04:21:42,281 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:21:42,285 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:42,285 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]47854
2025-06-05T04:21:42,285 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:42,285 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:42,287 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:21:42,292 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:21:42,306 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:42,306 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:42,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:42,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:42,348 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:42,348 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:42,358 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:42,358 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:42,359 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:42,359 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:42,361 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:42,361 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:42,361 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:42,362 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:42,362 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:42,362 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:42,362 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:42,362 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:42,362 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:42,362 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:42,362 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:42,362 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:42,363 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:42,363 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:42,363 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:42,363 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:42,363 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:42,363 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:42,363 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:21:43,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=48101
2025-06-05T04:21:43,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:21:43,806 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:43,806 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]48101
2025-06-05T04:21:43,809 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:43,810 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:43,812 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:21:43,826 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:21:43,846 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:43,847 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:43,907 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=48098
2025-06-05T04:21:43,908 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:21:43,912 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:43,912 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]48098
2025-06-05T04:21:43,912 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:43,912 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:43,913 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:21:43,926 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=48107
2025-06-05T04:21:43,926 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:21:43,929 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:43,929 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:43,929 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:43,929 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]48107
2025-06-05T04:21:43,930 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:43,930 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:43,931 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:21:43,932 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:21:43,948 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:43,948 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:43,948 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:43,950 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:43,951 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:43,951 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:43,951 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:43,951 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:43,951 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:43,951 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:43,951 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:21:43,951 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:43,951 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:43,964 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:43,964 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:43,969 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=48104
2025-06-05T04:21:43,969 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:21:43,973 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:43,974 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]48104
2025-06-05T04:21:43,974 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:43,974 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:43,975 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:21:43,988 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:21:44,002 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:44,002 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:44,039 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:44,039 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:44,039 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:44,039 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:44,050 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:44,050 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:44,050 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:44,050 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:44,053 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:44,053 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:44,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:44,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:44,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:44,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:44,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:44,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:44,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:44,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:44,054 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:44,055 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:44,055 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:44,056 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:44,056 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:44,056 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:44,056 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:44,056 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:44,056 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:44,056 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:44,056 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:21:44,065 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:44,065 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:44,068 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:21:44,149 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=48138
2025-06-05T04:21:44,149 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:21:44,153 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:44,153 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]48138
2025-06-05T04:21:44,153 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:44,153 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:44,153 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=48137
2025-06-05T04:21:44,153 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:21:44,154 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:21:44,159 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:44,159 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]48137
2025-06-05T04:21:44,159 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:44,159 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:44,160 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:21:44,164 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:21:44,167 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:21:44,180 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:44,180 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:44,180 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:44,180 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:44,240 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:44,240 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:44,240 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:44,240 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:44,250 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:44,250 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:44,250 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:44,251 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:44,253 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:44,253 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:44,253 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:44,253 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:44,253 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:44,254 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:44,254 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:44,254 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:44,254 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:44,254 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:44,254 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:44,255 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:44,255 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:44,255 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:44,255 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:21:44,255 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:44,255 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:44,255 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:44,255 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:44,255 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:21:45,744 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=48387
2025-06-05T04:21:45,744 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:21:45,751 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:45,751 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]48387
2025-06-05T04:21:45,751 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:45,752 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:45,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:21:45,764 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:21:45,777 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=48384
2025-06-05T04:21:45,777 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:45,777 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:21:45,777 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:45,786 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:45,786 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]48384
2025-06-05T04:21:45,787 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:45,787 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:45,788 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:21:45,794 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=48393
2025-06-05T04:21:45,795 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:21:45,801 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:21:45,803 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:45,804 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]48393
2025-06-05T04:21:45,804 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:45,804 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:45,806 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:21:45,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:21:45,825 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:45,826 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:45,842 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=48388
2025-06-05T04:21:45,843 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:21:45,848 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:45,848 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]48388
2025-06-05T04:21:45,848 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:45,848 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:45,850 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:21:45,850 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:45,850 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:45,865 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:21:45,880 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:45,881 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:45,890 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:45,890 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:45,890 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:45,891 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:45,903 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:45,903 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:45,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:45,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:45,908 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:45,908 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:45,909 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:45,910 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:45,910 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:45,910 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:45,910 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:45,910 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:45,910 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:45,910 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:45,910 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:45,910 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:45,911 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:45,911 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:45,911 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:45,911 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:21:45,922 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:45,923 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:45,927 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:45,927 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:45,927 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:45,927 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:45,928 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:21:45,933 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:45,933 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:45,944 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:45,944 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:45,947 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:21:46,024 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=48424
2025-06-05T04:21:46,024 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:21:46,028 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:46,028 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]48424
2025-06-05T04:21:46,028 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:46,029 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:46,029 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:21:46,039 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:21:46,053 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:46,053 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:46,085 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=48423
2025-06-05T04:21:46,086 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:21:46,091 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:46,091 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]48423
2025-06-05T04:21:46,091 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:46,091 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:46,092 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:21:46,101 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:21:46,116 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:46,116 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:46,134 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:46,135 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:46,145 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:46,145 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:46,148 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:21:46,163 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:46,163 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:46,174 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:46,174 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:46,176 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:21:48,692 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=48687
2025-06-05T04:21:48,692 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:21:48,700 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:48,700 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]48687
2025-06-05T04:21:48,701 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:48,701 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:48,702 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:21:48,713 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=48686
2025-06-05T04:21:48,714 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:21:48,721 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:48,721 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]48686
2025-06-05T04:21:48,722 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:48,722 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:48,722 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:21:48,723 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:21:48,742 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:21:48,745 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:48,746 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:48,752 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=48692
2025-06-05T04:21:48,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:21:48,758 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:48,758 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]48692
2025-06-05T04:21:48,758 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:48,758 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:48,759 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:48,759 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:48,759 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:21:48,771 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:21:48,786 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:48,786 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:48,799 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=48695
2025-06-05T04:21:48,800 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:21:48,805 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:48,805 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]48695
2025-06-05T04:21:48,805 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:48,805 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:48,807 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:21:48,817 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:21:48,834 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:48,834 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:48,840 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:48,840 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:48,840 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:48,840 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:48,845 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:48,845 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:48,852 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:48,853 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:48,853 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:48,853 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:48,857 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:48,857 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:48,857 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:48,857 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:48,857 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:48,857 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:48,857 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:48,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:48,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:48,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:48,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:48,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:48,858 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:48,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:48,858 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:48,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:48,858 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:48,858 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:48,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:48,858 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:48,858 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:48,859 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:48,859 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:48,859 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:48,859 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:48,859 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:21:48,860 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:48,860 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:48,864 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:48,865 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:21:48,917 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:48,917 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:48,922 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=48701
2025-06-05T04:21:48,923 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:21:48,927 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:48,927 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]48701
2025-06-05T04:21:48,927 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:48,927 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:48,928 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:21:48,928 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:48,928 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:48,934 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:48,934 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:48,935 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:48,935 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:48,935 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:48,935 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:48,935 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:48,935 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:48,935 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:48,935 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:21:48,948 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:48,948 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:48,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=48722
2025-06-05T04:21:48,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:21:48,959 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:48,959 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]48722
2025-06-05T04:21:48,959 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:48,959 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:48,960 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:21:48,965 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:21:48,979 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:48,979 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:49,017 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:49,017 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:49,019 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:49,019 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:49,028 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:49,028 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:49,031 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:49,031 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:49,031 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:49,032 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:49,032 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:49,032 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:49,032 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:49,032 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:49,032 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:49,032 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:49,032 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:49,032 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:49,035 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:21:52,647 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=48979
2025-06-05T04:21:52,647 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:21:52,651 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=48978
2025-06-05T04:21:52,651 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:21:52,651 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:52,651 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]48979
2025-06-05T04:21:52,651 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:52,652 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:52,653 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:21:52,655 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:52,655 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]48978
2025-06-05T04:21:52,655 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:52,655 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:52,658 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:21:52,667 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:21:52,672 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:21:52,686 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:52,686 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:52,688 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:52,688 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:52,701 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=48984
2025-06-05T04:21:52,701 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:21:52,705 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:52,705 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]48984
2025-06-05T04:21:52,705 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:52,705 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:52,706 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=48987
2025-06-05T04:21:52,706 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:21:52,707 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:21:52,711 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:52,711 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]48987
2025-06-05T04:21:52,711 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:52,711 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:52,713 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:21:52,719 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:21:52,726 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:21:52,735 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:52,735 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:52,741 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:52,742 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:52,777 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:52,778 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:52,778 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:52,778 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:52,792 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:52,792 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:52,792 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:52,793 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:52,798 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:52,798 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:52,799 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:52,799 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:52,799 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:52,799 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:52,799 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:52,799 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:52,799 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:52,799 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:52,799 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:52,799 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:52,800 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:52,800 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:52,800 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:52,800 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:52,800 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:52,800 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:52,800 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:52,800 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:52,800 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:52,800 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:52,800 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:52,800 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:52,800 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:52,800 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:52,800 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:52,800 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:21:52,800 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:21:52,809 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:52,809 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:52,817 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:52,817 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:52,820 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:52,821 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:52,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:21:52,829 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:52,829 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:52,832 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:52,832 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:52,832 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:52,832 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:52,832 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:52,832 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:52,832 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:52,832 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:52,833 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:21:52,868 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=48993
2025-06-05T04:21:52,868 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:21:52,872 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:52,872 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]48993
2025-06-05T04:21:52,872 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:52,872 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:52,873 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:21:52,879 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:21:52,894 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:52,894 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:52,947 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=48990
2025-06-05T04:21:52,947 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:21:52,951 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:52,951 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]48990
2025-06-05T04:21:52,951 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:52,951 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:52,952 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:21:52,959 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:52,959 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:52,963 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:21:52,968 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:52,968 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:52,971 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:21:52,978 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:52,978 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:53,068 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:53,068 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:53,078 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:53,079 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:53,081 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:53,082 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:53,082 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:53,082 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:21:58,538 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=49307
2025-06-05T04:21:58,538 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:21:58,546 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:58,546 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]49307
2025-06-05T04:21:58,546 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:58,547 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:58,547 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:21:58,567 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:21:58,584 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:58,584 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:58,597 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=49316
2025-06-05T04:21:58,597 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:21:58,597 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=49308
2025-06-05T04:21:58,597 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:21:58,601 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:58,601 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]49316
2025-06-05T04:21:58,601 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:58,601 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:58,602 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:58,602 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]49308
2025-06-05T04:21:58,602 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:58,602 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:58,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:21:58,603 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:21:58,603 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=49313
2025-06-05T04:21:58,606 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:21:58,615 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:58,615 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]49313
2025-06-05T04:21:58,615 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:58,615 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:58,618 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:21:58,622 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:21:58,629 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:21:58,635 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:21:58,639 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:58,639 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:58,645 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:58,645 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:58,649 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:58,650 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:58,695 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:58,695 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:58,703 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:58,703 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:58,705 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:58,705 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:58,706 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:58,706 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:58,710 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:58,710 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:58,716 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:58,717 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:58,717 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:21:58,719 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:58,719 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:58,721 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:58,721 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:58,721 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:58,721 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:58,722 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:58,722 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:58,722 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:58,723 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:21:58,724 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:58,724 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:58,725 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:58,725 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:58,726 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:58,726 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:58,726 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:58,726 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:58,726 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:21:58,824 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=49319
2025-06-05T04:21:58,824 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:21:58,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:58,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]49319
2025-06-05T04:21:58,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:58,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:58,830 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:21:58,840 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:21:58,857 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:58,857 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:58,926 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=49376
2025-06-05T04:21:58,926 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:21:58,931 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:21:58,931 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]49376
2025-06-05T04:21:58,931 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:21:58,931 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:21:58,932 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:21:58,938 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:58,938 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:58,946 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:21:58,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:58,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:58,955 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:21:58,964 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:21:58,964 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:21:59,049 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:21:59,049 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:21:59,062 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:21:59,062 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:21:59,064 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:21:59,064 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:21:59,064 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:21:59,065 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:22:07,412 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=49636
2025-06-05T04:22:07,413 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:22:07,422 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:07,422 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]49636
2025-06-05T04:22:07,423 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:07,423 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:07,426 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:22:07,427 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=49633
2025-06-05T04:22:07,427 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:22:07,437 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:07,438 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]49633
2025-06-05T04:22:07,438 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:07,439 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:07,447 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:22:07,468 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:22:07,485 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:07,486 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:07,488 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:22:07,498 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:07,498 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:07,519 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=49637
2025-06-05T04:22:07,519 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:22:07,520 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=49630
2025-06-05T04:22:07,520 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:22:07,524 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:07,524 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]49637
2025-06-05T04:22:07,524 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:07,524 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:07,525 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:07,525 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]49630
2025-06-05T04:22:07,525 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:07,525 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:07,525 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:22:07,530 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:22:07,551 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:22:07,551 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:22:07,566 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:07,566 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:07,566 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:07,566 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:07,584 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:07,584 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:07,584 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:07,584 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:07,597 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:07,598 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:07,599 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:07,599 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:07,603 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:22:07,603 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:07,603 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:07,604 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:22:07,628 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:07,628 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:07,628 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:07,628 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:07,640 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:07,640 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:07,640 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:07,640 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:07,642 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:07,642 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:07,642 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:07,642 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:07,642 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:07,642 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:07,642 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:07,643 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:07,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:07,643 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:07,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:07,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:07,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:07,643 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:07,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:22:07,643 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:07,643 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:07,643 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:07,643 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:07,643 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:07,643 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:07,644 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:07,644 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:07,644 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:07,644 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:22:07,759 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=49642
2025-06-05T04:22:07,760 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:22:07,764 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:07,764 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]49642
2025-06-05T04:22:07,764 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:07,764 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:07,765 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:22:07,774 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:22:07,789 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:07,789 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:07,814 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=49753
2025-06-05T04:22:07,814 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:22:07,818 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:07,818 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]49753
2025-06-05T04:22:07,818 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:07,818 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:07,819 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:22:07,819 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:22:07,833 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:07,833 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:07,871 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:07,871 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:07,877 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:07,877 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:07,882 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:07,882 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:07,885 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:22:07,888 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:07,888 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:07,891 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:07,891 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:07,891 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:07,891 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:07,891 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:07,891 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:07,891 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:07,891 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:07,892 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:22:21,417 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=49988
2025-06-05T04:22:21,417 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:22:21,424 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:21,424 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]49988
2025-06-05T04:22:21,424 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:21,424 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:21,426 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:22:21,427 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:22:21,429 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=49989
2025-06-05T04:22:21,429 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:22:21,434 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=49995
2025-06-05T04:22:21,434 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:22:21,435 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:21,436 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]49989
2025-06-05T04:22:21,436 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:21,436 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:21,436 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=49994
2025-06-05T04:22:21,436 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:22:21,437 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:22:21,438 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:22:21,439 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:21,439 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]49995
2025-06-05T04:22:21,439 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:21,439 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:21,440 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:22:21,441 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:22:21,441 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:21,441 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]49994
2025-06-05T04:22:21,441 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:21,442 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:21,442 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:22:21,443 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:22:21,444 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:21,444 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:21,453 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:21,454 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:21,461 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:21,461 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:21,463 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:21,463 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:21,543 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:21,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:21,544 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:21,543 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:21,544 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:21,544 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:21,544 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:21,544 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:21,554 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:21,555 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:21,554 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:21,554 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:21,555 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:21,555 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:21,558 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:21,559 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:21,559 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:22:21,559 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:21,559 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:21,559 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:21,559 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:21,559 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:21,559 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:21,559 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:21,559 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:21,559 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:21,559 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:21,559 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:21,560 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:21,560 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:21,560 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:21,560 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:21,560 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:21,560 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:21,560 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:21,560 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:21,560 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:21,560 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:21,560 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:21,561 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:21,561 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:21,561 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:21,561 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:21,561 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:21,561 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:21,561 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:21,561 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:21,561 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:21,561 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:21,562 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:21,562 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:21,562 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:21,562 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:22:21,562 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:22:21,563 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:21,564 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:21,568 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:22:21,721 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=50000
2025-06-05T04:22:21,721 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:22:21,725 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:21,725 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]50000
2025-06-05T04:22:21,725 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:21,725 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:21,727 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:22:21,727 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:22:21,732 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=50003
2025-06-05T04:22:21,732 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:22:21,737 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:21,737 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]50003
2025-06-05T04:22:21,737 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:21,737 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:21,738 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:22:21,739 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:22:21,741 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:21,741 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:21,753 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:21,753 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:21,814 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:21,814 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:21,814 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:21,814 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:21,825 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:21,825 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:21,825 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:21,825 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:21,828 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:21,828 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:21,828 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:21,828 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:21,828 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:21,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:21,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:21,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:21,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:21,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:21,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:21,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:21,829 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:21,829 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:21,830 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:22:21,830 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:21,830 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:21,830 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:22:54,591 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=50363
2025-06-05T04:22:54,592 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:22:54,600 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:54,600 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]50363
2025-06-05T04:22:54,601 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:54,602 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:54,602 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:22:54,603 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:22:54,618 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:54,618 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:54,624 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=50370
2025-06-05T04:22:54,624 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:22:54,632 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:54,632 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]50370
2025-06-05T04:22:54,632 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:54,632 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:54,633 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=50361
2025-06-05T04:22:54,633 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:22:54,634 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:22:54,634 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:22:54,642 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:54,642 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]50361
2025-06-05T04:22:54,642 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:54,642 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:54,643 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:22:54,644 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:22:54,648 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=50362
2025-06-05T04:22:54,649 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:22:54,651 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:54,651 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:54,653 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:54,654 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]50362
2025-06-05T04:22:54,654 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:54,654 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:54,655 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:22:54,656 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:22:54,664 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:54,664 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:54,674 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:54,674 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:54,717 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:54,717 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:54,717 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:54,717 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:54,721 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:54,721 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:54,731 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:54,731 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:54,731 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:54,731 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:54,732 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:54,732 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:54,735 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:54,735 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:54,737 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:54,737 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:54,737 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:54,737 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:54,738 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:54,738 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:54,739 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:54,739 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:54,739 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:54,739 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:22:54,739 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:54,739 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:54,739 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:54,739 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:54,739 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:54,739 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:54,739 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:54,739 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:54,740 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:54,740 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:54,740 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:54,740 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:54,740 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:54,740 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:54,740 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:54,740 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:54,740 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:22:54,745 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:54,746 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:22:54,748 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:54,749 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:54,752 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:54,752 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:54,753 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:22:43,602 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=50379
2025-06-05T04:22:43,602 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:22:43,606 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:43,606 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]50379
2025-06-05T04:22:43,606 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:43,606 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:43,607 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:22:43,608 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:22:43,621 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:43,621 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:43,640 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=50380
2025-06-05T04:22:43,641 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:22:43,645 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:22:43,645 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]50380
2025-06-05T04:22:43,645 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:22:43,645 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:22:43,646 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:22:43,646 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:22:43,660 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:22:43,660 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:22:43,690 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:43,690 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:43,701 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:43,701 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:43,704 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:22:43,704 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:43,704 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:22:43,715 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:22:43,715 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:22:43,717 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:22:43,718 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:22:43,718 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:22:43,718 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:23:18,158 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=50798
2025-06-05T04:23:18,159 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:23:18,163 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:23:18,163 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]50798
2025-06-05T04:23:18,163 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:23:18,163 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:23:18,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:23:18,166 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:23:18,179 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=50807
2025-06-05T04:23:18,179 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:23:18,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:23:18,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]50807
2025-06-05T04:23:18,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:23:18,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:23:18,184 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:23:18,185 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:23:18,185 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:23:18,185 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:23:18,200 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:23:18,200 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:23:18,240 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=50804
2025-06-05T04:23:18,240 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:23:18,243 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=50799
2025-06-05T04:23:18,243 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:23:18,244 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:23:18,244 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]50804
2025-06-05T04:23:18,244 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:23:18,244 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:23:18,245 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:23:18,246 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:23:18,248 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:23:18,248 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]50799
2025-06-05T04:23:18,248 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:23:18,248 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:23:18,248 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:23:18,249 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:23:18,261 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:23:18,261 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:23:18,265 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:23:18,265 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:23:18,265 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:23:18,265 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:23:18,265 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:23:18,265 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:23:18,278 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:23:18,278 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:23:18,279 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:23:18,279 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:23:18,283 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:23:18,283 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:23:18,284 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:23:18,284 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:23:18,284 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:23:18,284 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:23:18,284 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:23:18,284 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:23:18,284 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:23:18,284 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:23:18,284 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:23:18,284 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:23:18,284 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:23:18,284 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:23:18,336 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:23:18,336 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:23:18,336 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:23:18,337 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:23:18,347 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:23:18,347 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:23:18,347 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:23:18,347 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:23:18,350 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:23:18,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:23:29,765 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=50810
2025-06-05T04:23:29,766 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:23:29,770 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:23:29,770 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]50810
2025-06-05T04:23:29,770 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:23:29,770 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:23:29,771 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:23:29,771 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:23:29,777 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=50813
2025-06-05T04:23:29,777 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:23:29,782 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:23:29,782 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]50813
2025-06-05T04:23:29,782 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:23:29,782 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:23:29,783 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:23:29,783 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:23:29,785 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:23:29,785 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:23:29,797 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:23:29,797 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:23:29,845 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:23:29,845 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:23:29,845 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:23:29,845 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:23:29,856 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:23:29,856 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:23:29,856 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:23:29,856 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:23:29,859 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:23:29,859 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:23:29,859 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:23:29,859 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:23:29,859 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:23:29,859 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:23:29,859 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:23:29,859 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:23:29,860 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:23:29,860 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:24:14,012 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=51349
2025-06-05T04:24:14,012 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:24:14,019 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:24:14,019 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]51349
2025-06-05T04:24:14,019 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:24:14,021 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:24:14,021 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:24:14,021 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:24:14,046 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:24:14,047 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:24:14,089 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=51350
2025-06-05T04:24:14,089 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:24:14,093 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:24:14,093 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]51350
2025-06-05T04:24:14,094 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:24:14,094 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:24:14,094 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:24:14,095 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:24:14,110 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:24:14,110 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:24:14,138 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=51355
2025-06-05T04:24:14,139 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:24:14,143 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:24:14,143 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]51355
2025-06-05T04:24:14,143 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:24:14,143 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:24:14,144 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:24:14,144 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:24:14,145 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:24:14,145 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:24:14,159 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:24:14,159 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:24:14,160 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:24:14,160 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:24:14,164 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:24:14,168 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:24:14,168 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:24:14,180 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:24:14,180 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:24:14,183 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:24:14,204 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=51358
2025-06-05T04:24:14,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:24:14,209 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:24:14,209 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]51358
2025-06-05T04:24:14,209 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:24:14,209 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:24:14,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:24:14,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:24:14,232 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:24:14,232 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:24:14,234 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:24:14,234 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:24:14,244 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:24:14,244 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:24:14,252 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:24:14,303 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:24:14,303 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:24:14,314 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:24:14,315 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:24:14,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:24:14,377 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=51376
2025-06-05T04:24:14,377 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:24:14,381 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:24:14,381 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]51376
2025-06-05T04:24:14,381 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:24:14,381 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:24:14,382 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:24:14,383 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:24:14,396 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:24:14,396 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:24:14,402 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=51375
2025-06-05T04:24:14,402 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:24:14,407 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:24:14,407 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]51375
2025-06-05T04:24:14,407 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:24:14,407 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:24:14,407 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:24:14,408 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:24:14,423 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:24:14,423 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:24:14,468 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:24:14,468 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:24:14,468 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:24:14,468 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:24:14,479 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:24:14,479 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:24:14,479 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:24:14,479 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:24:14,482 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:24:14,482 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:24:14,483 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:24:14,483 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:24:14,483 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:25:43,867 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=52261
2025-06-05T04:25:43,867 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:25:43,871 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:25:43,871 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]52261
2025-06-05T04:25:43,871 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:25:43,871 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:25:43,872 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:25:43,873 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:25:43,890 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:25:43,891 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:25:43,990 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:25:43,991 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:25:43,995 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=52266
2025-06-05T04:25:43,995 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:25:44,002 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:25:44,002 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:25:44,002 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:25:44,003 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]52266
2025-06-05T04:25:44,003 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:25:44,003 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:25:44,003 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:25:44,004 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:25:44,005 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:25:44,005 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:25:44,005 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:25:44,005 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:25:44,005 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:25:44,005 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:25:44,005 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:25:44,005 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:25:44,005 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/9047655cafcd4b0f82e243b4e6096541/onnx_handler.py", line 16, in initialize
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:25:44,006 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed:Load model /tmp/models/9047655cafcd4b0f82e243b4e6096541/model.onnx failed. File doesn't exist
2025-06-05T04:25:44,019 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:25:44,019 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:25:44,058 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=52271
2025-06-05T04:25:44,058 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:25:44,062 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:25:44,062 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]52271
2025-06-05T04:25:44,062 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:25:44,062 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:25:44,063 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:25:44,063 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:25:44,077 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:25:44,077 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:25:44,095 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=52276
2025-06-05T04:25:44,096 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:25:44,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:25:44,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]52276
2025-06-05T04:25:44,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:25:44,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:25:44,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:25:44,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:25:44,109 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:25:44,109 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:25:44,114 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:25:44,114 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:25:44,120 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:25:44,120 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/onnx_handler.py", line 16, in initialize
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:25:44,123 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed:Load model /tmp/models/9dd2a99fbf67485ca6c3d4590a4db7e8/model.onnx failed. File doesn't exist
2025-06-05T04:25:44,127 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:25:44,127 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:25:44,139 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:25:44,139 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/3efce99e1632401d94785e0e8d784f1f/onnx_handler.py", line 16, in initialize
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:25:44,151 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed:Load model /tmp/models/3efce99e1632401d94785e0e8d784f1f/model.onnx failed. File doesn't exist
2025-06-05T04:25:44,164 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:25:44,164 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:25:44,175 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:25:44,175 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/onnx_handler.py", line 16, in initialize
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:25:44,179 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:25:44,180 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:25:44,180 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed:Load model /tmp/models/e1be07fd09144e9d9963e3271c4ae4fa/model.onnx failed. File doesn't exist
2025-06-05T04:25:44,249 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=52337
2025-06-05T04:25:44,249 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:25:44,253 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:25:44,253 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]52337
2025-06-05T04:25:44,253 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:25:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:25:44,254 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:25:44,255 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:25:44,268 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:25:44,268 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:25:44,292 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=52336
2025-06-05T04:25:44,292 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:25:44,297 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:25:44,297 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]52336
2025-06-05T04:25:44,297 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:25:44,297 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:25:44,297 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:25:44,298 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:25:44,311 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:25:44,311 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:25:44,330 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:25:44,330 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:25:44,343 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:25:44,343 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:25:44,346 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/457b1438d72f425b8f0be6b72fee1276/onnx_handler.py", line 16, in initialize
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:25:44,347 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed:Load model /tmp/models/457b1438d72f425b8f0be6b72fee1276/model.onnx failed. File doesn't exist
2025-06-05T04:25:44,358 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:25:44,358 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:25:44,369 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:25:44,369 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:25:44,371 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:25:44,371 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:25:44,371 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/onnx_handler.py", line 16, in initialize
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:25:44,372 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed:Load model /tmp/models/da8fe388e3d246d6ba49a12b4ad8a7d1/model.onnx failed. File doesn't exist
2025-06-05T04:26:09,508 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=52899
2025-06-05T04:26:09,509 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:26:09,515 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:09,515 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]52899
2025-06-05T04:26:09,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:09,516 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:09,530 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:26:09,589 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:26:09,591 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:09,591 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:09,624 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=52903
2025-06-05T04:26:09,625 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:26:09,629 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:09,630 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]52903
2025-06-05T04:26:09,630 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:09,630 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:09,632 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:26:09,645 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:26:09,660 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:09,660 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:09,684 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:09,685 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:09,698 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:09,698 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:09,704 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:09,704 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:09,704 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:09,705 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:09,705 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:09,705 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:09,705 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:09,705 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:09,706 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:09,706 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:09,706 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:09,706 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:09,707 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:09,707 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:09,707 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:09,708 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:09,708 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:09,708 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:09,708 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:26:09,724 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:09,724 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:09,736 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:09,736 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:09,738 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:09,738 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:09,738 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:09,739 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:09,740 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:09,740 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:09,740 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:09,740 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:09,741 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:26:09,745 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=52908
2025-06-05T04:26:09,745 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:26:09,751 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:09,751 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]52908
2025-06-05T04:26:09,751 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:09,751 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:09,752 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:26:09,758 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:26:09,772 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:09,772 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:09,786 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=52914
2025-06-05T04:26:09,787 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:26:09,791 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:09,791 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]52914
2025-06-05T04:26:09,791 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:09,791 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:09,792 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:26:09,798 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:26:09,812 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:09,813 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:09,851 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:09,851 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:09,860 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:09,860 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:09,862 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:09,863 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:09,865 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:09,866 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:09,867 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:09,867 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:09,867 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:09,867 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:26:09,872 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:09,872 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:09,875 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:09,875 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:09,875 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:09,876 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:09,877 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:09,877 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:09,877 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:09,877 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:26:09,905 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=52946
2025-06-05T04:26:09,905 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=52951
2025-06-05T04:26:09,905 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:26:09,905 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:26:09,909 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:09,909 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:09,909 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]52951
2025-06-05T04:26:09,909 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]52946
2025-06-05T04:26:09,909 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:09,909 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:09,909 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:09,909 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:09,910 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:26:09,910 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:26:09,917 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:26:09,917 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:26:09,931 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:09,931 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:09,932 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:09,932 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:10,004 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:10,004 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:10,004 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:10,004 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:10,014 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:10,014 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:10,014 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:10,014 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:10,017 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:10,017 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:10,018 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:10,018 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:10,018 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:10,018 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:10,018 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:10,018 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:10,019 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:10,019 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:10,019 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:10,019 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:10,019 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:10,019 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:10,019 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:10,019 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:10,019 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:10,020 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:10,020 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:10,020 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:10,020 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:10,020 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:26:10,020 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:10,020 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:10,020 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:26:11,455 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=53233
2025-06-05T04:26:11,455 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:26:11,466 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:11,469 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]53233
2025-06-05T04:26:11,469 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:11,470 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:11,473 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:26:11,499 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:26:11,499 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=53230
2025-06-05T04:26:11,500 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:26:11,507 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:11,507 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]53230
2025-06-05T04:26:11,507 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:11,507 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:11,508 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:26:11,511 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:11,512 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:11,526 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:26:11,553 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:11,553 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:11,603 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:11,603 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:11,610 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:11,610 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:11,615 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:11,615 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:11,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:11,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:11,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:11,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:11,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:11,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:11,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:11,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:11,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:11,621 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:26:11,624 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:11,624 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:11,627 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:11,628 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:11,628 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:11,628 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:11,628 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:11,628 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:11,628 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:11,628 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:11,628 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:11,628 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:26:11,631 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=53236
2025-06-05T04:26:11,632 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:26:11,632 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=53239
2025-06-05T04:26:11,633 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:26:11,636 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:11,636 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]53236
2025-06-05T04:26:11,637 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:11,637 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:11,637 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:11,637 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]53239
2025-06-05T04:26:11,637 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:11,637 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:11,638 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:26:11,639 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:26:11,653 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:26:11,653 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:26:11,667 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:11,667 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:11,667 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:11,668 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:11,742 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:11,742 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:11,743 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:11,743 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:11,755 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:11,755 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:11,755 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:11,755 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:11,758 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:11,760 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:11,760 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:11,760 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:11,760 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:11,760 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:11,761 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:26:11,827 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=53296
2025-06-05T04:26:11,828 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:26:11,828 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=53297
2025-06-05T04:26:11,828 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:26:11,832 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:11,832 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]53296
2025-06-05T04:26:11,832 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:11,832 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:11,832 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:11,832 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]53297
2025-06-05T04:26:11,832 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:11,832 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:11,833 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:26:11,833 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:26:11,846 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:26:11,846 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:26:11,859 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:11,859 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:11,859 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:11,859 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:11,952 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:11,952 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:11,952 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:11,953 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:11,963 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:11,963 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:11,963 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:11,963 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:11,965 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:11,966 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:11,966 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:11,966 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:11,966 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:11,966 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:11,966 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:11,966 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:11,966 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:11,966 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:11,967 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:11,967 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:11,967 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:11,967 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:11,967 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:11,967 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:11,967 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:11,967 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:11,967 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:11,967 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:26:13,335 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=53512
2025-06-05T04:26:13,335 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:26:13,347 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=53509
2025-06-05T04:26:13,347 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:26:13,359 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:13,361 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:13,363 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]53512
2025-06-05T04:26:13,364 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:13,364 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:13,367 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]53509
2025-06-05T04:26:13,368 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:26:13,374 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:13,374 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:13,378 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:26:13,393 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:26:13,399 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:26:13,413 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:13,413 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:13,415 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:13,415 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:13,499 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:13,499 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:13,499 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:13,499 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:13,511 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:13,512 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:13,512 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:13,512 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:13,520 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:13,520 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:13,521 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:13,521 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:13,521 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:13,521 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:13,521 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:13,521 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:26:13,554 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=53524
2025-06-05T04:26:13,554 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:26:13,558 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:13,558 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]53524
2025-06-05T04:26:13,558 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:13,559 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:13,561 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:26:13,571 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:26:13,573 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=53521
2025-06-05T04:26:13,573 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:26:13,580 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:13,580 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]53521
2025-06-05T04:26:13,581 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:13,581 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:13,582 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:26:13,586 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:13,587 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:13,588 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:26:13,602 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:13,602 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:13,663 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:13,663 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:13,663 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:13,663 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:13,674 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:13,674 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:13,674 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:13,674 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:13,677 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:13,677 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:13,677 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:13,677 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:13,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:26:13,678 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:13,678 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:13,678 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:13,679 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:26:24,966 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=53584
2025-06-05T04:26:24,966 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:26:24,971 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:24,971 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]53584
2025-06-05T04:26:24,971 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:24,971 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:24,972 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:26:24,978 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:26:24,991 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:24,992 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:25,017 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=53581
2025-06-05T04:26:25,018 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:26:25,022 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:25,022 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]53581
2025-06-05T04:26:25,022 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:25,022 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:25,023 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:26:25,028 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:26:25,042 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:25,042 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:25,073 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:25,073 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:25,083 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:25,084 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:25,084 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:25,085 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:25,087 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:26:25,096 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:25,096 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:25,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:26:16,214 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=53815
2025-06-05T04:26:16,217 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:26:16,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:16,225 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]53815
2025-06-05T04:26:16,226 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:16,226 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:16,227 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:26:16,267 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:16,267 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:26:16,267 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:16,278 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=53814
2025-06-05T04:26:16,278 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:26:16,285 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:16,286 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]53814
2025-06-05T04:26:16,286 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:16,287 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:16,288 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:26:16,319 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:26:16,337 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:16,337 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:16,360 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:16,360 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:16,373 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:16,373 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:16,376 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:16,377 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:16,378 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:16,378 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:16,378 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:16,378 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:16,378 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:16,378 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:26:16,396 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:16,396 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:16,407 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:16,407 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:16,410 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:26:16,476 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=53821
2025-06-05T04:26:16,477 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:26:16,482 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:16,483 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]53821
2025-06-05T04:26:16,483 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:16,483 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:16,484 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:26:16,496 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:26:16,511 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:16,511 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=53820
2025-06-05T04:26:16,511 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:16,511 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:26:16,515 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:16,515 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]53820
2025-06-05T04:26:16,515 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:16,515 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:16,516 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:26:16,527 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:26:16,542 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:16,543 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:16,599 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=53880
2025-06-05T04:26:16,599 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:26:16,603 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:16,603 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]53880
2025-06-05T04:26:16,603 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:16,603 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:16,604 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:26:16,614 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:16,614 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:16,614 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:16,614 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:16,615 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:26:16,623 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:16,623 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:16,623 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:16,623 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:16,624 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=53882
2025-06-05T04:26:16,624 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:26:16,626 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:16,626 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:16,626 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:16,626 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:16,626 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:16,626 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:16,626 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:16,626 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:16,626 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:16,626 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:16,627 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:16,627 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:16,627 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:16,627 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:16,627 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:16,627 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:16,627 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:16,627 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:26:16,627 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:16,628 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:26:16,629 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:16,629 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]53882
2025-06-05T04:26:16,629 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:16,629 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:16,630 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:26:16,633 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:16,633 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:16,642 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:26:16,656 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:16,656 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:16,727 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:16,727 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:16,727 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:16,727 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:16,738 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:16,738 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:16,738 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:16,738 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:16,741 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:16,742 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:16,742 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:16,742 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:16,742 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:16,742 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:16,742 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:16,742 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:16,742 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:16,743 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:26:20,170 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=54115
2025-06-05T04:26:20,170 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:26:20,178 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:20,179 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]54115
2025-06-05T04:26:20,179 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:20,179 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:20,180 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:26:20,201 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:26:20,209 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=54112
2025-06-05T04:26:20,210 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:26:20,219 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:20,220 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]54112
2025-06-05T04:26:20,220 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:20,221 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:20,224 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:26:20,229 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:20,229 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:20,262 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:26:20,273 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:20,273 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:20,336 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:20,336 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:20,336 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:20,336 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:20,348 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:20,348 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:20,348 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:20,348 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:20,353 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:20,353 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:20,353 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:20,353 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:20,353 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:20,353 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:20,353 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:26:20,353 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:20,353 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:20,353 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:20,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:26:20,488 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=54118
2025-06-05T04:26:20,488 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:26:20,492 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:20,492 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]54118
2025-06-05T04:26:20,492 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:20,492 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:20,493 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=54119
2025-06-05T04:26:20,493 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:26:20,494 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:26:20,498 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:20,499 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]54119
2025-06-05T04:26:20,499 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:20,499 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:20,500 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:26:20,500 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:26:20,506 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:26:20,516 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:20,516 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:20,521 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:20,521 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:20,548 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=54179
2025-06-05T04:26:20,548 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:26:20,552 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:20,552 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]54179
2025-06-05T04:26:20,552 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:20,552 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:20,553 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:26:20,559 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:26:20,573 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:20,574 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:20,577 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:20,577 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:20,577 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:20,577 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:20,587 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=54178
2025-06-05T04:26:20,588 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:26:20,588 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:20,588 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:20,588 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:20,588 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:20,594 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:20,594 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:20,594 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:20,594 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:20,594 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:20,594 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:20,594 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:20,595 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:26:20,595 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:20,595 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]54178
2025-06-05T04:26:20,595 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:20,595 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:20,596 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:26:20,597 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:26:20,604 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:26:20,619 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:20,619 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:20,661 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:20,661 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:20,668 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:20,668 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:20,672 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:20,672 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:20,674 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:26:20,678 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:20,678 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:20,681 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:26:25,914 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=54425
2025-06-05T04:26:25,915 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:26:25,921 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:25,922 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]54425
2025-06-05T04:26:25,922 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:25,922 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:25,926 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:26:25,973 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:26:25,980 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:25,980 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:26,015 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=54424
2025-06-05T04:26:26,015 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:26:26,022 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:26,022 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]54424
2025-06-05T04:26:26,022 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:26,022 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:26,025 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:26:26,041 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:26:26,058 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:26,058 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:26,106 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:26,106 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:26,111 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:26,111 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:26,118 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:26,118 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:26,123 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:26,124 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:26,124 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:26:26,125 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:26,125 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:26,128 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:26:26,313 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=54490
2025-06-05T04:26:26,313 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:26:26,317 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:26,318 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]54490
2025-06-05T04:26:26,318 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:26,318 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:26,318 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=54433
2025-06-05T04:26:26,319 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:26:26,319 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:26:26,321 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=54430
2025-06-05T04:26:26,321 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:26:26,324 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:26,324 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]54433
2025-06-05T04:26:26,324 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:26,324 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:26,325 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:26:26,325 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:26:26,327 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:26,327 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]54430
2025-06-05T04:26:26,327 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:26,327 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:26,329 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:26:26,342 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:26:26,344 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:26:26,346 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:26,346 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:26,357 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:26,358 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:26,358 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:26,358 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:26,364 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=54493
2025-06-05T04:26:26,365 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:26:26,369 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:26,369 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]54493
2025-06-05T04:26:26,369 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:26,369 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:26,370 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:26:26,382 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:26:26,396 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:26,396 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:26,436 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:26,436 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:26,436 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:26,436 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:26,436 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:26,436 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:26,447 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:26,447 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:26,447 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:26,447 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:26,447 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:26,447 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:26,451 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:26:26,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:26,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:26,452 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:26,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:26,452 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:26,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:26,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:26,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:26,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:26,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:26,452 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:26,452 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:26,452 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:26,452 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:26,452 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:26,452 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:26,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:26,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:26:26,463 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:26,463 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:26,474 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:26,474 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:26,476 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:26:34,834 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=54754
2025-06-05T04:26:34,834 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:26:34,886 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:34,897 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]54754
2025-06-05T04:26:34,898 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:34,898 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:34,900 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:26:34,906 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=54757
2025-06-05T04:26:34,906 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:26:34,913 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:34,914 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]54757
2025-06-05T04:26:34,914 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:34,914 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:34,920 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:26:34,920 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:26:34,944 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:34,944 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:34,945 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:26:34,973 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:34,973 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:35,046 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:35,046 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:35,046 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:35,046 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:35,058 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:35,058 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:35,058 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:35,058 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:35,061 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:35,061 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:35,061 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:35,061 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:35,062 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:35,062 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:35,062 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:35,062 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:35,062 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:35,063 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:35,063 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:26:35,240 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=54823
2025-06-05T04:26:35,241 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:26:35,245 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:35,245 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]54823
2025-06-05T04:26:35,245 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:35,245 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:35,246 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:26:35,260 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=54815
2025-06-05T04:26:35,260 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:26:35,261 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:26:35,263 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=54817
2025-06-05T04:26:35,263 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:26:35,265 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=54814
2025-06-05T04:26:35,265 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:26:35,265 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:35,265 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]54815
2025-06-05T04:26:35,265 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:35,265 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:35,266 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:26:35,270 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:35,270 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]54817
2025-06-05T04:26:35,270 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:35,270 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:35,271 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:35,271 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]54814
2025-06-05T04:26:35,271 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:35,271 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:35,272 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:26:35,275 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:26:35,276 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:26:35,277 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:26:35,282 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:26:35,282 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:35,282 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:35,292 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:35,292 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:35,295 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:35,295 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:35,296 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:35,296 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:35,368 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:35,368 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:35,368 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:35,368 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:35,368 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:35,368 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:35,368 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:35,369 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:35,378 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:35,379 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:35,379 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:35,379 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:35,379 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:35,379 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:35,379 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:35,379 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:35,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:35,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:35,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:35,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:35,385 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:35,385 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:35,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:35,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:35,385 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:35,385 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:26:35,385 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:35,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:35,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:35,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:35,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:35,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:35,386 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:35,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:35,386 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:35,386 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:35,386 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:35,386 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:35,386 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:35,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:35,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:35,386 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:35,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:35,386 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:35,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:35,386 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:35,387 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:35,387 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:35,387 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:35,388 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:35,388 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:35,388 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:35,388 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:35,388 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:35,388 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:26:35,388 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:35,388 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:35,388 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:35,388 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:35,388 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:35,388 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:27:00,106 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=55105
2025-06-05T04:27:00,106 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:27:00,113 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:00,114 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]55105
2025-06-05T04:27:00,114 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:00,114 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:00,115 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:27:00,117 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:27:00,142 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:00,142 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:00,148 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=55106
2025-06-05T04:27:00,149 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:27:00,157 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:00,158 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]55106
2025-06-05T04:27:00,158 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:00,159 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:00,160 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:27:00,161 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:27:00,190 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:00,190 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:48,960 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:48,960 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:48,974 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:48,974 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:48,974 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:48,975 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:48,989 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:48,989 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:48,990 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:48,990 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:48,991 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:48,992 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:48,992 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:48,992 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:26:48,993 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:48,994 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:26:49,252 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=55168
2025-06-05T04:26:49,253 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:26:49,253 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=55166
2025-06-05T04:26:49,253 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:26:49,259 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:49,259 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]55166
2025-06-05T04:26:49,259 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:49,259 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:49,260 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:49,260 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]55168
2025-06-05T04:26:49,260 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:49,261 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:49,261 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:26:49,261 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:26:49,262 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:26:49,262 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:26:49,272 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=55167
2025-06-05T04:26:49,272 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:26:49,276 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=55165
2025-06-05T04:26:49,276 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:26:49,277 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:49,278 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]55167
2025-06-05T04:26:49,278 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:49,278 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:49,279 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:49,279 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:49,279 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:26:49,279 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:26:49,281 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:26:49,281 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]55165
2025-06-05T04:26:49,281 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:26:49,281 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:26:49,281 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:49,281 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:49,282 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:26:49,283 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:26:49,296 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:49,296 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:49,300 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:26:49,300 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:26:49,362 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:49,362 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:49,362 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:49,362 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:26:49,362 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:49,362 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:49,362 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:49,362 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:26:49,375 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:49,375 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:49,375 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:49,376 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:49,376 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:49,376 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:49,376 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:26:49,376 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:49,381 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:26:49,382 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:49,382 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:49,382 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:49,382 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:49,382 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:49,382 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:49,382 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:49,382 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:49,382 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:49,382 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:49,382 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:49,382 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:49,382 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:49,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:49,383 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:26:49,383 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:49,383 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:26:49,383 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:49,383 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:26:49,383 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:26:49,383 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:26:49,383 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:49,383 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:26:49,383 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:49,384 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:49,384 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:26:49,384 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:49,384 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:49,384 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:26:49,384 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:49,384 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:26:49,384 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:26:49,384 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:26:49,384 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:26:49,384 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:26:49,384 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:26:49,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:26:49,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:26:49,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:27:10,670 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=55483
2025-06-05T04:27:10,670 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:27:10,674 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:10,674 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]55483
2025-06-05T04:27:10,675 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:10,675 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:10,675 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:27:10,676 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:27:10,692 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:10,692 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:10,717 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=55484
2025-06-05T04:27:10,718 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:27:10,741 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:10,756 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]55484
2025-06-05T04:27:10,756 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:10,757 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:10,767 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:27:10,769 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:27:10,801 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:10,802 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:10,818 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:10,818 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:10,832 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:10,832 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:10,850 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:10,850 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:10,850 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:10,850 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:10,851 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:27:10,875 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:10,875 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:10,890 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:10,890 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:10,892 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:10,892 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:10,892 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:10,893 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:27:11,111 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=55546
2025-06-05T04:27:11,111 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:27:11,115 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:11,115 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]55546
2025-06-05T04:27:11,115 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:11,115 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:11,116 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:27:11,117 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:27:11,130 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:11,130 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:11,141 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=55543
2025-06-05T04:27:11,141 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:27:11,145 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:11,146 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]55543
2025-06-05T04:27:11,146 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:11,146 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:11,147 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:27:11,147 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:27:11,154 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=55547
2025-06-05T04:27:11,154 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:27:11,155 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=55548
2025-06-05T04:27:11,155 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:27:11,158 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:11,158 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]55547
2025-06-05T04:27:11,158 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:11,158 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:11,159 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:27:11,159 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:11,160 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]55548
2025-06-05T04:27:11,160 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:11,160 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:11,160 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:27:11,160 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:27:11,161 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:27:11,162 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:11,162 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:11,174 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:11,174 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:11,176 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:11,176 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:11,215 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:11,215 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:11,215 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:11,215 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:11,224 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:11,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:11,224 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:11,224 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:11,225 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:11,225 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:11,226 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:11,226 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:11,228 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:11,228 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:11,228 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:11,229 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:11,229 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:11,229 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:11,229 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:11,229 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:11,229 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:11,229 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:11,229 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:11,229 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:11,229 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:27:11,236 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:11,236 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:11,239 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:11,239 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:11,240 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:11,240 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:11,240 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:11,240 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:11,240 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:11,240 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:11,240 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:11,240 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:11,241 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:11,242 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:11,243 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:27:45,624 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=55900
2025-06-05T04:27:45,624 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:27:45,632 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:45,653 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]55900
2025-06-05T04:27:45,653 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:45,653 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:45,655 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:27:45,656 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:27:45,669 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=55903
2025-06-05T04:27:45,669 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:27:45,677 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:45,677 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]55903
2025-06-05T04:27:45,678 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:45,678 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:45,679 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:45,679 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:45,680 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:27:45,687 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:27:45,706 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:45,706 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:45,792 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:45,792 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:45,792 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:45,792 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:45,804 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:45,804 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:45,804 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:45,804 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:45,810 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:45,810 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:45,811 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:45,811 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:45,811 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:45,811 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:45,811 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:45,811 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:45,811 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:45,811 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:45,811 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:27:45,967 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=55965
2025-06-05T04:27:45,967 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:27:45,972 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:45,972 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]55965
2025-06-05T04:27:45,972 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:45,972 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:45,972 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:27:45,973 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:27:45,977 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=55964
2025-06-05T04:27:45,977 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:27:45,982 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:45,982 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]55964
2025-06-05T04:27:45,982 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:45,982 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:45,983 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:27:45,983 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:27:45,987 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:45,987 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:45,998 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:45,998 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:46,006 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=55961
2025-06-05T04:27:46,007 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:27:46,011 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:46,012 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]55961
2025-06-05T04:27:46,012 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:46,012 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:46,012 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:27:46,013 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:27:46,022 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=55960
2025-06-05T04:27:46,022 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:27:46,026 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:27:46,026 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]55960
2025-06-05T04:27:46,026 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:27:46,026 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:27:46,027 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:46,027 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:46,027 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:27:46,028 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:27:46,042 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:27:46,043 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:27:46,058 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:46,058 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:46,059 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:46,059 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:46,070 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:46,070 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:46,070 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:46,070 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:46,073 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:46,074 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:27:46,078 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:46,078 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:46,090 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:46,090 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:46,092 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:46,093 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:46,093 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:46,093 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:27:46,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:27:46,104 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:27:46,107 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:28:41,538 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=56375
2025-06-05T04:28:41,538 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:28:41,542 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:28:41,542 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]56375
2025-06-05T04:28:41,542 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:28:41,542 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:28:41,543 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:28:41,545 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:28:41,561 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:28:41,561 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:28:41,587 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=56376
2025-06-05T04:28:41,587 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:28:41,592 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:28:41,592 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]56376
2025-06-05T04:28:41,592 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:28:41,592 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:28:41,593 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:28:41,594 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:28:41,617 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:28:41,617 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:28:41,669 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:28:41,669 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:28:41,669 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:28:41,669 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:28:41,682 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:28:41,682 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:28:41,685 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:28:41,686 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:28:41,686 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:28:41,691 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:28:41,827 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=56444
2025-06-05T04:28:41,827 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:28:41,830 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=56431
2025-06-05T04:28:41,830 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:28:41,830 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=56432
2025-06-05T04:28:41,830 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:28:41,831 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:28:41,831 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]56444
2025-06-05T04:28:41,831 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:28:41,831 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:28:41,832 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:28:41,833 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:28:41,834 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:28:41,834 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]56431
2025-06-05T04:28:41,834 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:28:41,834 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:28:41,835 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:28:41,835 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:28:41,835 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]56432
2025-06-05T04:28:41,835 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:28:41,835 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:28:41,835 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:28:41,836 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:28:41,836 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:28:41,840 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=56441
2025-06-05T04:28:41,840 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:28:41,845 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:28:41,845 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]56441
2025-06-05T04:28:41,845 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:28:41,845 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:28:41,845 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:28:41,846 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:28:41,847 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:28:41,847 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:28:41,850 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:28:41,850 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:28:41,850 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:28:41,850 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:28:41,861 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:28:41,862 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:28:41,920 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:28:41,920 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:28:41,920 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:28:41,920 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:28:41,920 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:28:41,920 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:28:41,920 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:28:41,920 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:28:41,931 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:28:41,931 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:28:41,931 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:28:41,931 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:28:41,931 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:28:41,931 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:28:41,933 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:28:41,933 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:28:41,934 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:28:41,934 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:28:41,935 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:28:41,935 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:28:41,935 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:28:41,935 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:28:41,935 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:28:41,935 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:28:41,935 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:28:41,935 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:28:41,935 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:28:41,935 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:28:41,936 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:28:41,938 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:28:41,938 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:28:41,941 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:28:41,942 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:28:41,942 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:28:41,942 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:30:11,409 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=56975
2025-06-05T04:30:11,409 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:30:11,417 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:30:11,417 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]56975
2025-06-05T04:30:11,417 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:30:11,417 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:30:11,418 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:30:11,418 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:30:11,434 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:30:11,434 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:30:11,439 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=56980
2025-06-05T04:30:11,439 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:30:11,444 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:30:11,444 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]56980
2025-06-05T04:30:11,444 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:30:11,444 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:30:11,446 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:30:11,447 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:30:11,463 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:30:11,463 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:30:11,547 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:30:11,547 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:30:11,547 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:30:11,548 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:30:11,560 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:30:11,560 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:30:11,560 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:30:11,560 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:30:11,565 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:30:11,565 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:30:11,565 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:30:11,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:30:11,566 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:30:11,567 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:30:11,667 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=57007
2025-06-05T04:30:11,667 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:30:11,671 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:30:11,672 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]57007
2025-06-05T04:30:11,672 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:30:11,672 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:30:11,672 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:30:11,673 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:30:11,673 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=56985
2025-06-05T04:30:11,673 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:30:11,675 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=56992
2025-06-05T04:30:11,676 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:30:11,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:30:11,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]56985
2025-06-05T04:30:11,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:30:11,678 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:30:11,679 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:30:11,679 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:30:11,680 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:30:11,680 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]56992
2025-06-05T04:30:11,680 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:30:11,681 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:30:11,681 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:30:11,681 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:30:11,687 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:30:11,688 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:30:11,693 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:30:11,693 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:30:11,700 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:30:11,700 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:30:11,730 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=56988
2025-06-05T04:30:11,730 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:30:11,734 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:30:11,734 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]56988
2025-06-05T04:30:11,734 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:30:11,734 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:30:11,735 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:30:11,735 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:30:11,749 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:30:11,749 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:30:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:30:11,759 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:30:11,759 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:30:11,759 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:30:11,759 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:30:11,759 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:30:11,770 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:30:11,770 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:30:11,770 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:30:11,770 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:30:11,770 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:30:11,770 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:30:11,772 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:30:11,772 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:30:11,772 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:30:11,772 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:30:11,773 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:30:11,773 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:30:11,774 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:30:11,774 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:30:11,774 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:30:11,774 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:30:11,774 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:30:11,774 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:30:11,774 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:30:11,774 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:30:11,775 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:30:11,825 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:30:11,825 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:30:11,836 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:30:11,836 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:30:11,838 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:30:11,839 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:30:11,839 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:30:11,839 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:30:11,839 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:30:11,839 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:30:11,839 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T04:32:36,421 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=57750
2025-06-05T04:32:36,421 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T04:32:36,425 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:32:36,425 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]57750
2025-06-05T04:32:36,425 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:32:36,425 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:32:36,426 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T04:32:36,427 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T04:32:36,442 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:32:36,442 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:32:36,443 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=57751
2025-06-05T04:32:36,443 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T04:32:36,447 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:32:36,448 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]57751
2025-06-05T04:32:36,448 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:32:36,448 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:32:36,450 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T04:32:36,450 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T04:32:36,469 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:32:36,469 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:32:36,530 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:32:36,530 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:32:36,530 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:32:36,530 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:32:36,543 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:32:36,543 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:32:36,545 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:32:36,545 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:32:36,550 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:32:36,550 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:32:36,550 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:32:36,550 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:32:36,550 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:32:36,550 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:32:36,550 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:32:36,550 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:32:36,550 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:32:36,550 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:32:36,551 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/tmp/models/894607b110ec4315a426792dd379bf21/onnx_handler.py", line 16, in initialize
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:32:36,551 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/onnx_handler.py", line 16, in initialize
2025-06-05T04:32:36,551 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:32:36,551 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:32:36,551 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed:Load model /tmp/models/894607b110ec4315a426792dd379bf21/model.onnx failed. File doesn't exist
2025-06-05T04:32:36,551 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:32:36,551 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:32:36,551 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:32:36,551 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed:Load model /tmp/models/37c3f6aa19c14f69a6baea1ed8aee6b2/model.onnx failed. File doesn't exist
2025-06-05T04:32:36,621 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=57763
2025-06-05T04:32:36,622 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T04:32:36,626 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:32:36,626 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]57763
2025-06-05T04:32:36,626 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:32:36,626 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:32:36,627 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T04:32:36,628 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T04:32:36,635 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=57762
2025-06-05T04:32:36,636 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T04:32:36,639 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=57761
2025-06-05T04:32:36,640 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T04:32:36,640 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:32:36,640 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]57762
2025-06-05T04:32:36,640 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:32:36,640 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:32:36,641 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T04:32:36,642 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T04:32:36,645 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:32:36,646 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:32:36,648 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:32:36,648 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]57761
2025-06-05T04:32:36,648 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:32:36,648 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:32:36,648 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T04:32:36,649 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T04:32:36,656 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:32:36,657 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:32:36,663 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:32:36,663 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:32:36,712 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=57781
2025-06-05T04:32:36,712 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T04:32:36,716 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T04:32:36,716 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]57781
2025-06-05T04:32:36,716 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T04:32:36,716 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T04:32:36,717 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T04:32:36,717 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T04:32:36,720 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:32:36,720 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:32:36,720 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:32:36,720 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:32:36,720 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:32:36,720 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:32:36,730 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T04:32:36,730 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T04:32:36,731 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:32:36,731 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:32:36,731 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:32:36,731 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:32:36,731 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:32:36,731 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:32:36,735 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/tmp/models/e17873f41caa4416b8858cfd9fbbcba3/onnx_handler.py", line 16, in initialize
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:32:36,736 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed:Load model /tmp/models/e17873f41caa4416b8858cfd9fbbcba3/model.onnx failed. File doesn't exist
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:32:36,737 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:32:36,738 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:32:36,738 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/tmp/models/e33ef62464614b5591afb68136eac6df/onnx_handler.py", line 16, in initialize
2025-06-05T04:32:36,738 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:32:36,738 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:32:36,738 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:32:36,738 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:32:36,738 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:32:36,738 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed:Load model /tmp/models/e33ef62464614b5591afb68136eac6df/model.onnx failed. File doesn't exist
2025-06-05T04:32:36,744 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:32:36,744 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:32:36,744 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:32:36,744 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:32:36,744 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/3df31b23cd754e81ae89acf8501bf003/onnx_handler.py", line 16, in initialize
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:32:36,745 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed:Load model /tmp/models/3df31b23cd754e81ae89acf8501bf003/model.onnx failed. File doesn't exist
2025-06-05T04:32:36,857 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T04:32:36,857 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T04:32:36,868 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T04:32:36,868 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 263, in <module>
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 231, in run_server
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 194, in handle_connection
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/model_loader.py", line 143, in load
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/tmp/models/fc9698834de243038ef5dbf39afe0e9a/onnx_handler.py", line 16, in initialize
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self.session = ort.InferenceSession(model_path, providers=providers)
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 472, in __init__
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     self._create_inference_session(providers, provider_options, disabled_optimizers)
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 550, in _create_inference_session
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG -     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
2025-06-05T04:32:36,872 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed:Load model /tmp/models/fc9698834de243038ef5dbf39afe0e9a/model.onnx failed. File doesn't exist
2025-06-05T06:28:54,556 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=81382
2025-06-05T06:28:54,559 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T06:28:54,561 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T06:28:54,561 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]81382
2025-06-05T06:28:54,561 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T06:28:54,563 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T06:28:54,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=81386
2025-06-05T06:28:54,566 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T06:28:54,571 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T06:28:54,572 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]81386
2025-06-05T06:28:54,571 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=81391
2025-06-05T06:28:54,572 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T06:28:54,572 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T06:28:54,573 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T06:28:54,574 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T06:28:54,575 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T06:28:54,577 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T06:28:54,577 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]81391
2025-06-05T06:28:54,577 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T06:28:54,577 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T06:28:54,578 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T06:28:54,580 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=81396
2025-06-05T06:28:54,581 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T06:28:54,585 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T06:28:54,585 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]81396
2025-06-05T06:28:54,585 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T06:28:54,586 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T06:28:54,590 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T06:28:54,601 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T06:28:54,605 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T06:28:54,608 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T06:28:54,614 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T06:28:54,634 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T06:28:54,634 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T06:28:54,634 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T06:28:54,634 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T06:28:54,634 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T06:28:54,634 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T06:28:54,634 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T06:28:54,635 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T06:28:54,679 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=81401
2025-06-05T06:28:54,680 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T06:28:54,683 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T06:28:54,684 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]81401
2025-06-05T06:28:54,684 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T06:28:54,684 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T06:28:54,685 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T06:28:54,696 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T06:28:54,712 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T06:28:54,713 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T06:28:54,729 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=81406
2025-06-05T06:28:54,729 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T06:28:54,734 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T06:28:54,734 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]81406
2025-06-05T06:28:54,734 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T06:28:54,734 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T06:28:54,735 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T06:28:54,746 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T06:28:54,750 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T06:28:54,750 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T06:28:54,750 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T06:28:54,750 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T06:28:54,750 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T06:28:54,750 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T06:28:54,750 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T06:28:54,750 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T06:28:54,763 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T06:28:54,764 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T06:28:54,767 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T06:28:54,767 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T06:28:54,767 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T06:28:54,767 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T06:28:54,767 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T06:28:54,767 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T06:28:54,767 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T06:28:54,767 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T06:28:54,769 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T06:28:54,769 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T06:28:54,785 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T06:28:54,785 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T06:28:54,808 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - [1;31m2025-06-05 06:28:54.807819208 [E:onnxruntime:Default, provider_bridge_ort.cc:2195 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1778 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.12: cannot open shared object file: No such file or directory
2025-06-05T06:28:54,808 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - [1;31m2025-06-05 06:28:54.808392755 [E:onnxruntime:Default, provider_bridge_ort.cc:2195 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1778 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.12: cannot open shared object file: No such file or directory
2025-06-05T06:28:54,808 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - [m
2025-06-05T06:28:54,809 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - [0;93m2025-06-05 06:28:54.807899552 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1055 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.[m
2025-06-05T06:28:54,809 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - [m
2025-06-05T06:28:54,809 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - [0;93m2025-06-05 06:28:54.808416124 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1055 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.[m
2025-06-05T06:28:54,808 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - [1;31m2025-06-05 06:28:54.808323011 [E:onnxruntime:Default, provider_bridge_ort.cc:2195 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1778 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.12: cannot open shared object file: No such file or directory
2025-06-05T06:28:54,809 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - [m
2025-06-05T06:28:54,810 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - [0;93m2025-06-05 06:28:54.808411070 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1055 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.[m
2025-06-05T06:28:54,815 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - [1;31m2025-06-05 06:28:54.815080402 [E:onnxruntime:Default, provider_bridge_ort.cc:2195 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1778 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.12: cannot open shared object file: No such file or directory
2025-06-05T06:28:54,815 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - [m
2025-06-05T06:28:54,815 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - [0;93m2025-06-05 06:28:54.815123498 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1055 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.[m
2025-06-05T06:28:54,843 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - [1;31m2025-06-05 06:28:54.843509857 [E:onnxruntime:Default, provider_bridge_ort.cc:2195 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1778 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.12: cannot open shared object file: No such file or directory
2025-06-05T06:28:54,844 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - [m
2025-06-05T06:28:54,844 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - [0;93m2025-06-05 06:28:54.843557525 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1055 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.[m
2025-06-05T06:28:54,845 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-06-05T06:28:54,845 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T06:28:54,860 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T06:28:54,860 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T06:28:54,897 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - [1;31m2025-06-05 06:28:54.897658715 [E:onnxruntime:Default, provider_bridge_ort.cc:2195 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1778 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.12: cannot open shared object file: No such file or directory
2025-06-05T06:28:54,897 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - [m
2025-06-05T06:28:54,898 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - [0;93m2025-06-05 06:28:54.897685840 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1055 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.[m
2025-06-05T09:00:37,379 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=117471
2025-06-05T09:00:37,379 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=117443
2025-06-05T09:00:37,379 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=117476
2025-06-05T09:00:37,379 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=117466
2025-06-05T09:00:37,379 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=117447
2025-06-05T09:00:37,380 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T09:00:37,380 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T09:00:37,380 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T09:00:37,380 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T09:00:37,380 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T09:00:37,383 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:00:37,383 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]117447
2025-06-05T09:00:37,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:00:37,383 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:00:37,383 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]117466
2025-06-05T09:00:37,383 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:00:37,384 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:00:37,384 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:00:37,384 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:00:37,384 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]117443
2025-06-05T09:00:37,384 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:00:37,384 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:00:37,385 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:00:37,385 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]117471
2025-06-05T09:00:37,385 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:00:37,385 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:00:37,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:00:37,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]117476
2025-06-05T09:00:37,385 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:00:37,386 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:00:37,390 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=117461
2025-06-05T09:00:37,390 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T09:00:37,393 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T09:00:37,393 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T09:00:37,393 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T09:00:37,393 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T09:00:37,393 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T09:00:37,398 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:00:37,398 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]117461
2025-06-05T09:00:37,398 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:00:37,399 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:00:37,400 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T09:00:37,427 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T09:00:37,427 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T09:00:37,427 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T09:00:37,428 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T09:00:37,428 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T09:00:37,429 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T09:00:37,463 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:00:37,463 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:00:37,464 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:00:37,464 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:00:37,464 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:00:37,464 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:00:37,464 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:00:37,464 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:00:37,464 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:00:37,464 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:00:37,464 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:00:37,464 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:00:37,620 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:00:37,621 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:00:37,621 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:00:37,622 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:00:37,625 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:00:37,628 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:00:37,648 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:00:37,648 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:00:37,648 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:00:37,648 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:00:37,648 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:00:37,648 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:00:37,649 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:00:37,649 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:00:37,649 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:00:37,649 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:00:37,649 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:00:37,649 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:02:37,185 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=118418
2025-06-05T09:02:37,186 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=118413
2025-06-05T09:02:37,186 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=118408
2025-06-05T09:02:37,187 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T09:02:37,187 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T09:02:37,187 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T09:02:37,190 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:02:37,190 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:02:37,190 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]118408
2025-06-05T09:02:37,190 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]118413
2025-06-05T09:02:37,190 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:02:37,190 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=118404
2025-06-05T09:02:37,191 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:02:37,191 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:02:37,191 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:02:37,191 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T09:02:37,193 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:02:37,193 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]118418
2025-06-05T09:02:37,193 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:02:37,193 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:02:37,197 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:02:37,197 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]118404
2025-06-05T09:02:37,197 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:02:37,197 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:02:37,200 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T09:02:37,200 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T09:02:37,200 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T09:02:37,200 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T09:02:37,238 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T09:02:37,238 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T09:02:37,238 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T09:02:37,239 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T09:02:37,254 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=118423
2025-06-05T09:02:37,254 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T09:02:37,258 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:02:37,259 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]118423
2025-06-05T09:02:37,259 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:02:37,259 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:02:37,260 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T09:02:37,272 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T09:02:37,272 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:02:37,272 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:02:37,272 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:02:37,272 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:02:37,273 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:02:37,273 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:02:37,272 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:02:37,273 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:02:37,288 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:02:37,288 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:02:37,340 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=118428
2025-06-05T09:02:37,340 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T09:02:37,344 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:02:37,344 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]118428
2025-06-05T09:02:37,344 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:02:37,344 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:02:37,345 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T09:02:37,359 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T09:02:37,374 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:02:37,374 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:02:37,436 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:02:37,437 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:02:37,439 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:02:37,440 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:02:37,440 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:02:37,453 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:02:37,453 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:02:37,453 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:02:37,453 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:02:37,453 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:02:37,454 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:02:37,454 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:02:37,454 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:02:37,454 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:02:37,454 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:02:37,496 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:02:37,509 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:02:37,509 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:03:21,168 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=119070
2025-06-05T09:03:21,169 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T09:03:21,175 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:03:21,175 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]119070
2025-06-05T09:03:21,176 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:03:21,176 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:03:21,185 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T09:03:21,197 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=119074
2025-06-05T09:03:21,197 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T09:03:21,202 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:03:21,202 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]119074
2025-06-05T09:03:21,203 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:03:21,203 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T09:03:21,203 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:03:21,205 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T09:03:21,215 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T09:03:21,219 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:03:21,220 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:03:21,231 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:03:21,231 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:03:21,242 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=119082
2025-06-05T09:03:21,242 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T09:03:21,246 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:03:21,247 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]119082
2025-06-05T09:03:21,247 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:03:21,247 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:03:21,249 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T09:03:21,261 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T09:03:21,289 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:03:21,290 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:03:21,308 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=119087
2025-06-05T09:03:21,309 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T09:03:21,312 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:03:21,312 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]119087
2025-06-05T09:03:21,313 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:03:21,313 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:03:21,314 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T09:03:21,326 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T09:03:21,341 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:03:21,341 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:03:21,354 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:03:21,357 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:03:21,367 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:03:21,367 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:03:21,371 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:03:21,371 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:03:21,411 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:03:21,426 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:03:21,426 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:03:21,447 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=119092
2025-06-05T09:03:21,448 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T09:03:21,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:03:21,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]119092
2025-06-05T09:03:21,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:03:21,452 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:03:21,454 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T09:03:21,457 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:03:21,466 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T09:03:21,470 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:03:21,471 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:03:21,483 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:03:21,484 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:03:21,516 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=119111
2025-06-05T09:03:21,517 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T09:03:21,521 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:03:21,522 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]119111
2025-06-05T09:03:21,522 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:03:21,522 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:03:21,523 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T09:03:21,534 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T09:03:21,549 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:03:21,550 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:03:21,602 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:03:21,614 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:03:21,614 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:03:21,656 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:03:21,667 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:03:21,667 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:10:06,534 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend received inference at: 1749114606
2025-06-05T09:10:06,603 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Invoking custom service failed.
2025-06-05T09:10:06,603 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T09:10:06,604 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 134, in predict
2025-06-05T09:10:06,604 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2025-06-05T09:10:06,604 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py", line 428, in handle
2025-06-05T09:10:06,604 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2025-06-05T09:10:06,604 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/e13982913fb44a56aa444b76c17cb597/onnx_handler.py", line 27, in preprocess
2025-06-05T09:10:06,604 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
2025-06-05T09:10:06,604 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - cv2.error: OpenCV(4.11.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:993: error: (-215:Assertion failed) !buf.empty() in function 'imdecode_'
2025-06-05T09:10:06,604 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-05T09:11:46,861 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend received inference at: 1749114706
2025-06-05T09:11:46,864 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Invoking custom service failed.
2025-06-05T09:11:46,864 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T09:11:46,864 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 134, in predict
2025-06-05T09:11:46,864 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2025-06-05T09:11:46,865 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py", line 428, in handle
2025-06-05T09:11:46,865 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2025-06-05T09:11:46,865 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/e13982913fb44a56aa444b76c17cb597/onnx_handler.py", line 28, in preprocess
2025-06-05T09:11:46,865 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     img = cv2.resize(img, (self.imgsz, self.imgsz))
2025-06-05T09:11:46,865 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - cv2.error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'
2025-06-05T09:11:46,865 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend received inference at: 1749114869
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Invoking custom service failed.
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 134, in predict
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py", line 428, in handle
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/e13982913fb44a56aa444b76c17cb597/onnx_handler.py", line 28, in preprocess
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG -     img = cv2.resize(img, (self.imgsz, self.imgsz))
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - cv2.error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'
2025-06-05T09:14:29,732 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-05T09:18:09,804 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=123043
2025-06-05T09:18:09,805 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T09:18:09,806 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=123052
2025-06-05T09:18:09,807 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T09:18:09,809 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:18:09,809 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - [PID]123043
2025-06-05T09:18:09,810 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:18:09,810 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:18:09,812 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:18:09,812 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]123052
2025-06-05T09:18:09,813 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:18:09,813 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:18:09,818 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T09:18:09,818 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T09:18:09,824 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=123066
2025-06-05T09:18:09,825 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T09:18:09,830 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:18:09,830 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - [PID]123066
2025-06-05T09:18:09,830 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:18:09,831 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:18:09,832 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=123047
2025-06-05T09:18:09,833 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T09:18:09,835 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T09:18:09,853 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:18:09,858 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T09:18:09,858 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T09:18:09,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - [PID]123047
2025-06-05T09:18:09,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:18:09,858 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:18:09,860 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T09:18:09,862 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T09:18:09,880 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T09:18:09,896 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:18:09,896 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:18:09,896 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:18:09,896 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:18:09,896 [WARN ] W-9001-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:18:09,896 [WARN ] W-9003-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:18:09,897 [WARN ] W-9002-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:18:09,897 [WARN ] W-9000-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:18:09,947 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=123071
2025-06-05T09:18:09,947 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T09:18:09,951 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:18:09,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - [PID]123071
2025-06-05T09:18:09,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:18:09,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:18:09,953 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T09:18:09,975 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T09:18:09,975 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=123130
2025-06-05T09:18:09,975 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T09:18:09,979 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:18:09,979 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - [PID]123130
2025-06-05T09:18:09,979 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:18:09,979 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:18:09,980 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T09:18:09,996 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:18:09,997 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T09:18:09,997 [WARN ] W-9004-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:18:10,012 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:18:10,012 [WARN ] W-9005-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:18:10,079 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:18:10,080 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:18:10,082 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:18:10,083 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:18:10,096 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:18:10,096 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:18:10,097 [INFO ] W-9000-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:18:10,097 [INFO ] W-9001-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:18:10,097 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:18:10,098 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:18:10,099 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:18:10,099 [INFO ] W-9003-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:18:10,120 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:18:10,150 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:18:10,151 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:18:10,162 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:18:10,179 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:18:10,179 [INFO ] W-9005-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:19:32,897 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Backend received inference at: 1749115172
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Invoking custom service failed.
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/service.py", line 134, in predict
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py", line 428, in handle
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -   File "/tmp/models/12b797488c0349b1a03c11fa2875754d/onnx_handler.py", line 28, in preprocess
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG -     img = cv2.resize(img, (self.imgsz, self.imgsz))
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - cv2.error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'
2025-06-05T09:19:32,952 [INFO ] W-9004-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-05T09:30:03,952 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=126368
2025-06-05T09:30:03,952 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=126364
2025-06-05T09:30:03,953 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-06-05T09:30:03,952 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=126390
2025-06-05T09:30:03,953 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-06-05T09:30:03,953 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-06-05T09:30:03,957 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:30:03,958 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - [PID]126390
2025-06-05T09:30:03,958 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:30:03,958 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:30:03,958 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:30:03,958 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - [PID]126368
2025-06-05T09:30:03,958 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:30:03,958 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:30:03,958 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:30:03,959 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - [PID]126364
2025-06-05T09:30:03,959 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:30:03,959 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:30:03,967 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-06-05T09:30:03,967 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-06-05T09:30:03,967 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-06-05T09:30:03,968 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=126382
2025-06-05T09:30:03,968 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-06-05T09:30:03,973 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:30:03,973 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - [PID]126382
2025-06-05T09:30:03,973 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:30:03,974 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:30:03,975 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-06-05T09:30:03,997 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-05T09:30:03,997 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=126398
2025-06-05T09:30:03,998 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-05T09:30:03,998 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-06-05T09:30:04,002 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-05T09:30:04,003 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-05T09:30:04,003 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:30:04,003 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - [PID]126398
2025-06-05T09:30:04,004 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:30:04,004 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:30:04,005 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-06-05T09:30:04,026 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-05T09:30:04,041 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:30:04,041 [WARN ] W-9002-vetlom_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:30:04,041 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:30:04,042 [WARN ] W-9001-thieudong_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:30:04,042 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:30:04,042 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:30:04,042 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:30:04,042 [WARN ] W-9004-nganmach_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:30:04,042 [WARN ] W-9000-xuoc_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:30:04,042 [WARN ] W-9003-bamdinh_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:30:04,129 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=126457
2025-06-05T09:30:04,130 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-06-05T09:30:04,133 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Successfully loaded /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-06-05T09:30:04,133 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - [PID]126457
2025-06-05T09:30:04,133 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-05T09:30:04,134 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.18
2025-06-05T09:30:04,135 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-06-05T09:30:04,153 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-05T09:30:04,168 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG - /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ts/torch_handler/base_handler.py:13: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-06-05T09:30:04,169 [WARN ] W-9005-divatma_1.0-stderr MODEL_LOG -   from pkg_resources import packaging
2025-06-05T09:30:04,218 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:30:04,219 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:30:04,221 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:30:04,228 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:30:04,233 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:30:04,234 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:30:04,234 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:30:04,234 [INFO ] W-9002-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:30:04,234 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:30:04,235 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:30:04,235 [INFO ] W-9004-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:30:04,243 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:30:04,244 [INFO ] W-9000-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:30:04,274 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:30:04,274 [INFO ] W-9001-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:30:04,320 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-05T09:30:04,333 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - ONNX enabled
2025-06-05T09:30:04,333 [INFO ] W-9005-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-05T09:31:15,615 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend received inference at: 1749115875
2025-06-05T09:31:52,375 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend received inference at: 1749115912
2025-06-05T09:34:09,726 [INFO ] W-9003-bamdinh_1.0-stdout MODEL_LOG - Backend received inference at: 1749116049
