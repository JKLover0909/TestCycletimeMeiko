2025-06-04T16:16:27,376 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-06-04T16:16:27,376 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-06-04T16:16:27,377 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-06-04T16:16:27,377 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-06-04T16:16:27,418 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
2025-06-04T16:16:27,418 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
2025-06-04T16:16:27,580 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.11.0
TS Home: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages
Current directory: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve
Temp directory: C:\Users\1\AppData\Local\Temp
Metrics config path: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 28
Max heap size: 8128 M
Python executable: C:\Users\1\anaconda3\envs\ts_yolo12\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
Initial Models: all
Log dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Metrics dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2025-06-04T16:16:27,580 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.11.0
TS Home: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages
Current directory: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve
Temp directory: C:\Users\1\AppData\Local\Temp
Metrics config path: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 28
Max heap size: 8128 M
Python executable: C:\Users\1\anaconda3\envs\ts_yolo12\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
Initial Models: all
Log dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Metrics dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2025-06-04T16:16:27,584 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-06-04T16:16:27,584 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-06-04T16:16:27,594 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: bamdinh.mar
2025-06-04T16:16:27,594 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: bamdinh.mar
2025-06-04T16:16:27,778 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model bamdinh
2025-06-04T16:16:27,778 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model bamdinh
2025-06-04T16:16:27,778 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model bamdinh
2025-06-04T16:16:27,778 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model bamdinh
2025-06-04T16:16:27,778 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model bamdinh loaded.
2025-06-04T16:16:27,778 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model bamdinh loaded.
2025-06-04T16:16:27,778 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: bamdinh, count: 1
2025-06-04T16:16:27,778 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: bamdinh, count: 1
2025-06-04T16:16:27,783 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: divatma.mar
2025-06-04T16:16:27,783 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: divatma.mar
2025-06-04T16:16:27,784 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:27,784 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:27,946 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model divatma
2025-06-04T16:16:27,946 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model divatma
2025-06-04T16:16:27,947 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model divatma
2025-06-04T16:16:27,947 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model divatma
2025-06-04T16:16:27,947 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model divatma loaded.
2025-06-04T16:16:27,947 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model divatma loaded.
2025-06-04T16:16:27,947 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: divatma, count: 1
2025-06-04T16:16:27,947 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: divatma, count: 1
2025-06-04T16:16:27,947 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: nganmach.mar
2025-06-04T16:16:27,947 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: nganmach.mar
2025-06-04T16:16:27,949 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:27,949 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:28,098 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nganmach
2025-06-04T16:16:28,098 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nganmach
2025-06-04T16:16:28,098 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nganmach
2025-06-04T16:16:28,098 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nganmach
2025-06-04T16:16:28,098 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nganmach loaded.
2025-06-04T16:16:28,098 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nganmach loaded.
2025-06-04T16:16:28,099 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nganmach, count: 1
2025-06-04T16:16:28,099 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nganmach, count: 1
2025-06-04T16:16:28,099 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: thieudong.mar
2025-06-04T16:16:28,099 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: thieudong.mar
2025-06-04T16:16:28,100 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:28,100 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:28,256 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model thieudong
2025-06-04T16:16:28,256 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model thieudong
2025-06-04T16:16:28,257 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model thieudong
2025-06-04T16:16:28,257 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model thieudong
2025-06-04T16:16:28,257 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model thieudong loaded.
2025-06-04T16:16:28,257 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model thieudong loaded.
2025-06-04T16:16:28,257 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: thieudong, count: 1
2025-06-04T16:16:28,257 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: thieudong, count: 1
2025-06-04T16:16:28,257 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: vetlom.mar
2025-06-04T16:16:28,257 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: vetlom.mar
2025-06-04T16:16:28,259 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:28,259 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:28,418 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vetlom
2025-06-04T16:16:28,418 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vetlom
2025-06-04T16:16:28,418 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vetlom
2025-06-04T16:16:28,418 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vetlom
2025-06-04T16:16:28,418 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vetlom loaded.
2025-06-04T16:16:28,418 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vetlom loaded.
2025-06-04T16:16:28,418 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vetlom, count: 1
2025-06-04T16:16:28,418 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vetlom, count: 1
2025-06-04T16:16:28,419 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: xuoc.mar
2025-06-04T16:16:28,419 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: xuoc.mar
2025-06-04T16:16:28,420 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:28,420 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:28,588 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model xuoc
2025-06-04T16:16:28,588 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model xuoc
2025-06-04T16:16:28,588 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model xuoc
2025-06-04T16:16:28,588 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model xuoc
2025-06-04T16:16:28,588 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model xuoc loaded.
2025-06-04T16:16:28,588 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model xuoc loaded.
2025-06-04T16:16:28,588 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: xuoc, count: 1
2025-06-04T16:16:28,588 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: xuoc, count: 1
2025-06-04T16:16:28,589 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:28,589 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:28,590 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2025-06-04T16:16:28,590 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2025-06-04T16:16:28,745 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-06-04T16:16:28,745 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-06-04T16:16:28,746 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2025-06-04T16:16:28,746 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2025-06-04T16:16:28,747 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2025-06-04T16:16:28,747 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2025-06-04T16:16:28,748 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2025-06-04T16:16:28,748 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2025-06-04T16:16:28,748 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2025-06-04T16:16:28,748 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2025-06-04T16:16:29,013 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-06-04T16:16:29,013 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-06-04T16:16:29,113 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2025-06-04T16:16:29,113 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2025-06-04T16:16:29,152 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:16:29,158 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:29,158 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]22840
2025-06-04T16:16:29,159 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:29,159 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,159 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:29,159 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,161 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:29,161 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:29,169 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:16:29,172 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589171
2025-06-04T16:16:29,172 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589171
2025-06-04T16:16:29,176 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589176
2025-06-04T16:16:29,176 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589176
2025-06-04T16:16:29,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:16:29,273 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:29,274 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:29,274 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:29,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:16:29,332 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:29,332 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]2924
2025-06-04T16:16:29,333 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:29,333 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:29,333 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:29,333 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:29,334 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589334
2025-06-04T16:16:29,334 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:16:29,334 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589334
2025-06-04T16:16:29,335 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589335
2025-06-04T16:16:29,335 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589335
2025-06-04T16:16:29,348 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:16:29,408 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:29,408 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:29,409 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:29,500 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:16:29,506 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:29,506 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]17860
2025-06-04T16:16:29,506 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,506 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:29,506 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,506 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:29,506 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:29,506 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:29,507 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589507
2025-06-04T16:16:29,507 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589507
2025-06-04T16:16:29,508 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:16:29,508 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589508
2025-06-04T16:16:29,508 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589508
2025-06-04T16:16:29,521 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:16:29,582 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:29,582 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:29,583 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:29,671 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:16:29,676 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:29,677 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]19692
2025-06-04T16:16:29,677 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,677 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:29,677 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,678 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:29,678 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:29,678 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:29,679 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589679
2025-06-04T16:16:29,679 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589679
2025-06-04T16:16:29,679 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:16:29,679 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589679
2025-06-04T16:16:29,679 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589679
2025-06-04T16:16:29,708 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:16:29,769 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:29,770 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:29,770 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:29,840 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:16:29,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:29,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]20220
2025-06-04T16:16:29,847 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:29,847 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:29,847 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:29,847 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:29,847 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:29,849 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589849
2025-06-04T16:16:29,849 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028589849
2025-06-04T16:16:29,849 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:16:29,849 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589849
2025-06-04T16:16:29,849 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028589849
2025-06-04T16:16:29,878 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:16:29,938 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:29,939 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:29,939 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:29,994 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:16:30,000 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:30,001 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]31148
2025-06-04T16:16:30,001 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:30,001 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:30,001 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change null -> WORKER_STARTED
2025-06-04T16:16:30,001 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:30,001 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:30,001 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:30,002 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028590002
2025-06-04T16:16:30,002 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028590002
2025-06-04T16:16:30,002 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:16:30,003 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028590003
2025-06-04T16:16:30,003 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028590003
2025-06-04T16:16:30,035 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:16:30,096 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:30,097 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:30,098 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:30,641 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:30,642 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:30,642 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:30,642 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:30,642 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:30,642 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:30,643 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:30,643 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:30,643 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:30,643 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:30,643 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:30,643 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:30,643 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:30,643 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:30,643 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:30,643 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:30,643 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:30,643 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:30,643 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:30,644 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:30,644 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:30,644 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:30,644 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:30,644 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:30,644 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:30,645 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:30,645 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:30,645 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:30,645 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:30,645 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:30,646 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:30,646 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:30,646 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:30,646 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:30,646 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:30,646 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:30,647 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:30,647 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:30,648 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:30,648 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:30,648 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:30,648 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:30,648 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:30,648 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:30,649 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:30,649 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:30,649 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:30,643 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:30,643 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:30,655 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:30,655 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:30,655 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:30,655 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:30,655 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028590655
2025-06-04T16:16:30,655 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028590655
2025-06-04T16:16:30,657 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:16:30,657 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:16:30,657 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:30,657 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:30,657 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:30,657 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:30,693 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:30,693 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:30,694 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:30,694 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:30,694 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:30,694 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:30,694 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:30,694 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:30,694 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:30,694 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:30,694 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:30,694 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:30,694 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:30,695 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:30,695 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:30,695 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:30,695 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:30,695 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:30,695 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:30,695 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028590695
2025-06-04T16:16:30,695 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028590695
2025-06-04T16:16:30,695 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:30,696 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:30,697 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:30,697 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:30,697 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:30,697 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:30,697 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:30,697 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:30,697 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:30,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:30,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:30,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:30,699 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:30,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:30,699 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:30,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:30,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:30,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:30,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:30,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:30,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:30,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:30,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:30,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:30,701 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:30,701 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:30,701 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:30,701 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:30,701 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:30,701 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:30,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:30,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:30,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:30,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:30,871 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:30,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:30,871 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:30,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:30,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:30,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:30,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:30,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:30,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:30,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:30,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:30,872 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:30,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:30,872 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:30,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:30,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:30,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:30,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:30,873 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028590873
2025-06-04T16:16:30,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:30,873 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028590873
2025-06-04T16:16:30,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:30,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:30,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:30,873 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:16:30,873 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:16:30,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:30,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:30,874 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:30,875 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:31,016 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:31,016 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:31,016 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:31,016 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:31,016 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:31,017 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:31,017 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:31,017 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:31,017 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:31,017 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:31,018 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:31,018 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:31,018 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:31,018 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028591018
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028591018
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:31,018 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:31,019 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:31,019 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:31,019 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:31,019 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:31,019 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:31,019 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:31,019 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:31,019 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:31,020 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:31,185 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:31,185 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:31,185 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:31,185 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:31,185 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:31,185 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:31,185 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:31,185 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:31,185 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:31,185 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:31,186 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:31,186 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:31,186 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:31,186 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:31,186 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:31,186 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:31,186 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:31,186 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:31,186 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:31,186 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:31,186 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:31,186 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028591186
2025-06-04T16:16:31,186 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:31,186 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028591186
2025-06-04T16:16:31,187 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:31,187 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:31,188 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:16:31,188 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:16:31,188 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:31,188 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:31,188 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:31,188 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:31,188 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:31,188 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:31,188 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:31,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:31,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:31,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:31,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:31,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:31,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:31,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:31,190 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:31,191 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:31,191 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:31,191 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:31,191 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:31,191 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:31,191 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:31,191 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:31,191 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:31,327 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:31,328 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:31,328 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:31,328 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:31,328 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:31,328 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:31,328 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:31,328 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:31,329 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:31,329 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:31,329 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:31,329 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028591329
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749028591329
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:31,329 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:31,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:31,331 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:31,331 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:31,331 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:31,672 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:31,672 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:31,700 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:31,700 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:31,889 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:31,889 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:32,028 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:32,028 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:32,198 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:32,198 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:32,339 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:32,339 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:32,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:16:32,926 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:32,926 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]31320
2025-06-04T16:16:32,926 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:32,926 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:32,926 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:32,926 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:32,926 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:32,926 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:32,928 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028592928
2025-06-04T16:16:32,928 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:16:32,928 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028592928
2025-06-04T16:16:32,928 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028592928
2025-06-04T16:16:32,928 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028592928
2025-06-04T16:16:32,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:16:32,963 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:16:32,970 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:32,970 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]8780
2025-06-04T16:16:32,970 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:32,970 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:32,970 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:32,970 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:32,971 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:32,971 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:32,972 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028592972
2025-06-04T16:16:32,972 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:16:32,972 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028592972
2025-06-04T16:16:32,972 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028592972
2025-06-04T16:16:32,972 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028592972
2025-06-04T16:16:32,995 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:16:33,014 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:33,014 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:33,015 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:33,056 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:33,057 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:33,057 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:33,146 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:16:33,152 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:33,153 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]12008
2025-06-04T16:16:33,153 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:33,153 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:33,153 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:33,153 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:33,153 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:33,153 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:33,155 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028593155
2025-06-04T16:16:33,155 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028593155
2025-06-04T16:16:33,155 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:16:33,155 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028593155
2025-06-04T16:16:33,155 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028593155
2025-06-04T16:16:33,168 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:16:33,229 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:33,229 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:33,229 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:33,312 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:16:33,317 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:33,318 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]29276
2025-06-04T16:16:33,318 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:33,318 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:33,318 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:33,318 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:33,319 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:33,319 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:33,320 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028593320
2025-06-04T16:16:33,320 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028593320
2025-06-04T16:16:33,320 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:16:33,320 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028593320
2025-06-04T16:16:33,320 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028593320
2025-06-04T16:16:33,337 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:16:33,398 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:33,398 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:33,398 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:33,501 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:16:33,506 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:33,507 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]31368
2025-06-04T16:16:33,507 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:33,507 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:33,507 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:33,507 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:33,507 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:33,507 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:33,509 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028593509
2025-06-04T16:16:33,509 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:16:33,509 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028593509
2025-06-04T16:16:33,509 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028593509
2025-06-04T16:16:33,509 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028593509
2025-06-04T16:16:33,526 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:16:33,585 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:33,585 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:33,587 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:33,666 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:16:33,672 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:33,672 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]23356
2025-06-04T16:16:33,672 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:33,672 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:33,672 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:33,672 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:33,672 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:33,672 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:33,674 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028593674
2025-06-04T16:16:33,674 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028593674
2025-06-04T16:16:33,674 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:16:33,674 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028593674
2025-06-04T16:16:33,674 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028593674
2025-06-04T16:16:33,697 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:16:33,773 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:33,773 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:33,774 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:34,343 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:34,343 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,343 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:34,343 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:34,343 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,344 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:34,343 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,344 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,344 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:34,344 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,344 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,344 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,344 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,344 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,344 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,344 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:34,344 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:34,344 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,344 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,344 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,344 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,344 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:34,344 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,344 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:34,345 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:34,346 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:34,347 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:34,377 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:34,377 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,377 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:34,378 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:34,378 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,379 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:34,378 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,379 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,379 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,379 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,379 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:34,379 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,379 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,379 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,379 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,379 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:34,379 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:34,379 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,379 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:34,379 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,379 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,379 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:34,379 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,379 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,381 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,381 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,381 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:34,381 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,381 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,382 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,382 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:34,382 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:34,382 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:34,382 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:34,382 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:34,382 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:34,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:34,539 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,539 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,539 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,539 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,540 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:34,540 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:34,540 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:34,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:34,540 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:34,540 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:34,540 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,540 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,540 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,540 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:16:34,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,540 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:34,541 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:34,542 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:34,543 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:34,544 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:34,544 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:34,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:34,659 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:34,659 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:34,659 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,659 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,659 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,659 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,659 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:34,659 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:34,659 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:34,659 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,659 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:34,659 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:34,659 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:34,662 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:34,850 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:34,850 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,850 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:34,850 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,850 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:34,850 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,850 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:34,851 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,851 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:34,851 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,851 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,851 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,851 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,851 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,851 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,851 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:34,851 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,851 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:34,851 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:34,851 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,851 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,852 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:34,852 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:34,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,853 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:34,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:34,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:34,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:34,856 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:34,856 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:34,979 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:34,979 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,979 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:34,979 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:34,979 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,979 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:34,979 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:34,979 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:34,979 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,979 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:34,979 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,979 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,979 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:34,980 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,980 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:34,980 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:34,980 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:34,980 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:34,980 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,980 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:34,981 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:34,982 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:35,348 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,348 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,394 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,394 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,548 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,548 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,672 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,672 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,859 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,859 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,996 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:35,996 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:36,696 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:16:36,702 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:36,702 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]12196
2025-06-04T16:16:36,702 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:36,702 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:36,702 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:36,702 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:36,702 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:36,702 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:36,704 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028596704
2025-06-04T16:16:36,704 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:16:36,704 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028596704
2025-06-04T16:16:36,704 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028596704
2025-06-04T16:16:36,704 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028596704
2025-06-04T16:16:36,718 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:16:36,732 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:16:36,738 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:36,738 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]9268
2025-06-04T16:16:36,738 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:36,738 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:36,738 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:36,738 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:36,739 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:36,739 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:36,741 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028596741
2025-06-04T16:16:36,741 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:16:36,741 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028596741
2025-06-04T16:16:36,741 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028596741
2025-06-04T16:16:36,741 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028596741
2025-06-04T16:16:36,754 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:16:36,792 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:36,792 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:36,792 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:36,821 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:36,822 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:36,822 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:36,909 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:16:36,915 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:36,915 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]19032
2025-06-04T16:16:36,915 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:36,916 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:36,916 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:36,916 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:36,916 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:36,916 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:36,918 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028596918
2025-06-04T16:16:36,918 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:16:36,918 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028596918
2025-06-04T16:16:36,918 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028596918
2025-06-04T16:16:36,918 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028596918
2025-06-04T16:16:36,930 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:16:36,994 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:36,994 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:36,994 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:37,069 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:16:37,075 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:37,075 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]7200
2025-06-04T16:16:37,075 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:37,075 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:37,075 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:37,075 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:37,075 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:37,075 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:37,077 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028597077
2025-06-04T16:16:37,077 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:16:37,077 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028597077
2025-06-04T16:16:37,077 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028597077
2025-06-04T16:16:37,077 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028597077
2025-06-04T16:16:37,099 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:16:37,159 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:37,159 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:37,160 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:37,238 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:16:37,244 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:37,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]5852
2025-06-04T16:16:37,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:37,245 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:37,245 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:37,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:37,245 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:37,245 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:37,248 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028597248
2025-06-04T16:16:37,248 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:16:37,248 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028597248
2025-06-04T16:16:37,248 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028597248
2025-06-04T16:16:37,248 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028597248
2025-06-04T16:16:37,270 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:16:37,336 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:37,336 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:37,336 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:37,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:16:37,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:37,416 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]27104
2025-06-04T16:16:37,416 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:37,416 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:37,416 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:37,416 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:37,416 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:37,416 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:37,418 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:16:37,418 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028597418
2025-06-04T16:16:37,418 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028597418
2025-06-04T16:16:37,418 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028597418
2025-06-04T16:16:37,418 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028597418
2025-06-04T16:16:37,442 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:16:37,504 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:37,504 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:37,505 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:38,174 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:38,174 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,174 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:38,174 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:38,174 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:38,174 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:38,174 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,175 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,175 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,174 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,175 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,175 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,175 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,175 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,175 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,175 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:38,175 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,175 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:38,175 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:38,175 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:38,175 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:38,175 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,175 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,175 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,176 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,175 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:38,176 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:38,176 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:38,177 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,178 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,178 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,178 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:38,178 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:38,178 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:38,178 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:38,179 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:38,180 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,180 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,180 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,180 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,180 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,180 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:38,180 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,181 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:38,181 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:38,181 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:38,181 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:38,181 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,181 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,181 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,181 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,181 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:38,181 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,181 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:38,181 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-06-04T16:16:38,181 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:38,182 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:38,184 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:38,184 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:38,184 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:38,183 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:38,184 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:38,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:38,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:38,318 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:38,318 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,319 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:38,319 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:38,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,319 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,319 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,319 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:38,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,319 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:38,319 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,319 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,319 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,319 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:38,320 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:38,322 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:38,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:38,322 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:38,322 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:38,322 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:38,466 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,467 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:38,467 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:38,467 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,467 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,467 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,467 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,467 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,467 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:38,467 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,467 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,468 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,467 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:38,468 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:38,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:38,470 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,469 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:38,470 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,470 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:38,470 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:38,470 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:38,470 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:38,628 [INFO ] nioEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:38,628 [INFO ] nioEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:38,628 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,628 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,628 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:38,628 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,628 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,629 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:38,629 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:38,629 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:38,629 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,629 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,629 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-06-04T16:16:38,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:38,632 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:38,754 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:38,754 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,754 [INFO ] nioEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,754 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:38,754 [INFO ] nioEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:38,754 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:38,755 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,755 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,755 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,755 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,755 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:38,755 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:38,755 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,755 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:38,755 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:38,755 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-06-04T16:16:38,755 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:38,756 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:38,757 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:38,757 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:38,757 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:38,757 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:40,185 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,185 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,197 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,197 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,334 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,334 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,476 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,476 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,632 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,632 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,756 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:40,756 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:41,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:16:41,448 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:16:41,454 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:41,454 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]22940
2025-06-04T16:16:41,454 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,454 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:41,454 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,454 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:41,454 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:41,455 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:41,455 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]9408
2025-06-04T16:16:41,455 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:41,455 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:41,455 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,455 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,455 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:41,455 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:41,455 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:41,456 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601456
2025-06-04T16:16:41,456 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601456
2025-06-04T16:16:41,456 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601456
2025-06-04T16:16:41,456 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:16:41,456 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601456
2025-06-04T16:16:41,456 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:16:41,456 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601456
2025-06-04T16:16:41,456 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601456
2025-06-04T16:16:41,458 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601458
2025-06-04T16:16:41,458 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601458
2025-06-04T16:16:41,472 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:16:41,487 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:16:41,530 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:41,530 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:41,530 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:41,544 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:41,544 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:41,544 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:41,581 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:16:41,589 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:41,589 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]12104
2025-06-04T16:16:41,589 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:41,589 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,589 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:41,589 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,589 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:41,589 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:41,590 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601590
2025-06-04T16:16:41,590 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:16:41,590 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601590
2025-06-04T16:16:41,591 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601591
2025-06-04T16:16:41,591 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601591
2025-06-04T16:16:41,613 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:16:41,673 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:41,673 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:41,673 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:41,741 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:16:41,747 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:41,747 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]24440
2025-06-04T16:16:41,747 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:41,747 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,747 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,747 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:41,747 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:41,747 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:41,748 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601748
2025-06-04T16:16:41,748 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:16:41,748 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601748
2025-06-04T16:16:41,748 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601748
2025-06-04T16:16:41,748 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601748
2025-06-04T16:16:41,760 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:16:41,819 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:41,819 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:41,819 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:41,892 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:16:41,898 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:41,898 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]33400
2025-06-04T16:16:41,898 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:41,898 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,898 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:41,898 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:41,898 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:41,898 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:41,899 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601899
2025-06-04T16:16:41,899 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028601899
2025-06-04T16:16:41,900 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601900
2025-06-04T16:16:41,899 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:16:41,900 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028601900
2025-06-04T16:16:41,909 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:16:41,970 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:41,970 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:41,970 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:42,056 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:16:42,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:42,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]8756
2025-06-04T16:16:42,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:42,062 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:42,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:42,062 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:42,062 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:42,062 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:42,064 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028602064
2025-06-04T16:16:42,064 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028602064
2025-06-04T16:16:42,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:16:42,064 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028602064
2025-06-04T16:16:42,064 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028602064
2025-06-04T16:16:42,075 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:16:42,141 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:42,142 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:42,142 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:42,859 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:42,859 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:42,859 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:42,859 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:42,859 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:42,859 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:42,860 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:42,860 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:42,860 [INFO ] nioEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:42,860 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:42,860 [INFO ] nioEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:42,860 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:42,860 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:42,860 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:42,860 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:42,860 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:42,860 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:42,860 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:42,860 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:42,860 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:42,861 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:42,861 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:42,861 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:42,861 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:42,861 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:42,861 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:42,861 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:42,862 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:42,863 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:42,863 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:42,863 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:42,863 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:42,863 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:42,863 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:42,863 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:42,863 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:42,863 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:42,884 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:42,884 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:42,885 [INFO ] nioEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:42,885 [INFO ] nioEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:42,885 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:42,885 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:42,885 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:42,885 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:42,885 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:42,885 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:42,885 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:42,885 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:42,886 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:42,885 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:42,886 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:42,886 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:42,887 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:42,887 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:42,887 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:42,887 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:42,887 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:42,887 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:42,887 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:42,887 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:42,887 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:42,888 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:42,889 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:42,889 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:42,889 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:42,889 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:42,956 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:42,956 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:42,956 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:42,956 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:42,956 [INFO ] nioEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:42,956 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:42,956 [INFO ] nioEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:42,956 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:42,957 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:42,957 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:42,957 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:42,957 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:42,957 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:42,957 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:42,957 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:42,957 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:42,957 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:42,957 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:42,957 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:42,958 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:42,959 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:42,959 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:42,959 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:42,959 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:42,959 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:42,959 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:42,959 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:42,959 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:42,959 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:42,960 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:43,111 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:43,111 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:43,111 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:43,111 [INFO ] nioEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:43,111 [INFO ] nioEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:43,111 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:43,112 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:43,112 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:43,112 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:43,112 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:43,112 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:43,112 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:43,112 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:43,112 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:43,112 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:43,112 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:43,112 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:43,112 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:43,112 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:43,112 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:43,112 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:43,112 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:43,112 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:43,112 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:43,113 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:43,114 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:43,116 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:43,116 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:43,257 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:43,257 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:43,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:43,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:43,258 [INFO ] nioEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:43,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:43,258 [INFO ] nioEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:43,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:43,258 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:43,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:43,258 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:43,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:43,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:43,258 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:43,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:43,258 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:43,259 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:43,259 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:43,259 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:43,259 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:43,259 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:43,259 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:43,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:43,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:43,262 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:43,262 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:43,262 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:43,262 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:43,262 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:43,262 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:43,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:43,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:43,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:43,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:43,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:43,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:43,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:43,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:43,383 [INFO ] nioEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:43,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:43,383 [INFO ] nioEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:43,384 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:43,384 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:43,384 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:43,384 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:43,384 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:43,384 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:43,384 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:43,384 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:43,384 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:43,384 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:43,384 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:43,385 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:43,386 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:43,387 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:43,387 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:43,387 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:43,387 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:45,878 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:45,878 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:45,892 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:45,892 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:45,969 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:45,969 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:46,124 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:46,124 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:46,263 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:46,263 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:46,401 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:46,401 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:47,191 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:16:47,197 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:47,198 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]6804
2025-06-04T16:16:47,198 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:47,198 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,198 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,198 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:47,198 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:47,198 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:47,199 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607199
2025-06-04T16:16:47,199 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607199
2025-06-04T16:16:47,199 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:16:47,199 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607199
2025-06-04T16:16:47,199 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607199
2025-06-04T16:16:47,209 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:16:47,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:16:47,216 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:47,217 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]28656
2025-06-04T16:16:47,217 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:47,217 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,217 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:47,217 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,218 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:47,218 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:47,219 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607219
2025-06-04T16:16:47,219 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607219
2025-06-04T16:16:47,219 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:16:47,219 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607219
2025-06-04T16:16:47,219 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607219
2025-06-04T16:16:47,238 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:16:47,268 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:16:47,274 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:47,274 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]26336
2025-06-04T16:16:47,274 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,274 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:47,274 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,274 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:47,274 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:47,274 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:47,276 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607276
2025-06-04T16:16:47,276 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607276
2025-06-04T16:16:47,276 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607276
2025-06-04T16:16:47,276 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:16:47,276 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607276
2025-06-04T16:16:47,279 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:47,280 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:47,284 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:47,300 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:16:47,306 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:47,306 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:47,307 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:47,362 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:47,362 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:47,362 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:47,435 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:16:47,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:47,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]27724
2025-06-04T16:16:47,441 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:47,441 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,441 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:47,441 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:47,441 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:47,442 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607442
2025-06-04T16:16:47,442 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:16:47,442 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607442
2025-06-04T16:16:47,442 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607442
2025-06-04T16:16:47,442 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607442
2025-06-04T16:16:47,472 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:16:47,532 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:47,532 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:47,532 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:47,586 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:16:47,592 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:47,592 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]28032
2025-06-04T16:16:47,592 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:47,592 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,592 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,592 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:47,592 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:47,592 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:47,594 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607594
2025-06-04T16:16:47,594 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607594
2025-06-04T16:16:47,594 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:16:47,594 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607594
2025-06-04T16:16:47,594 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607594
2025-06-04T16:16:47,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:16:47,674 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:47,674 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:47,674 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:47,740 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:16:47,746 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:47,747 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]26288
2025-06-04T16:16:47,747 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:47,748 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,748 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:47,748 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:47,748 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:47,748 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:47,750 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607750
2025-06-04T16:16:47,750 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028607750
2025-06-04T16:16:47,750 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:16:47,750 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607750
2025-06-04T16:16:47,750 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028607750
2025-06-04T16:16:47,782 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:16:47,846 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:47,846 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:47,846 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:48,608 [INFO ] nioEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,608 [INFO ] nioEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,608 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,608 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:48,608 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:48,608 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,609 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:48,609 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:48,609 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:48,609 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,609 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,609 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-06-04T16:16:48,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:48,611 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:48,613 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:48,613 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,613 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:48,614 [INFO ] nioEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:48,614 [INFO ] nioEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,614 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:48,614 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:48,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,614 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,614 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,615 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:48,615 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:48,615 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:48,615 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,615 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:48,615 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2025-06-04T16:16:48,615 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:48,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:48,617 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,617 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,617 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,617 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,617 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:48,617 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,617 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,617 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,617 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:48,618 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:48,618 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:48,618 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:48,618 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:48,618 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:48,644 [INFO ] nioEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,644 [INFO ] nioEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,644 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,644 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:48,644 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:48,644 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,644 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:48,644 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:48,644 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:48,644 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,645 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:48,645 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:48,645 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:48,646 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:48,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:48,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:48,800 [INFO ] nioEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,800 [INFO ] nioEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,800 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,800 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,800 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:48,800 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:48,800 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:48,800 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:48,800 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:48,800 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,800 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,800 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:48,800 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:48,801 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:48,802 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:48,914 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:48,914 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,914 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:48,914 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:48,914 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:48,914 [INFO ] nioEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:48,914 [INFO ] nioEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,915 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,915 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:48,915 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,915 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:48,915 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:48,915 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:48,915 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,915 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:48,915 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:48,915 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:48,915 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:48,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:48,917 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:48,917 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:48,917 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:48,917 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,917 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,917 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:48,917 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:48,918 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:48,918 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:48,918 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:48,918 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:48,918 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:48,918 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:48,918 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:48,918 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:49,060 [INFO ] nioEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:49,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:49,060 [INFO ] nioEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:49,061 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:49,061 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:49,061 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:49,061 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:49,061 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:49,061 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:49,061 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:49,061 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:49,061 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:49,061 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:49,061 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:49,061 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:49,061 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:49,061 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2025-06-04T16:16:49,061 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:49,061 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2025-06-04T16:16:49,061 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:49,062 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:49,064 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:53,622 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:53,622 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:53,622 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:53,622 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:53,652 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:53,652 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:53,810 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:53,810 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:53,919 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:53,919 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:54,074 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:54,074 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:16:54,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:16:54,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:16:54,904 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:54,904 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]19848
2025-06-04T16:16:54,904 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:54,904 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:54,904 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:54,904 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:54,904 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:54,904 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:16:54,906 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:16:54,906 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028614906
2025-06-04T16:16:54,906 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028614906
2025-06-04T16:16:54,906 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028614906
2025-06-04T16:16:54,906 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028614906
2025-06-04T16:16:54,908 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:54,908 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]32164
2025-06-04T16:16:54,908 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:54,908 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:54,908 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:54,908 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:54,908 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:54,908 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:16:54,911 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028614911
2025-06-04T16:16:54,911 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028614911
2025-06-04T16:16:54,911 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028614911
2025-06-04T16:16:54,911 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:16:54,911 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028614911
2025-06-04T16:16:54,911 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:16:54,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:54,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]21896
2025-06-04T16:16:54,919 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:54,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:54,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:54,919 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:54,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:16:54,920 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:54,920 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:16:54,934 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:16:54,935 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028614934
2025-06-04T16:16:54,934 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:16:54,935 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028614934
2025-06-04T16:16:54,935 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028614935
2025-06-04T16:16:54,935 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028614935
2025-06-04T16:16:54,951 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:16:54,981 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:54,982 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:54,982 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:54,996 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:54,996 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:54,996 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:55,010 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:55,011 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:55,011 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:55,075 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:16:55,081 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:55,082 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]32020
2025-06-04T16:16:55,082 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:55,082 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:55,082 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:55,082 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:55,082 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:55,082 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:16:55,084 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028615084
2025-06-04T16:16:55,084 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028615084
2025-06-04T16:16:55,084 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:16:55,084 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028615084
2025-06-04T16:16:55,084 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028615084
2025-06-04T16:16:55,106 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:16:55,168 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:55,168 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:55,168 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:55,183 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:16:55,188 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:55,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]22840
2025-06-04T16:16:55,189 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:55,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:55,189 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:55,189 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:55,189 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:55,189 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:16:55,191 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028615191
2025-06-04T16:16:55,191 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:16:55,191 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028615191
2025-06-04T16:16:55,191 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028615191
2025-06-04T16:16:55,191 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028615191
2025-06-04T16:16:55,203 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:16:55,262 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:55,262 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:55,263 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:55,347 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:16:55,353 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:16:55,353 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]18436
2025-06-04T16:16:55,354 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:16:55,354 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:55,354 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:16:55,354 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:16:55,354 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:55,354 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:16:55,355 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028615355
2025-06-04T16:16:55,355 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028615355
2025-06-04T16:16:55,355 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:16:55,356 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028615356
2025-06-04T16:16:55,356 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028615356
2025-06-04T16:16:55,369 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:16:55,432 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:16:55,432 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:16:55,433 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:16:56,314 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:56,314 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:56,316 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,316 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,316 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:56,316 [INFO ] nioEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,316 [INFO ] nioEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,316 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:56,316 [INFO ] nioEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,316 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:56,316 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,316 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:56,316 [INFO ] nioEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,316 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,316 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,316 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:56,316 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:56,316 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:56,316 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,316 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,316 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,316 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:56,316 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,316 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,316 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:56,316 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,316 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,316 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,316 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:56,316 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:16:56,316 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:16:56,316 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,316 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,316 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,316 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,317 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,316 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,316 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,317 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,316 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,317 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,317 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,317 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:56,317 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2025-06-04T16:16:56,317 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2025-06-04T16:16:56,317 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:56,317 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:56,317 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,317 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:56,317 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:56,317 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:56,317 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:56,318 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:56,318 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,319 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,319 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:56,321 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,321 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,321 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:56,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:56,321 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:56,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:56,321 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:56,321 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:56,321 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:16:56,321 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:56,333 [INFO ] nioEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,333 [INFO ] nioEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,333 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,333 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,333 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,335 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:56,335 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,335 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:56,335 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,335 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:56,335 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,335 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:56,335 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:16:56,335 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:56,335 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,335 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,335 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,335 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:56,335 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:56,335 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:56,336 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,337 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,337 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,337 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,337 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:56,337 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,337 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,337 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,337 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:56,337 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:56,338 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:56,338 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:56,338 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:16:56,338 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:16:56,436 [INFO ] nioEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,436 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:56,436 [INFO ] nioEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,445 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,446 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:56,446 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,446 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,446 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,446 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:56,446 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:56,446 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:56,446 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,446 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,446 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2025-06-04T16:16:56,446 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:56,447 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,447 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,447 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:56,447 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:56,447 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:56,447 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:56,447 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:56,448 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:56,449 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:56,449 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:16:56,449 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:56,449 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,536 [INFO ] nioEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,536 [INFO ] nioEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,536 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:56,536 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:56,536 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,536 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,537 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:56,536 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,537 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:56,537 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:56,537 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:56,537 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:16:56,537 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,537 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,537 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,537 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,537 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:56,537 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,537 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,538 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,539 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,539 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:56,539 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,539 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,539 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,539 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:56,539 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:56,539 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:56,539 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:16:56,540 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:56,540 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:16:56,712 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:16:56,712 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,712 [INFO ] nioEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,712 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:16:56,712 [INFO ] nioEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:16:56,713 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,712 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:16:56,713 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:16:56,713 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,713 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,713 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:56,713 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,713 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:16:56,713 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:16:56,713 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:16:56,713 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2025-06-04T16:16:56,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,714 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:16:56,715 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:16:56,715 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:16:56,715 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:16:56,715 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:16:56,715 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:16:56,715 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:56,715 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:16:56,715 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:16:56,715 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:17:04,320 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,320 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,320 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,320 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,352 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,352 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,460 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,460 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,551 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,551 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,724 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:04,724 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:05,693 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:17:05,695 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:17:05,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:05,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]31320
2025-06-04T16:17:05,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:05,700 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,700 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:05,700 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:17:05,700 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:17:05,701 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:05,701 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625701
2025-06-04T16:17:05,701 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625701
2025-06-04T16:17:05,701 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625701
2025-06-04T16:17:05,701 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]27568
2025-06-04T16:17:05,701 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625701
2025-06-04T16:17:05,702 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,701 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:17:05,702 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,701 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:05,702 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:17:05,702 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:17:05,702 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:05,704 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:17:05,706 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625706
2025-06-04T16:17:05,706 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625706
2025-06-04T16:17:05,706 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:17:05,706 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625706
2025-06-04T16:17:05,706 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625706
2025-06-04T16:17:05,722 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:05,722 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]8648
2025-06-04T16:17:05,722 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:05,722 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,722 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,723 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:05,723 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:17:05,723 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:17:05,723 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:17:05,737 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:17:05,738 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625738
2025-06-04T16:17:05,738 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:17:05,738 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625738
2025-06-04T16:17:05,738 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625738
2025-06-04T16:17:05,738 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625738
2025-06-04T16:17:05,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:17:05,799 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:05,799 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:05,800 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:05,817 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:05,818 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:05,818 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:05,830 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:17:05,832 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:05,832 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:05,832 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:05,835 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:05,835 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]16332
2025-06-04T16:17:05,835 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:05,835 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,835 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,836 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:05,836 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:17:05,836 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:17:05,838 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625838
2025-06-04T16:17:05,838 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:17:05,838 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625838
2025-06-04T16:17:05,838 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625838
2025-06-04T16:17:05,838 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625838
2025-06-04T16:17:05,850 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:17:05,913 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:05,914 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:05,914 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:05,948 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:17:05,955 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:05,955 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]7636
2025-06-04T16:17:05,956 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:05,956 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,956 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:05,956 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:05,956 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:17:05,956 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:17:05,957 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625957
2025-06-04T16:17:05,957 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028625957
2025-06-04T16:17:05,957 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:17:05,957 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625957
2025-06-04T16:17:05,957 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028625957
2025-06-04T16:17:05,968 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:17:06,034 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:06,034 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:06,035 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:06,184 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:17:06,190 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:06,190 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]28488
2025-06-04T16:17:06,190 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:06,191 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:06,191 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:06,191 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:06,191 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:17:06,191 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:17:06,192 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028626192
2025-06-04T16:17:06,192 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028626192
2025-06-04T16:17:06,192 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:17:06,192 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028626192
2025-06-04T16:17:06,192 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028626192
2025-06-04T16:17:06,204 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:17:06,264 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:06,265 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:06,265 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:07,375 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:07,376 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,376 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:07,376 [INFO ] nioEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,376 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:07,376 [INFO ] nioEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,376 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:07,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:07,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:07,377 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:07,377 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:07,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,377 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:07,377 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:07,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:07,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:07,379 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:17:07,379 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:17:07,379 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:17:07,379 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,393 [INFO ] nioEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,393 [INFO ] nioEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,393 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:07,393 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:07,394 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,394 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:07,394 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:07,394 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:07,394 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,394 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,394 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:07,394 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:07,394 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:07,395 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:07,397 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:17:07,397 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:17:07,397 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:17:07,397 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:17:07,422 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:07,422 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,422 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:07,422 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,423 [INFO ] nioEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,423 [INFO ] nioEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,423 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,423 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:07,423 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:07,423 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,423 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:17:07,423 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:17:07,423 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:07,423 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,423 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:07,423 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,423 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:07,424 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:17:07,425 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:17:07,427 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:07,427 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,428 [INFO ] nioEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,428 [INFO ] nioEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:07,428 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,428 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,428 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,428 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:07,428 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:07,429 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:17:07,429 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:17:07,429 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:07,429 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,429 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,429 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:07,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:07,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:07,431 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:17:07,431 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:17:07,431 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:17:07,431 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:17:07,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:07,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:07,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:07,494 [INFO ] nioEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,494 [INFO ] nioEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,494 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,494 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:07,494 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,494 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:07,494 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:07,494 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:17:07,494 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:07,494 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,494 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,494 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:07,495 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,496 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,496 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,496 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:07,496 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:07,496 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:17:07,496 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:17:07,496 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:17:07,496 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:07,678 [INFO ] nioEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,678 [INFO ] nioEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,678 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,678 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:07,678 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:07,678 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:07,678 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:07,679 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,679 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:07,679 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,679 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:07,679 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:07,679 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:07,679 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:07,680 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:07,681 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:07,681 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:07,681 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:07,681 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:17:07,681 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:17:07,681 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:17:07,681 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:17:20,394 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,394 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,408 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,408 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,438 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,438 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,440 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,440 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,502 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,502 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,689 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:20,689 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:21,686 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:17:21,686 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:17:21,692 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:21,692 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]14256
2025-06-04T16:17:21,692 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,692 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:21,692 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,692 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:21,692 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:17:21,692 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:17:21,692 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:21,693 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]7508
2025-06-04T16:17:21,693 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,693 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:21,693 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,693 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:17:21,693 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:21,693 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:17:21,694 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641693
2025-06-04T16:17:21,694 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641693
2025-06-04T16:17:21,694 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:17:21,694 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641694
2025-06-04T16:17:21,694 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641694
2025-06-04T16:17:21,696 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:17:21,696 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641696
2025-06-04T16:17:21,696 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641696
2025-06-04T16:17:21,696 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641696
2025-06-04T16:17:21,696 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641696
2025-06-04T16:17:21,724 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:17:21,724 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:17:21,732 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:17:21,735 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:17:21,738 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:21,738 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]1820
2025-06-04T16:17:21,739 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,739 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:21,739 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,739 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:21,739 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:17:21,739 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:17:21,740 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:17:21,741 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641741
2025-06-04T16:17:21,741 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641741
2025-06-04T16:17:21,741 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641741
2025-06-04T16:17:21,741 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641741
2025-06-04T16:17:21,742 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:21,743 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]11132
2025-06-04T16:17:21,743 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,743 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:21,743 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,743 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:21,743 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:17:21,743 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:17:21,745 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641745
2025-06-04T16:17:21,745 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:17:21,745 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641745
2025-06-04T16:17:21,745 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641745
2025-06-04T16:17:21,745 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641745
2025-06-04T16:17:21,786 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:17:21,786 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:17:21,789 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:21,789 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:21,789 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:21,789 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:21,789 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:21,789 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:21,812 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:17:21,818 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:21,819 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]3896
2025-06-04T16:17:21,819 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:21,819 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,819 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:21,819 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:21,819 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:17:21,819 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:17:21,821 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641821
2025-06-04T16:17:21,821 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:17:21,821 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028641821
2025-06-04T16:17:21,821 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641821
2025-06-04T16:17:21,821 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028641821
2025-06-04T16:17:21,848 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:17:21,851 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:21,851 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:21,852 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:21,853 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:21,854 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:21,854 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:21,910 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:21,910 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:21,910 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:22,001 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:17:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]18400
2025-06-04T16:17:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:22,007 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:22,007 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:22,007 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:17:22,007 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:17:22,010 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:17:22,010 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028642010
2025-06-04T16:17:22,010 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028642010
2025-06-04T16:17:22,010 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028642010
2025-06-04T16:17:22,010 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028642010
2025-06-04T16:17:22,036 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:17:22,098 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:22,098 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:22,098 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:23,140 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:23,141 [INFO ] nioEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:23,141 [INFO ] nioEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,141 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,141 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,141 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,141 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:23,141 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,141 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:23,141 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:17:23,141 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:23,141 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:17:23,142 [INFO ] nioEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,141 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:23,142 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,142 [INFO ] nioEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,142 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,142 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:23,142 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,142 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,142 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:23,142 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,142 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:23,142 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,142 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:23,142 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,142 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:23,142 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,142 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,142 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:17:23,142 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,142 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:23,142 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:17:23,142 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2025-06-04T16:17:23,142 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,142 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,142 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,142 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,143 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,142 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,143 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,143 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2025-06-04T16:17:23,143 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:23,143 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:23,143 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,143 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:23,143 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:23,143 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:23,143 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:23,144 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:23,144 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:23,144 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:23,144 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,144 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:23,144 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:23,144 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,144 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:23,144 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:17:23,144 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,144 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:23,144 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:17:23,144 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:23,144 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:23,144 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:17:23,144 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:23,144 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:17:23,144 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:23,145 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:23,145 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:23,145 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,145 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:23,145 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,145 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:23,145 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,145 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:23,145 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:23,145 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,145 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:23,145 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:23,145 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:23,145 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:23,145 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,146 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:23,146 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,146 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:23,146 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,146 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,146 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:23,146 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,146 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:23,146 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,146 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:17:23,146 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:17:23,146 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,146 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:23,147 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,147 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,147 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,147 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:23,147 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:23,147 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:17:23,147 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:17:23,176 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:23,176 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:23,177 [INFO ] nioEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:23,177 [INFO ] nioEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,177 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,177 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,177 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:23,177 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:23,177 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:23,177 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,177 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:23,177 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,178 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,177 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:23,178 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:23,178 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:23,179 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:23,180 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:17:23,180 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:17:23,180 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:17:23,180 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:17:23,191 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,192 [INFO ] nioEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:23,192 [INFO ] nioEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:23,192 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:23,192 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:23,192 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,192 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:23,192 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:23,192 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:17:23,192 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,192 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:23,192 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,192 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,192 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:17:23,194 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:17:23,197 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:23,197 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,197 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:23,197 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:23,197 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:23,197 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,198 [INFO ] nioEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,198 [INFO ] nioEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,198 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,198 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:23,198 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:23,198 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,198 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:17:23,198 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:17:23,198 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:23,198 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,198 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:23,198 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,198 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:23,199 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:23,200 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:23,201 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:17:23,201 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:17:23,201 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:17:23,201 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:17:23,413 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:23,413 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,413 [INFO ] nioEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,413 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:23,413 [INFO ] nioEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:23,413 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:23,413 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,413 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:23,413 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:23,413 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:23,413 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,414 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,414 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:23,414 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:23,414 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,414 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,414 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:23,414 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,414 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:23,414 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:23,415 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:23,417 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:17:23,417 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:17:23,417 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:17:23,417 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:17:29,105 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2025-06-04T16:17:29,105 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2025-06-04T16:17:44,155 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,155 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,155 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,155 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,184 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,184 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,200 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,200 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,200 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,200 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,419 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:44,419 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:17:45,454 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:17:45,460 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:45,460 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]21100
2025-06-04T16:17:45,460 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:45,460 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,460 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,460 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:45,461 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:17:45,461 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:17:45,463 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665463
2025-06-04T16:17:45,463 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665463
2025-06-04T16:17:45,463 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:17:45,463 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665463
2025-06-04T16:17:45,463 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665463
2025-06-04T16:17:45,479 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:17:45,480 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:17:45,486 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:45,487 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]26076
2025-06-04T16:17:45,487 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:45,487 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,487 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:45,487 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,488 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:17:45,488 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:17:45,490 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665489
2025-06-04T16:17:45,489 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:17:45,490 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665489
2025-06-04T16:17:45,490 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665490
2025-06-04T16:17:45,490 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665490
2025-06-04T16:17:45,511 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:17:45,553 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:45,553 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:45,553 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:45,555 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:17:45,559 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:17:45,561 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:45,561 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]3628
2025-06-04T16:17:45,562 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:45,562 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,562 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,562 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:45,562 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:17:45,562 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:17:45,563 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665563
2025-06-04T16:17:45,563 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665563
2025-06-04T16:17:45,563 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:17:45,563 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665563
2025-06-04T16:17:45,563 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665563
2025-06-04T16:17:45,564 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:17:45,567 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:45,568 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]26564
2025-06-04T16:17:45,568 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:45,568 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,568 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:45,568 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,568 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:17:45,568 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:17:45,572 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665572
2025-06-04T16:17:45,572 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665572
2025-06-04T16:17:45,572 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:17:45,572 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665572
2025-06-04T16:17:45,572 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665572
2025-06-04T16:17:45,589 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:45,589 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:17:45,589 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:45,589 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:45,589 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]29008
2025-06-04T16:17:45,589 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:45,589 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:45,590 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,590 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,590 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:45,590 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:17:45,590 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:17:45,592 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665592
2025-06-04T16:17:45,592 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665592
2025-06-04T16:17:45,593 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:17:45,593 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665593
2025-06-04T16:17:45,593 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665593
2025-06-04T16:17:45,597 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:17:45,621 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:17:45,644 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:45,644 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:45,644 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:45,665 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:45,666 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:45,666 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:45,686 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:45,686 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:45,686 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:45,726 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:17:45,731 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:17:45,731 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]23100
2025-06-04T16:17:45,731 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:17:45,732 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,732 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:17:45,732 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:17:45,732 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:17:45,732 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:17:45,734 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665734
2025-06-04T16:17:45,734 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:17:45,734 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028665734
2025-06-04T16:17:45,734 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665734
2025-06-04T16:17:45,734 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028665734
2025-06-04T16:17:45,760 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:17:45,821 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:17:45,821 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:17:45,822 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:17:46,870 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:46,870 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,870 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:46,870 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:46,870 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:46,870 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:46,870 [INFO ] nioEventLoopGroup-5-49 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,870 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,870 [INFO ] nioEventLoopGroup-5-49 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,870 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,870 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,870 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,870 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,871 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,871 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:46,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:46,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,871 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:46,871 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,871 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:46,871 [INFO ] nioEventLoopGroup-5-50 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:46,871 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:46,871 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:17:46,871 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,871 [INFO ] nioEventLoopGroup-5-50 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:46,871 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:46,871 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:46,871 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,871 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,871 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:17:46,872 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,871 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:46,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,872 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,872 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:46,872 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,872 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,872 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,872 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:17:46,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:46,872 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:17:46,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,872 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:46,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:46,872 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2025-06-04T16:17:46,872 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,872 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,872 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2025-06-04T16:17:46,872 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,872 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:46,872 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,872 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:17:46,873 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,873 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:17:46,874 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:46,874 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:46,874 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:46,874 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:46,874 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,874 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,874 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,874 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:46,874 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,875 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:17:46,875 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:17:46,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:46,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:46,875 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:46,875 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:17:46,875 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:46,926 [INFO ] nioEventLoopGroup-5-51 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:46,926 [INFO ] nioEventLoopGroup-5-51 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:46,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,926 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:46,926 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:17:46,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:46,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,926 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:46,926 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,927 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:46,927 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:46,927 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:46,927 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,927 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2025-06-04T16:17:46,927 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:46,927 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2025-06-04T16:17:46,927 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,928 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:17:46,929 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:17:46,948 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:46,948 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,948 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,949 [INFO ] nioEventLoopGroup-5-53 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,949 [INFO ] nioEventLoopGroup-5-53 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:46,949 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:46,949 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:46,949 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,949 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:46,950 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:46,950 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:17:46,950 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,950 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,950 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:46,950 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:46,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,951 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:17:46,952 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:17:46,955 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:46,955 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,955 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:46,955 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:46,956 [INFO ] nioEventLoopGroup-5-52 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,956 [INFO ] nioEventLoopGroup-5-52 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,956 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,956 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:46,956 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,956 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:46,956 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:46,956 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:17:46,956 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:46,956 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:46,956 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,956 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:46,956 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:46,957 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2025-06-04T16:17:46,957 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:46,957 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2025-06-04T16:17:46,957 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:46,957 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:46,957 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:46,957 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:46,958 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:17:46,959 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:46,959 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:46,959 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:46,959 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:46,959 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:46,960 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:17:46,960 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:17:47,039 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:17:47,039 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:47,039 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:17:47,039 [INFO ] nioEventLoopGroup-5-54 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:47,039 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:17:47,039 [INFO ] nioEventLoopGroup-5-54 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:17:47,039 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:17:47,039 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:47,039 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:17:47,039 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:17:47,039 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:47,039 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:47,039 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:47,039 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:47,040 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:17:47,040 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:17:47,040 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:47,040 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:17:47,040 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:17:47,040 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2025-06-04T16:17:47,040 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:17:47,041 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:17:47,042 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:17:47,043 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:17:47,043 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:17:47,043 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:18:20,879 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:20,879 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:20,879 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:20,879 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:20,941 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:20,941 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:20,957 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:20,957 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:20,973 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:20,973 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:21,050 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:21,050 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:18:22,152 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:18:22,158 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:18:22,159 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]3944
2025-06-04T16:18:22,159 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:18:22,159 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,159 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,159 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:18:22,159 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:18:22,159 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:18:22,160 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702160
2025-06-04T16:18:22,160 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:18:22,160 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702160
2025-06-04T16:18:22,161 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702161
2025-06-04T16:18:22,161 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702161
2025-06-04T16:18:22,171 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:18:22,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:18:22,178 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:18:22,178 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]23540
2025-06-04T16:18:22,178 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:18:22,178 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,178 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:18:22,178 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,178 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:18:22,178 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:18:22,180 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702180
2025-06-04T16:18:22,180 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702180
2025-06-04T16:18:22,180 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702180
2025-06-04T16:18:22,180 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:18:22,180 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702180
2025-06-04T16:18:22,203 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:18:22,240 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:18:22,240 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:18:22,241 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:18:22,241 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:18:22,244 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:18:22,246 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:18:22,247 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]31832
2025-06-04T16:18:22,247 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,247 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:18:22,247 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,247 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:18:22,247 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:18:22,247 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:18:22,247 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702247
2025-06-04T16:18:22,247 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702247
2025-06-04T16:18:22,248 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702248
2025-06-04T16:18:22,247 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:18:22,248 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702248
2025-06-04T16:18:22,248 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:18:22,250 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:18:22,250 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]17844
2025-06-04T16:18:22,250 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,250 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:18:22,250 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,250 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:18:22,250 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:18:22,250 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:18:22,251 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702251
2025-06-04T16:18:22,251 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702251
2025-06-04T16:18:22,251 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:18:22,251 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702251
2025-06-04T16:18:22,251 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702251
2025-06-04T16:18:22,252 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:18:22,259 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:18:22,261 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:18:22,261 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:18:22,261 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:18:22,265 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:18:22,265 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]15804
2025-06-04T16:18:22,266 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,266 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:18:22,266 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,266 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:18:22,266 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:18:22,266 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:18:22,267 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702267
2025-06-04T16:18:22,267 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:18:22,267 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702267
2025-06-04T16:18:22,267 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702267
2025-06-04T16:18:22,267 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702267
2025-06-04T16:18:22,267 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:18:22,310 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:18:22,311 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:18:22,311 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:18:22,311 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:18:22,311 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:18:22,312 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:18:22,318 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:18:22,324 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:18:22,324 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]18292
2025-06-04T16:18:22,324 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:18:22,324 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,324 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:18:22,324 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:18:22,324 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:18:22,324 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:18:22,325 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702325
2025-06-04T16:18:22,325 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028702325
2025-06-04T16:18:22,325 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702325
2025-06-04T16:18:22,325 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:18:22,325 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028702325
2025-06-04T16:18:22,326 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:18:22,329 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:18:22,330 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:18:22,330 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:18:22,388 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:18:22,388 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:18:22,388 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:18:23,520 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:18:23,520 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,520 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:18:23,520 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:18:23,520 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:18:23,520 [INFO ] nioEventLoopGroup-5-55 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,520 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:18:23,520 [INFO ] nioEventLoopGroup-5-55 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,520 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,520 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,520 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,520 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:18:23,521 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:18:23,521 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,521 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:18:23,521 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:18:23,521 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,521 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,521 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:18:23,521 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,521 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:18:23,523 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:18:23,536 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:18:23,536 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,536 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:18:23,536 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:18:23,536 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,537 [INFO ] nioEventLoopGroup-5-56 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,537 [INFO ] nioEventLoopGroup-5-56 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,537 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:18:23,537 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:18:23,537 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,537 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:18:23,537 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:18:23,537 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:18:23,538 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,537 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:18:23,538 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,538 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,538 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:18:23,538 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,538 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,538 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:18:23,538 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,538 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,538 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:18:23,538 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:18:23,538 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:18:23,539 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:18:23,540 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:18:23,541 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:18:23,541 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:18:23,541 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:18:23,541 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:18:23,603 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:18:23,604 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:18:23,604 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,604 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,604 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:18:23,604 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:18:23,604 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,604 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:18:23,604 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:18:23,604 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:18:23,604 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,604 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:18:23,604 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,604 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,605 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:18:23,606 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:18:23,607 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:18:23,607 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:18:23,608 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,608 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,608 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,608 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,608 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:18:23,608 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:18:23,608 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:18:23,608 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:18:23,609 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,608 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,609 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,609 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:18:23,609 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:18:23,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:18:23,610 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,611 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:18:23,612 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:18:23,613 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:18:23,613 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:18:23,613 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:18:23,613 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:18:23,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:18:23,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:18:23,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:18:23,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:18:23,623 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,623 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:18:23,623 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,623 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,624 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:18:23,624 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:18:23,624 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:18:23,624 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:18:23,624 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,624 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,624 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:18:23,624 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:18:23,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:18:23,626 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:18:23,654 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:18:23,654 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,654 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:18:23,654 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:18:23,654 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,654 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:18:23,654 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:18:23,654 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:18:23,654 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,655 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,655 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,655 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:18:23,655 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:18:23,655 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:18:23,655 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:18:23,655 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,655 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:18:23,655 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:18:23,655 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:18:23,655 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:18:23,656 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:18:29,100 [ERROR] Thread-3 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2025-06-04T16:18:29,100 [ERROR] Thread-3 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2025-06-04T16:19:18,532 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,532 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,546 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,546 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,609 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,609 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,625 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,625 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,641 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,641 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,673 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:18,673 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:19:19,840 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:19:19,846 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:19:19,846 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]26180
2025-06-04T16:19:19,846 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,846 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:19:19,846 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:19:19,846 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,846 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:19:19,846 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:19:19,846 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:19:19,847 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759847
2025-06-04T16:19:19,847 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759847
2025-06-04T16:19:19,847 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759847
2025-06-04T16:19:19,847 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:19:19,847 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759847
2025-06-04T16:19:19,847 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:19:19,853 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:19:19,853 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]6736
2025-06-04T16:19:19,853 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:19:19,853 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,853 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:19:19,853 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,854 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:19:19,854 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:19:19,855 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759855
2025-06-04T16:19:19,855 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:19:19,855 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759855
2025-06-04T16:19:19,855 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759855
2025-06-04T16:19:19,855 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759855
2025-06-04T16:19:19,855 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:19:19,911 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:19:19,911 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:19:19,911 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:19:19,912 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:19:19,912 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:19:19,912 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:19:19,918 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:19:19,924 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:19:19,924 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]20832
2025-06-04T16:19:19,924 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,924 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:19:19,924 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,924 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:19:19,924 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:19:19,924 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:19:19,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759926
2025-06-04T16:19:19,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:19:19,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759926
2025-06-04T16:19:19,926 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759926
2025-06-04T16:19:19,926 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759926
2025-06-04T16:19:19,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:19:19,941 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:19:19,946 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:19:19,946 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]3348
2025-06-04T16:19:19,947 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:19:19,947 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,947 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:19:19,947 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,947 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:19:19,947 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:19:19,949 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759949
2025-06-04T16:19:19,949 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:19:19,949 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759949
2025-06-04T16:19:19,949 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759949
2025-06-04T16:19:19,949 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759949
2025-06-04T16:19:19,950 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:19:19,957 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:19:19,963 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:19:19,963 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]15860
2025-06-04T16:19:19,963 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:19:19,964 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,964 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,964 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:19:19,964 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:19:19,964 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:19:19,965 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759965
2025-06-04T16:19:19,965 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:19:19,965 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759965
2025-06-04T16:19:19,965 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759965
2025-06-04T16:19:19,965 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759965
2025-06-04T16:19:19,965 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:19:19,979 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:19:19,986 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:19:19,987 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]32512
2025-06-04T16:19:19,987 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,987 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:19:19,987 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:19:19,987 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:19:19,987 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:19:19,987 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:19:19,989 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759988
2025-06-04T16:19:19,989 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749028759988
2025-06-04T16:19:19,989 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:19:19,989 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759989
2025-06-04T16:19:19,989 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749028759989
2025-06-04T16:19:19,989 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:19:19,990 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:19:19,990 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:19:19,990 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:19:20,011 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:19:20,011 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:19:20,012 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:19:20,026 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:19:20,027 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:19:20,027 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:19:20,051 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:19:20,051 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:19:20,052 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:19:21,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:19:21,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,321 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:19:21,321 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:19:21,321 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:19:21,321 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:19:21,321 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,321 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,321 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,322 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,322 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:19:21,322 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,322 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,322 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:19:21,322 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\41f17af07c804c0d8f8a9b2e362558e8\yolo_handler.py", line 3, in <module>
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2025-06-04T16:19:21,322 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:19:21,323 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,324 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:19:21,325 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:19:21,325 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:19:21,325 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:19:21,325 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:19:21,325 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:19:21,326 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:19:21,326 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,326 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,326 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,326 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,326 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,327 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:19:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:19:21,327 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:19:21,327 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,327 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:19:21,327 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,327 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,327 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:19:21,327 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,327 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,327 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\58a867469d02430a921b7a50c2c4ce8c\yolo_handler.py", line 3, in <module>
2025-06-04T16:19:21,327 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:19:21,328 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,330 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:19:21,329 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:19:21,330 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:19:21,330 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:19:21,330 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:19:21,395 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:19:21,396 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,396 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,396 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,396 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,396 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:19:21,396 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,397 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:19:21,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:19:21,397 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:19:21,397 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,397 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,397 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,397 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8a565a0275064652bf42b9f7cdce9f79\yolo_handler.py", line 3, in <module>
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:19:21,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:19:21,399 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:19:21,449 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:19:21,449 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,450 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:19:21,450 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:19:21,450 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,450 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:19:21,450 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,450 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:19:21,450 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,450 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,450 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,450 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,450 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,450 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,450 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,450 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,451 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:19:21,451 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:19:21,451 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:19:21,451 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,451 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:19:21,451 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8b23f7411adc41b3b3fa195b0999462b\yolo_handler.py", line 3, in <module>
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:19:21,451 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:19:21,452 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,453 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,453 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,453 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:19:21,453 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:19:21,453 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:19:21,453 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:19:21,453 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:19:21,453 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:19:21,458 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:19:21,458 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,458 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:19:21,458 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:19:21,458 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:19:21,458 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,458 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:19:21,458 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,458 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,458 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,458 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,458 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,459 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,459 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,459 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:19:21,459 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,459 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,459 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:19:21,459 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:19:21,459 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,459 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,459 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:19:21,459 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:19:21,459 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:19:21,459 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,459 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:19:21,459 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:19:21,459 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,459 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:19:21,459 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,459 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,459 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:19:21,459 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:19:21,459 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,459 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,459 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,459 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:19:21,459 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:19:21,460 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2025-06-04T16:19:21,460 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:19:21,459 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\80cb1cb40b964ccfa5c4a07b493645f1\yolo_handler.py", line 3, in <module>
2025-06-04T16:19:21,460 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:19:21,460 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2025-06-04T16:19:21,460 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:19:21,460 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,460 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,460 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:19:21,460 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,460 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:19:21,460 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,460 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,460 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,460 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:19:21,460 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:19:21,460 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,460 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,460 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:19:21,460 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,460 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:19:21,460 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2025-06-04T16:19:21,460 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\487ec24610b34ac9bd1f225d030f2848\yolo_handler.py", line 3, in <module>
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:19:21,461 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:19:21,461 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:19:21,462 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:19:21,462 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:19:21,463 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:19:21,463 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:19:21,463 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:19:21,463 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:19:29,096 [ERROR] Thread-4 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2025-06-04T16:19:29,096 [ERROR] Thread-4 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):
  File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\metrics\metric_collector.py", line 27, in <module>
    system_metrics.collect_all(sys.modules['ts.metrics.system_metrics'], arguments.gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 119, in collect_all
    value(num_of_gpu)
  File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\metrics\system_metrics.py", line 64, in gpu_utilization
    import nvgpu
ModuleNotFoundError: No module named 'nvgpu'

2025-06-04T16:26:10,976 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-06-04T16:26:10,976 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-06-04T16:26:10,978 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-06-04T16:26:10,978 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-06-04T16:26:11,010 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
2025-06-04T16:26:11,010 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
2025-06-04T16:26:11,166 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.11.0
TS Home: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages
Current directory: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve
Temp directory: C:\Users\1\AppData\Local\Temp
Metrics config path: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 28
Max heap size: 8128 M
Python executable: C:\Users\1\anaconda3\envs\ts_yolo12\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
Initial Models: all
Log dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Metrics dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: true
Workflow Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2025-06-04T16:26:11,166 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.11.0
TS Home: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages
Current directory: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve
Temp directory: C:\Users\1\AppData\Local\Temp
Metrics config path: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 28
Max heap size: 8128 M
Python executable: C:\Users\1\anaconda3\envs\ts_yolo12\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
Initial Models: all
Log dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Metrics dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: true
Workflow Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2025-06-04T16:26:11,169 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-06-04T16:26:11,169 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-06-04T16:26:11,179 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: bamdinh.mar
2025-06-04T16:26:11,179 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: bamdinh.mar
2025-06-04T16:26:11,376 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model bamdinh
2025-06-04T16:26:11,376 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model bamdinh
2025-06-04T16:26:11,376 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model bamdinh
2025-06-04T16:26:11,376 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model bamdinh
2025-06-04T16:26:11,376 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model bamdinh loaded.
2025-06-04T16:26:11,376 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model bamdinh loaded.
2025-06-04T16:26:11,376 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: bamdinh, count: 1
2025-06-04T16:26:11,376 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: bamdinh, count: 1
2025-06-04T16:26:11,380 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: divatma.mar
2025-06-04T16:26:11,380 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: divatma.mar
2025-06-04T16:26:11,381 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:11,381 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:11,524 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model divatma
2025-06-04T16:26:11,524 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model divatma
2025-06-04T16:26:11,524 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model divatma
2025-06-04T16:26:11,524 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model divatma
2025-06-04T16:26:11,525 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model divatma loaded.
2025-06-04T16:26:11,525 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model divatma loaded.
2025-06-04T16:26:11,525 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: divatma, count: 1
2025-06-04T16:26:11,525 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: divatma, count: 1
2025-06-04T16:26:11,525 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: nganmach.mar
2025-06-04T16:26:11,525 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: nganmach.mar
2025-06-04T16:26:11,526 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:11,526 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:11,665 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nganmach
2025-06-04T16:26:11,665 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nganmach
2025-06-04T16:26:11,666 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nganmach
2025-06-04T16:26:11,666 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nganmach
2025-06-04T16:26:11,666 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nganmach loaded.
2025-06-04T16:26:11,666 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nganmach loaded.
2025-06-04T16:26:11,666 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nganmach, count: 1
2025-06-04T16:26:11,666 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nganmach, count: 1
2025-06-04T16:26:11,666 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: thieudong.mar
2025-06-04T16:26:11,666 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: thieudong.mar
2025-06-04T16:26:11,667 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:11,667 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:11,806 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model thieudong
2025-06-04T16:26:11,806 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model thieudong
2025-06-04T16:26:11,806 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model thieudong
2025-06-04T16:26:11,806 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model thieudong
2025-06-04T16:26:11,806 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model thieudong loaded.
2025-06-04T16:26:11,806 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model thieudong loaded.
2025-06-04T16:26:11,806 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: thieudong, count: 1
2025-06-04T16:26:11,806 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: thieudong, count: 1
2025-06-04T16:26:11,807 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: vetlom.mar
2025-06-04T16:26:11,807 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: vetlom.mar
2025-06-04T16:26:11,808 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:11,808 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:11,952 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vetlom
2025-06-04T16:26:11,952 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vetlom
2025-06-04T16:26:11,952 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vetlom
2025-06-04T16:26:11,952 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vetlom
2025-06-04T16:26:11,952 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vetlom loaded.
2025-06-04T16:26:11,952 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vetlom loaded.
2025-06-04T16:26:11,953 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vetlom, count: 1
2025-06-04T16:26:11,953 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vetlom, count: 1
2025-06-04T16:26:11,953 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: xuoc.mar
2025-06-04T16:26:11,953 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: xuoc.mar
2025-06-04T16:26:11,954 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:11,954 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:12,102 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model xuoc
2025-06-04T16:26:12,102 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model xuoc
2025-06-04T16:26:12,103 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model xuoc
2025-06-04T16:26:12,103 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model xuoc
2025-06-04T16:26:12,103 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model xuoc loaded.
2025-06-04T16:26:12,103 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model xuoc loaded.
2025-06-04T16:26:12,103 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: xuoc, count: 1
2025-06-04T16:26:12,103 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: xuoc, count: 1
2025-06-04T16:26:12,104 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:12,104 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:12,106 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2025-06-04T16:26:12,106 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2025-06-04T16:26:12,242 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-06-04T16:26:12,242 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-06-04T16:26:12,243 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2025-06-04T16:26:12,243 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2025-06-04T16:26:12,244 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2025-06-04T16:26:12,244 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2025-06-04T16:26:12,244 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2025-06-04T16:26:12,244 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2025-06-04T16:26:12,244 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2025-06-04T16:26:12,244 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2025-06-04T16:26:12,691 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:26:12,696 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:12,697 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]26156
2025-06-04T16:26:12,698 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:12,698 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:12,698 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:12,698 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:12,700 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:12,700 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:12,706 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:26:12,708 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029172708
2025-06-04T16:26:12,708 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029172708
2025-06-04T16:26:12,710 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029172710
2025-06-04T16:26:12,710 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029172710
2025-06-04T16:26:12,726 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:26:12,787 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:12,787 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:12,788 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:12,840 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:26:12,848 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:12,848 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]27136
2025-06-04T16:26:12,848 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:12,848 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:12,848 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:12,848 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:12,848 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:12,848 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:12,850 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029172850
2025-06-04T16:26:12,850 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029172850
2025-06-04T16:26:12,850 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029172850
2025-06-04T16:26:12,850 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:26:12,850 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029172850
2025-06-04T16:26:12,860 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:26:12,927 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:12,928 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:12,928 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:12,995 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:26:13,001 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:13,001 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]20872
2025-06-04T16:26:13,001 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:13,001 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:13,001 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:13,001 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:13,001 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:13,001 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:13,003 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029173003
2025-06-04T16:26:13,003 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029173003
2025-06-04T16:26:13,004 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029173004
2025-06-04T16:26:13,003 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:26:13,004 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029173004
2025-06-04T16:26:13,013 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:26:13,088 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:13,089 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:13,089 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:13,141 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:26:13,147 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:13,148 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]15316
2025-06-04T16:26:13,148 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:13,148 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:13,148 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:13,148 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:13,148 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:13,148 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:13,149 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029173149
2025-06-04T16:26:13,149 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029173149
2025-06-04T16:26:13,149 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029173149
2025-06-04T16:26:13,149 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:26:13,149 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029173149
2025-06-04T16:26:13,169 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:26:13,230 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:13,230 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:13,230 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:13,283 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:26:13,289 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:13,289 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]11212
2025-06-04T16:26:13,289 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:13,289 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:13,289 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:13,290 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:13,290 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:13,290 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:13,291 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029173291
2025-06-04T16:26:13,291 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:26:13,291 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029173291
2025-06-04T16:26:13,291 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029173291
2025-06-04T16:26:13,291 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029173291
2025-06-04T16:26:13,309 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:26:13,386 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:13,387 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:13,387 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:13,504 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:26:13,510 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:13,510 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]27268
2025-06-04T16:26:13,510 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:13,510 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:13,510 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change null -> WORKER_STARTED
2025-06-04T16:26:13,510 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:13,510 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:13,510 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:13,512 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029173512
2025-06-04T16:26:13,512 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:26:13,512 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029173512
2025-06-04T16:26:13,512 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029173512
2025-06-04T16:26:13,512 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029173512
2025-06-04T16:26:13,521 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:26:13,584 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:13,585 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:13,585 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:14,115 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:14,116 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,116 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:14,116 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:14,117 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:14,117 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,117 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:14,117 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,117 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,117 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,117 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,117 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,117 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,117 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,118 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:14,118 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:14,118 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:14,118 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,118 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:14,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:14,121 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:14,121 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:14,121 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:14,121 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:14,121 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:14,122 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:14,122 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:14,122 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:14,122 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,122 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,122 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,123 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,123 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:14,123 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,123 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,124 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,124 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:14,124 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:14,117 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,117 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,130 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:14,130 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:14,130 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,130 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,130 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174130
2025-06-04T16:26:14,130 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174130
2025-06-04T16:26:14,131 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:26:14,131 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:26:14,132 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:14,132 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:14,132 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:14,132 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:14,191 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:14,192 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,192 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,192 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:14,192 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,192 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:14,192 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,192 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:14,192 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,192 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:14,192 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,192 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,192 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,193 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,193 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:14,193 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,193 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174193
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174193
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:26:14,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:14,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:14,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:14,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:14,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,195 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:14,195 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:14,195 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:14,195 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:14,195 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:14,195 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:14,195 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:14,195 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:14,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:14,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:14,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:14,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:14,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:14,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:14,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:14,197 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:14,376 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:14,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,377 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:14,377 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:14,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:14,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:14,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,377 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,378 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:14,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,378 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:14,378 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,378 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:14,378 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,378 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174378
2025-06-04T16:26:14,378 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174378
2025-06-04T16:26:14,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:14,379 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:26:14,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:14,379 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:26:14,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:14,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:14,379 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:14,380 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,382 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,383 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:14,383 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:14,383 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:14,383 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:14,484 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:14,484 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,484 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:14,485 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:14,485 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,485 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:14,485 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,485 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:14,485 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,485 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,485 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,485 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,485 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,485 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,485 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,485 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:14,485 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,485 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:14,486 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:14,486 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174486
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174486
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,486 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:14,487 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:14,488 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:14,609 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:14,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:14,610 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:14,610 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:14,610 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,610 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:14,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,610 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,610 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,611 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:14,611 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:14,611 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,611 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174611
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174611
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:14,611 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:14,613 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,614 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,615 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:14,615 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:14,615 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:14,615 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:14,790 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:14,790 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,790 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:14,790 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:14,790 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,790 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:14,790 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:14,790 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:14,790 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,791 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,791 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:14,791 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,791 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,791 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,791 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:14,791 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,791 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174791
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029174791
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,791 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:14,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:14,793 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:15,139 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,139 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,198 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,198 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,381 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,381 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,492 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,492 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,617 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,617 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,800 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:15,800 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:16,405 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:26:16,411 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:16,411 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]31108
2025-06-04T16:26:16,411 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:16,411 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,411 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:16,411 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,412 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:16,412 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:16,413 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176413
2025-06-04T16:26:16,413 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176413
2025-06-04T16:26:16,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:26:16,413 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176413
2025-06-04T16:26:16,413 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176413
2025-06-04T16:26:16,437 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:26:16,475 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:26:16,481 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:16,481 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]30084
2025-06-04T16:26:16,481 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,481 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:16,481 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,482 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:16,482 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:16,482 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:16,482 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176482
2025-06-04T16:26:16,482 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176482
2025-06-04T16:26:16,483 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176483
2025-06-04T16:26:16,482 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:26:16,483 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176483
2025-06-04T16:26:16,497 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:26:16,501 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:16,501 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:16,502 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:16,556 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:16,556 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:16,557 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:16,655 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:26:16,661 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:16,661 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]7528
2025-06-04T16:26:16,661 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:16,661 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,661 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,661 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:16,661 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:16,661 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:16,663 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176663
2025-06-04T16:26:16,663 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:26:16,663 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176663
2025-06-04T16:26:16,664 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176663
2025-06-04T16:26:16,664 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176663
2025-06-04T16:26:16,684 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:26:16,743 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:16,744 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:16,744 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:16,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:26:16,809 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:16,809 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]24020
2025-06-04T16:26:16,809 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:16,809 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,809 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,809 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:16,810 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:16,810 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:16,811 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176811
2025-06-04T16:26:16,811 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176811
2025-06-04T16:26:16,811 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:26:16,811 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176811
2025-06-04T16:26:16,811 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176811
2025-06-04T16:26:16,823 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:26:16,887 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:16,887 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:16,888 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:16,936 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:26:16,941 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:16,941 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]27504
2025-06-04T16:26:16,941 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:16,941 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,941 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:16,941 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:16,942 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:16,942 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:16,943 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176943
2025-06-04T16:26:16,943 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029176943
2025-06-04T16:26:16,943 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:26:16,943 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176943
2025-06-04T16:26:16,943 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029176943
2025-06-04T16:26:16,961 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:26:17,021 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:17,021 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:17,021 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:17,117 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:26:17,123 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:17,123 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]9392
2025-06-04T16:26:17,123 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:17,123 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:17,123 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:17,124 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:17,124 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:17,124 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:17,125 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029177125
2025-06-04T16:26:17,125 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029177125
2025-06-04T16:26:17,125 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:26:17,125 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029177125
2025-06-04T16:26:17,125 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029177125
2025-06-04T16:26:17,145 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:26:17,207 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:17,207 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:17,207 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:17,774 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:17,774 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:17,774 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:17,774 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:17,774 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:17,774 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:17,774 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:17,774 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:17,775 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:17,775 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:17,775 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:17,775 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:17,775 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:17,775 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:17,775 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:17,775 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:17,775 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:17,775 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:17,775 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:17,775 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:17,775 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:17,775 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:17,775 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:17,775 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:17,776 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:17,777 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:17,778 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:17,778 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:17,778 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:17,778 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:17,778 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:17,778 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:17,778 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:17,778 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:17,830 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:17,831 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:17,831 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:17,831 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:17,831 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:17,831 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:17,831 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:17,831 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:17,831 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:17,831 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:17,831 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:17,831 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:17,831 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:17,831 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:17,832 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:17,833 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:17,834 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:17,835 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:17,835 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:17,835 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:17,835 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:17,835 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:18,012 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:18,013 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:18,013 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:18,013 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:18,013 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:18,013 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:18,013 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:18,013 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:18,013 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:18,013 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:18,013 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:18,013 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:18,013 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:18,014 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:18,014 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:18,014 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:18,014 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:18,014 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:18,014 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,014 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:18,014 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,014 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:18,014 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:18,014 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:26:18,014 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:18,014 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:26:18,014 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:18,015 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,016 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,017 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:18,017 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:18,017 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,017 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,017 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:18,017 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:18,017 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:18,017 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:18,118 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:18,118 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:18,119 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:18,119 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:18,119 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:18,119 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:18,119 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,119 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,119 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:18,119 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:18,119 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:18,119 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:18,119 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:18,119 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:18,119 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:18,120 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:18,121 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:18,257 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:18,258 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:18,258 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:18,258 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:18,258 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,258 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,258 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:18,258 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:18,258 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:18,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:18,259 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:18,259 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:18,259 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:18,259 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:26:18,259 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:18,260 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:18,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:18,261 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:18,261 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:18,261 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:18,261 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:18,261 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:18,408 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:18,409 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:18,409 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:18,409 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:18,409 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:18,409 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:18,409 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:18,409 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:18,409 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:18,409 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:18,410 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:18,410 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:18,410 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:18,410 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:18,410 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:18,411 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:18,793 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:18,793 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:18,836 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:18,836 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:19,023 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:19,023 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:19,132 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:19,132 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:19,270 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:19,270 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:19,411 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:19,411 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:20,063 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:26:20,066 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:26:20,069 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:20,069 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]33484
2025-06-04T16:26:20,069 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:20,069 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,069 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,069 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:20,069 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:20,069 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:20,070 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180070
2025-06-04T16:26:20,070 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:26:20,070 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180070
2025-06-04T16:26:20,070 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180070
2025-06-04T16:26:20,070 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180070
2025-06-04T16:26:20,073 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:20,073 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]29100
2025-06-04T16:26:20,073 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,073 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:20,073 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,073 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:20,074 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:20,074 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:20,076 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180076
2025-06-04T16:26:20,076 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:26:20,076 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180076
2025-06-04T16:26:20,077 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180077
2025-06-04T16:26:20,077 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180077
2025-06-04T16:26:20,095 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:26:20,098 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:26:20,154 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:20,155 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:20,156 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:20,157 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:20,157 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:20,157 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:20,268 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:26:20,274 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:20,274 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]3872
2025-06-04T16:26:20,274 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:20,274 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,274 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,274 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:20,274 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:20,274 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:20,276 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180276
2025-06-04T16:26:20,276 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180276
2025-06-04T16:26:20,276 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180276
2025-06-04T16:26:20,276 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:26:20,276 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180276
2025-06-04T16:26:20,301 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:26:20,358 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:20,358 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:20,359 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:20,374 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:26:20,380 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:20,380 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]15852
2025-06-04T16:26:20,380 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:20,380 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,380 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,380 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:20,380 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:20,380 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:20,381 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180381
2025-06-04T16:26:20,381 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:26:20,381 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180381
2025-06-04T16:26:20,381 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180381
2025-06-04T16:26:20,381 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180381
2025-06-04T16:26:20,394 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:26:20,453 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:20,453 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:20,453 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:20,516 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:26:20,522 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:20,522 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]9960
2025-06-04T16:26:20,522 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:20,522 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,522 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:20,522 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,523 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:20,523 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:20,524 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180524
2025-06-04T16:26:20,524 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:26:20,524 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180524
2025-06-04T16:26:20,524 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180524
2025-06-04T16:26:20,524 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180524
2025-06-04T16:26:20,551 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:26:20,609 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:20,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:20,610 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:20,677 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:26:20,683 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:20,683 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]32396
2025-06-04T16:26:20,683 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,683 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:20,683 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:20,683 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:20,683 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:20,683 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:20,684 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180684
2025-06-04T16:26:20,684 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029180684
2025-06-04T16:26:20,684 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180684
2025-06-04T16:26:20,684 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:26:20,684 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029180684
2025-06-04T16:26:20,709 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:26:20,768 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:20,768 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:20,768 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:21,432 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:21,433 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,433 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,433 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,433 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:21,433 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,433 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,433 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:21,434 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:21,434 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:21,434 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,434 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,434 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:21,434 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:21,434 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,436 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,437 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,437 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:21,437 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:21,437 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:21,437 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:21,437 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:21,437 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:21,447 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:21,447 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,447 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:21,447 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:21,447 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:21,447 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:21,447 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,447 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,447 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,447 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,448 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,448 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,448 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:21,448 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:21,448 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,448 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:21,449 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,448 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:21,449 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,449 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,449 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:21,449 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:21,450 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:21,451 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:21,451 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:21,451 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:21,451 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:21,584 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:21,584 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,584 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:21,584 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:21,584 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:21,584 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:21,584 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,584 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,585 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,585 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,585 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,585 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,585 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,585 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,585 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,585 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,585 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:21,585 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:21,585 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:21,585 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:21,585 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,585 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:21,585 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,585 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,585 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,585 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:21,586 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:21,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,588 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,588 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:21,588 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:21,588 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:21,588 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:21,701 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:21,701 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,701 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:21,702 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:21,702 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:21,702 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,702 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:21,702 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,702 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,702 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,702 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,702 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,702 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,702 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,702 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:21,702 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,702 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:21,703 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,703 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,703 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:21,703 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:21,703 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:21,704 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:21,705 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,705 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,705 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,705 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:21,705 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:21,705 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:21,705 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:21,844 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:21,844 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,844 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:21,844 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:21,844 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:21,844 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:21,844 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,844 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,845 [INFO ] nioEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:21,845 [INFO ] nioEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:21,845 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:21,845 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:21,845 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:21,845 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:21,845 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:21,845 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:21,845 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:21,845 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:21,845 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:21,845 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:21,845 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:21,846 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:21,847 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:21,847 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:21,847 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:21,847 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:21,847 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:21,847 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:22,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:22,007 [INFO ] nioEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:22,007 [INFO ] nioEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:22,008 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:22,008 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:22,008 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:22,008 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:22,008 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:22,008 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:22,008 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:22,008 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:22,008 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:22,008 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-06-04T16:26:22,008 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:22,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:22,010 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:22,010 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:22,010 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:22,010 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:23,451 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:23,451 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:23,464 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:23,464 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:23,591 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:23,591 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:23,714 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:23,714 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:23,856 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:23,856 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:24,011 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:24,011 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:24,702 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:26:24,702 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:26:24,708 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:24,708 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]16068
2025-06-04T16:26:24,708 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:24,708 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:24,708 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:24,708 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:24,708 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:24,708 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]10992
2025-06-04T16:26:24,709 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:24,709 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:24,709 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:24,709 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:24,709 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:24,709 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:24,709 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:24,709 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:24,710 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029184710
2025-06-04T16:26:24,710 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029184710
2025-06-04T16:26:24,710 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:26:24,710 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029184710
2025-06-04T16:26:24,710 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029184710
2025-06-04T16:26:24,710 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029184710
2025-06-04T16:26:24,710 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:26:24,710 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029184710
2025-06-04T16:26:24,710 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029184710
2025-06-04T16:26:24,710 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029184710
2025-06-04T16:26:24,734 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:26:24,734 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:26:24,795 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:24,795 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:24,796 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:24,796 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:24,796 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:24,796 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:24,837 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:26:24,843 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:24,843 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]29196
2025-06-04T16:26:24,843 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:24,843 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:24,843 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:24,843 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:24,843 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:24,843 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:24,845 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029184845
2025-06-04T16:26:24,844 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:26:24,845 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029184845
2025-06-04T16:26:24,845 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029184845
2025-06-04T16:26:24,845 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029184845
2025-06-04T16:26:24,860 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:26:24,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:24,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:24,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:24,965 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:26:24,970 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:24,971 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]25836
2025-06-04T16:26:24,971 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:24,971 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:24,971 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:24,971 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:24,971 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:24,971 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:24,972 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029184972
2025-06-04T16:26:24,972 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:26:24,972 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029184972
2025-06-04T16:26:24,972 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029184972
2025-06-04T16:26:24,972 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029184972
2025-06-04T16:26:24,986 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:26:25,048 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:25,048 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:25,048 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:25,124 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:26:25,129 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:25,130 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]27844
2025-06-04T16:26:25,130 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:25,130 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:25,130 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:25,130 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:25,130 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:25,130 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:25,131 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029185131
2025-06-04T16:26:25,131 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:26:25,131 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029185131
2025-06-04T16:26:25,131 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029185131
2025-06-04T16:26:25,131 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029185131
2025-06-04T16:26:25,160 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:26:25,218 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:25,218 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:25,218 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:25,296 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:26:25,302 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:25,302 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]31492
2025-06-04T16:26:25,302 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:25,302 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:25,302 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:25,302 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:25,303 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:25,303 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:25,304 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029185304
2025-06-04T16:26:25,304 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029185304
2025-06-04T16:26:25,304 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029185304
2025-06-04T16:26:25,304 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:26:25,304 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029185304
2025-06-04T16:26:25,330 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:26:25,388 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:25,389 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:25,389 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:26,082 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:26,082 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,082 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:26,082 [INFO ] nioEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,082 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:26,082 [INFO ] nioEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,082 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:26,082 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,082 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,082 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:26,082 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,082 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,082 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,082 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,083 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,083 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:26,083 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,083 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,083 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:26,083 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:26,083 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:26,084 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,085 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,086 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,086 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:26,086 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,086 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,086 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,086 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:26,086 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:26,086 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:26,086 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:26,100 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:26,100 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,100 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:26,100 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:26,100 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:26,100 [INFO ] nioEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:26,100 [INFO ] nioEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,101 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,101 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,101 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:26,101 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:26,102 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:26,102 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:26,102 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,102 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:26,102 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,102 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,102 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,102 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,102 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:26,102 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:26,103 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,104 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,105 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,105 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:26,105 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:26,105 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:26,105 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:26,105 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:26,105 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:26,169 [INFO ] nioEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,169 [INFO ] nioEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,169 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,169 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:26,169 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,169 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:26,169 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,170 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:26,170 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:26,170 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:26,170 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,170 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:26,170 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:26,170 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:26,171 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,172 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,172 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,172 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:26,172 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:26,172 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:26,172 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:26,172 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:26,172 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:26,305 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:26,305 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,305 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:26,305 [INFO ] nioEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,305 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:26,305 [INFO ] nioEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:26,306 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:26,306 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,306 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,306 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,306 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,306 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:26,306 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:26,306 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,306 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:26,306 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:26,306 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,307 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:26,308 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:26,477 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:26,477 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,477 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:26,477 [INFO ] nioEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,477 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:26,477 [INFO ] nioEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,477 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,478 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,478 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,478 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,478 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:26,478 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:26,478 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:26,478 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:26,478 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,478 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,478 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-06-04T16:26:26,478 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,479 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:26,480 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:26,626 [INFO ] nioEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:26,626 [INFO ] nioEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:26,626 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,626 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:26,626 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,626 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:26,626 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:26,627 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:26,627 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:26,627 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:26,627 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:26,627 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:26,627 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-06-04T16:26:26,627 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:26,628 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:26,629 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:26,629 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:26,629 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:26,629 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:29,102 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,102 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,114 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,114 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,178 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,178 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,316 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,316 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,487 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,487 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,644 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:29,644 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:30,361 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:26:30,365 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:26:30,368 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:30,368 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]33720
2025-06-04T16:26:30,369 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:30,369 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,369 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:30,369 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,369 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:30,369 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:30,370 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190370
2025-06-04T16:26:30,370 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190370
2025-06-04T16:26:30,370 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190370
2025-06-04T16:26:30,370 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:26:30,370 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190370
2025-06-04T16:26:30,373 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:30,373 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]31280
2025-06-04T16:26:30,373 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:30,373 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,373 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,373 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:30,373 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:30,373 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:30,376 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190376
2025-06-04T16:26:30,376 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:26:30,376 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190376
2025-06-04T16:26:30,376 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190376
2025-06-04T16:26:30,376 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190376
2025-06-04T16:26:30,393 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:26:30,411 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:26:30,416 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:26:30,423 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:30,423 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]6172
2025-06-04T16:26:30,423 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,423 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:30,423 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,423 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:30,423 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:30,423 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:30,424 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190424
2025-06-04T16:26:30,424 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190424
2025-06-04T16:26:30,424 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:26:30,424 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190424
2025-06-04T16:26:30,424 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190424
2025-06-04T16:26:30,439 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:26:30,454 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:30,455 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:30,455 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:30,473 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:30,473 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:30,473 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:30,497 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:30,497 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:30,497 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:30,556 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:26:30,562 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:30,562 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]5132
2025-06-04T16:26:30,563 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,563 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:30,563 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,563 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:30,563 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:30,563 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:30,564 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190564
2025-06-04T16:26:30,564 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190564
2025-06-04T16:26:30,564 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190564
2025-06-04T16:26:30,564 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:26:30,564 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190564
2025-06-04T16:26:30,579 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:26:30,639 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:30,640 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:30,640 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:30,745 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:26:30,751 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:30,751 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]3108
2025-06-04T16:26:30,751 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,751 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:30,751 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,752 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:30,752 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:30,752 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:30,754 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190754
2025-06-04T16:26:30,754 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190754
2025-06-04T16:26:30,754 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190754
2025-06-04T16:26:30,754 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:26:30,754 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190754
2025-06-04T16:26:30,767 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:26:30,824 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:30,824 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:30,824 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:30,909 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:26:30,915 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:30,915 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]13452
2025-06-04T16:26:30,916 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,916 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:30,916 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:30,916 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:30,916 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:30,916 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:30,918 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190918
2025-06-04T16:26:30,918 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:26:30,918 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029190918
2025-06-04T16:26:30,918 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190918
2025-06-04T16:26:30,918 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029190918
2025-06-04T16:26:30,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:26:30,990 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:30,990 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:30,991 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:31,748 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:31,748 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:31,748 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:31,749 [INFO ] nioEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:31,749 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:31,749 [INFO ] nioEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:31,749 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:31,749 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:31,749 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:31,749 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:31,749 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:31,749 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:31,749 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:31,749 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,749 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:31,749 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:31,749 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,749 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:31,749 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:31,749 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:31,749 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:31,749 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:31,750 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:31,750 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:31,750 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,751 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:31,752 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:31,752 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,752 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,752 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:31,752 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:31,752 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:31,752 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:31,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:31,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:31,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:31,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:31,759 [INFO ] nioEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:31,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:31,759 [INFO ] nioEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:31,759 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:31,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:31,759 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:31,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:31,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:31,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,759 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:31,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:31,759 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:31,760 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:31,760 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:31,760 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:31,760 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:31,760 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:31,760 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-06-04T16:26:31,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:31,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:31,762 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,762 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,762 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:31,762 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:31,762 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,762 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,762 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:31,762 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:31,764 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:31,764 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:31,764 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:31,764 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:31,768 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:31,768 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:31,768 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:31,768 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:31,768 [INFO ] nioEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:31,768 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:31,768 [INFO ] nioEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:31,768 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:31,768 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:31,768 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:31,768 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:31,769 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:31,769 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,769 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:31,769 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:31,769 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,769 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:31,769 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:31,769 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:31,769 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:31,769 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:31,769 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:31,769 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:31,769 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:31,769 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:31,769 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:31,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:31,771 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:31,771 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:31,771 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:31,771 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:31,771 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:31,771 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:31,771 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:31,771 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:31,771 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:31,772 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:31,872 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:31,872 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:31,872 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:31,872 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:31,872 [INFO ] nioEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:31,872 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:31,872 [INFO ] nioEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:31,872 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:31,872 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:31,872 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:31,872 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:31,872 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:31,872 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,872 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,873 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:31,873 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:31,873 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:31,873 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:31,873 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:31,873 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:31,873 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:31,874 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:31,875 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:32,059 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:32,059 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:32,059 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:32,059 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:32,059 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:32,059 [INFO ] nioEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:32,059 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:32,059 [INFO ] nioEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:32,060 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:32,059 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:32,060 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:32,060 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:32,060 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:32,060 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:32,060 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:32,060 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:32,060 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:32,060 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:32,060 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:32,060 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:32,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:32,062 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:32,193 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:32,193 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:32,193 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:32,194 [INFO ] nioEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:32,194 [INFO ] nioEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:32,194 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:32,194 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:32,194 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:32,194 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:32,194 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:32,194 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:32,194 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:32,194 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:32,194 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:32,194 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:32,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:32,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:32,196 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:32,197 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:32,197 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:32,197 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:36,758 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:36,758 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:36,774 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:36,774 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:36,775 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:36,775 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:36,880 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:36,880 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:37,069 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:37,069 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:37,211 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:37,211 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:38,042 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:26:38,048 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:38,049 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]20296
2025-06-04T16:26:38,049 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,049 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:38,049 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,049 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:38,049 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:38,049 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:38,050 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:26:38,050 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:26:38,051 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198051
2025-06-04T16:26:38,051 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198051
2025-06-04T16:26:38,051 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198051
2025-06-04T16:26:38,051 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198051
2025-06-04T16:26:38,059 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:38,059 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]1884
2025-06-04T16:26:38,059 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:38,059 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,059 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:38,059 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,060 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:38,060 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:38,065 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:26:38,065 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198065
2025-06-04T16:26:38,065 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:26:38,065 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198065
2025-06-04T16:26:38,065 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:26:38,065 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198065
2025-06-04T16:26:38,065 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198065
2025-06-04T16:26:38,080 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:38,080 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]9920
2025-06-04T16:26:38,080 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:38,080 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:38,080 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,080 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,081 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:38,081 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:26:38,081 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:38,082 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198082
2025-06-04T16:26:38,082 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198082
2025-06-04T16:26:38,082 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198082
2025-06-04T16:26:38,082 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:26:38,082 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198082
2025-06-04T16:26:38,094 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:26:38,135 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:38,135 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:38,135 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:38,145 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:38,145 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:38,145 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:38,156 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:38,156 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:38,157 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:38,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:26:38,199 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:38,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]18804
2025-06-04T16:26:38,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:38,200 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:38,200 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,200 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:38,200 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:38,202 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198202
2025-06-04T16:26:38,202 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:26:38,202 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198202
2025-06-04T16:26:38,202 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198202
2025-06-04T16:26:38,202 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198202
2025-06-04T16:26:38,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:26:38,279 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:38,279 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:38,279 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:38,376 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:26:38,381 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:38,382 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]22960
2025-06-04T16:26:38,382 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:38,382 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:38,382 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,382 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,382 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:38,382 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:38,384 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198384
2025-06-04T16:26:38,384 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:26:38,384 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198384
2025-06-04T16:26:38,384 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198384
2025-06-04T16:26:38,384 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198384
2025-06-04T16:26:38,395 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:26:38,453 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:38,453 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:38,453 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:38,517 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:26:38,523 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:38,523 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]22080
2025-06-04T16:26:38,524 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:38,524 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,524 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:38,524 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:38,524 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:38,524 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:38,525 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198525
2025-06-04T16:26:38,525 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029198525
2025-06-04T16:26:38,525 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:26:38,525 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198525
2025-06-04T16:26:38,525 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029198525
2025-06-04T16:26:38,532 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:26:38,593 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:38,593 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:38,593 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:39,437 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:39,437 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:39,437 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,437 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,437 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:39,437 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:39,438 [INFO ] nioEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,438 [INFO ] nioEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,437 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:39,438 [INFO ] nioEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,437 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,438 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:39,438 [INFO ] nioEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,438 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,438 [INFO ] nioEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,438 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,438 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,438 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:39,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:39,438 [INFO ] nioEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,438 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,439 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,438 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:39,439 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,438 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:39,438 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,439 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:39,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:39,439 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,439 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,439 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:39,439 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,439 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,439 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:39,439 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:39,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:39,438 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,439 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:39,439 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:39,439 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,439 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:39,439 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,439 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,439 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,439 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:39,439 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:39,440 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,440 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,440 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,440 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,440 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,440 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,440 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,440 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,440 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,440 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,440 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,440 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,440 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2025-06-04T16:26:39,440 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:39,439 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,440 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:39,441 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,440 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2025-06-04T16:26:39,441 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,440 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:39,441 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:39,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:39,441 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:39,441 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:39,441 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2025-06-04T16:26:39,441 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2025-06-04T16:26:39,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:39,441 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,441 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2025-06-04T16:26:39,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,441 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2025-06-04T16:26:39,441 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:39,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:39,441 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:39,441 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:39,441 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:39,442 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:39,442 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:39,442 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:39,442 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:39,442 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,442 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,442 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:39,442 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:39,442 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:39,442 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,442 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,442 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,442 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:39,442 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,442 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,442 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,442 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:39,442 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:39,442 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:39,442 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,443 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:39,443 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:39,443 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:39,443 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:39,443 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:39,443 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:39,443 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:39,443 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:39,443 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:39,443 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:39,443 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:39,443 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:39,443 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:39,443 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:39,443 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:39,443 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:39,443 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:39,443 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:39,443 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:39,443 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:39,443 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:39,444 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:39,444 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:39,444 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:39,444 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:39,444 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:39,444 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:39,444 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:39,444 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:39,444 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:39,444 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:39,444 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:39,444 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:39,444 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:39,444 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:39,444 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:39,445 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:39,445 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,445 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,445 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:39,445 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,445 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:39,445 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,445 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,445 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,445 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,445 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:39,445 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,445 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,445 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,445 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,445 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,445 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,445 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,445 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:39,445 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:39,446 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,446 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,446 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,446 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:39,446 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:39,447 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:39,446 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,446 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,447 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:39,447 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,447 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,447 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:39,447 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:39,447 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:39,447 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:39,447 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:39,447 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:39,447 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:39,447 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,511 [INFO ] nioEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,511 [INFO ] nioEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,511 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:39,511 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:39,511 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:39,511 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,512 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:39,512 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:39,512 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,512 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,512 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:39,512 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,512 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:39,514 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:39,514 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:39,513 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:39,514 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,671 [INFO ] nioEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:39,671 [INFO ] nioEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,671 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,671 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:39,671 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,671 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,671 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:39,672 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:39,672 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:39,672 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:39,672 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,672 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:39,672 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:39,672 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:39,673 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:39,791 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,792 [INFO ] nioEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:39,792 [INFO ] nioEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:39,792 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,792 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,792 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:39,793 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:39,793 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:39,793 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:39,793 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:39,793 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:39,793 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:39,793 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,793 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:39,793 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:39,794 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:39,795 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:39,795 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:39,795 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:39,795 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:47,447 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,448 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,447 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,448 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,448 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,448 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,521 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,521 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,677 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,677 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,801 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:47,801 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:26:48,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:26:48,771 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:26:48,775 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:26:48,775 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:48,776 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]25904
2025-06-04T16:26:48,776 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:48,776 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,776 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:48,776 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,776 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:48,776 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:26:48,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:48,777 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208777
2025-06-04T16:26:48,777 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208777
2025-06-04T16:26:48,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]3620
2025-06-04T16:26:48,777 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208777
2025-06-04T16:26:48,778 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,777 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208777
2025-06-04T16:26:48,777 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:26:48,778 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,777 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:48,780 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:48,780 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:48,780 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:26:48,782 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208782
2025-06-04T16:26:48,782 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208782
2025-06-04T16:26:48,784 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208784
2025-06-04T16:26:48,784 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208784
2025-06-04T16:26:48,784 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:26:48,799 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:48,799 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]31668
2025-06-04T16:26:48,799 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,799 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:48,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:26:48,799 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:48,799 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:48,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]3512
2025-06-04T16:26:48,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:48,799 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:48,799 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:48,799 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,800 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:48,799 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:26:48,800 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:26:48,802 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208802
2025-06-04T16:26:48,802 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208802
2025-06-04T16:26:48,802 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208802
2025-06-04T16:26:48,802 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208802
2025-06-04T16:26:48,802 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:26:48,802 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:26:48,802 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208802
2025-06-04T16:26:48,802 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208802
2025-06-04T16:26:48,804 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208804
2025-06-04T16:26:48,804 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208804
2025-06-04T16:26:48,804 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:26:48,813 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:26:48,817 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:26:48,817 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:26:48,866 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:48,866 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:48,867 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:48,874 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:48,874 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:48,874 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:48,877 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:48,877 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:48,877 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:48,877 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:48,877 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:48,877 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:48,930 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:26:48,938 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:48,938 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]18548
2025-06-04T16:26:48,938 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:48,938 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:48,938 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,938 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:48,938 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:48,938 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:26:48,939 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208939
2025-06-04T16:26:48,939 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:26:48,939 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029208939
2025-06-04T16:26:48,939 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208939
2025-06-04T16:26:48,939 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029208939
2025-06-04T16:26:48,955 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:26:49,018 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:49,019 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:49,019 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:49,078 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:26:49,085 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:26:49,085 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]31692
2025-06-04T16:26:49,085 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:49,085 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:26:49,085 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:26:49,085 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:26:49,085 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:49,085 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:26:49,087 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029209086
2025-06-04T16:26:49,087 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:26:49,087 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029209086
2025-06-04T16:26:49,087 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029209087
2025-06-04T16:26:49,087 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029209087
2025-06-04T16:26:49,114 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:26:49,173 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:26:49,174 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:26:49,174 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:26:50,219 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:50,219 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:50,219 [INFO ] nioEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,219 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:50,219 [INFO ] nioEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,219 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,219 [INFO ] nioEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,219 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,219 [INFO ] nioEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,219 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:50,219 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,219 [INFO ] nioEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,219 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,219 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,219 [INFO ] nioEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,219 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:50,219 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,219 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,219 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:50,219 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,219 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,219 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:50,219 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,219 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,219 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,219 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,219 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:50,219 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:50,219 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:50,219 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:26:50,220 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,219 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,219 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:50,220 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:50,220 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:26:50,220 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,219 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,220 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:50,220 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,220 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,220 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,219 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:50,219 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:50,220 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,220 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,220 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:26:50,220 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,220 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,220 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,220 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,220 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:50,220 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2025-06-04T16:26:50,220 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:50,220 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2025-06-04T16:26:50,220 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,220 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,221 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,220 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,221 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,220 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:50,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:50,221 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,221 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:50,221 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2025-06-04T16:26:50,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,221 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2025-06-04T16:26:50,221 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,221 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:50,221 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2025-06-04T16:26:50,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,221 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,221 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2025-06-04T16:26:50,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,221 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:50,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:50,221 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,221 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:50,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:50,221 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:50,221 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:50,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:50,222 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,221 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:50,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,222 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:50,222 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:50,222 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,222 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:50,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:50,222 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:50,222 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:50,222 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:50,222 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,222 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:50,222 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:50,222 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:50,222 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:50,222 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:26:50,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,222 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:50,224 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:50,222 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:26:50,224 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:50,222 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:50,224 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,224 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:50,224 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,224 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:50,224 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:26:50,224 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,224 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,224 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:50,224 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:50,224 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:50,224 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:50,224 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:50,224 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:50,224 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:50,225 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:50,225 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:50,225 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:50,225 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:50,225 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:50,225 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:50,225 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:50,225 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:50,225 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:50,225 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:50,225 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:50,225 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:50,225 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:50,225 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:50,225 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:50,225 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:50,225 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,225 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:50,225 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,225 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:50,225 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:50,226 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,226 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:50,226 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,226 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:50,226 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:50,226 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:50,226 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,226 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:50,226 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,226 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,226 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:50,226 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,226 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,226 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:50,226 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,226 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,226 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:50,226 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,227 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:50,226 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:50,227 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:50,227 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,227 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:26:50,227 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,227 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,227 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,227 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,227 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,227 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:50,227 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:50,227 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,227 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:50,227 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:50,227 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,227 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:26:50,227 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,227 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:50,228 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:50,228 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:50,228 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,239 [INFO ] nioEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,239 [INFO ] nioEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:50,239 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,239 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:50,239 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,240 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:50,240 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,240 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:50,240 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:50,240 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,240 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:50,240 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,240 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,240 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:50,240 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:26:50,240 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,240 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:50,240 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,240 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,240 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,240 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:50,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:50,243 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:50,243 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:50,243 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:26:50,243 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,267 [INFO ] nioEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,267 [INFO ] nioEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,267 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:50,267 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:50,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:50,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,267 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:50,267 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:50,268 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:50,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:50,268 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:26:50,268 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,268 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,268 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:50,268 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,270 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,270 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,270 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:50,270 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,270 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,270 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,270 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:50,270 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:50,271 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:50,271 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:50,271 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:26:50,271 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,400 [INFO ] nioEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,400 [INFO ] nioEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,400 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,400 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:26:50,400 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:26:50,400 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,400 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:26:50,401 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:26:50,401 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:26:50,401 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:26:50,401 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:26:50,401 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,401 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:26:50,401 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:26:50,402 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:26:50,402 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:26:50,402 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:26:50,402 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:26:50,402 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,402 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,402 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:26:50,402 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:26:50,403 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:26:50,403 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:26:50,403 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:26:50,403 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:26:50,403 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:50,403 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:26:50,403 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:26:50,403 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:27:03,227 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,227 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,227 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,227 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,228 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,228 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,243 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,243 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,273 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,273 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,410 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:03,410 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:04,550 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:27:04,551 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:27:04,553 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:27:04,555 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:04,555 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]10176
2025-06-04T16:27:04,555 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:04,555 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,555 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:04,555 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,556 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:27:04,556 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:27:04,557 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224557
2025-06-04T16:27:04,557 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:04,557 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224557
2025-06-04T16:27:04,557 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:27:04,557 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224557
2025-06-04T16:27:04,557 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224557
2025-06-04T16:27:04,557 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]26600
2025-06-04T16:27:04,557 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,557 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:04,557 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,558 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:27:04,557 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:04,558 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:27:04,558 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:27:04,561 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224561
2025-06-04T16:27:04,561 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224561
2025-06-04T16:27:04,561 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224561
2025-06-04T16:27:04,561 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224561
2025-06-04T16:27:04,561 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:27:04,561 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:04,562 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]5128
2025-06-04T16:27:04,562 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,562 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:04,562 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,562 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:04,562 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:27:04,562 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:27:04,571 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:04,571 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:27:04,571 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:27:04,571 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]24992
2025-06-04T16:27:04,571 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,571 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:04,571 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224571
2025-06-04T16:27:04,571 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,571 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:04,573 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:27:04,573 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:27:04,571 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224571
2025-06-04T16:27:04,573 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224573
2025-06-04T16:27:04,573 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224573
2025-06-04T16:27:04,586 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:27:04,586 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:04,586 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]20852
2025-06-04T16:27:04,586 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:04,586 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,586 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:04,586 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,586 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224586
2025-06-04T16:27:04,587 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:27:04,586 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224586
2025-06-04T16:27:04,587 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:27:04,587 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224587
2025-06-04T16:27:04,587 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224587
2025-06-04T16:27:04,587 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:27:04,587 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:27:04,589 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224589
2025-06-04T16:27:04,589 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224589
2025-06-04T16:27:04,589 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224589
2025-06-04T16:27:04,589 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224589
2025-06-04T16:27:04,589 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:27:04,604 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:27:04,617 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:27:04,618 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:27:04,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:04,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:04,651 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:04,651 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:04,651 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:04,651 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:04,664 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:04,664 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:04,665 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:04,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:04,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:04,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:04,676 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:04,677 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:04,677 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:04,683 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:27:04,689 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:04,689 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]12180
2025-06-04T16:27:04,689 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,689 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:04,689 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:04,689 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:04,690 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:27:04,690 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:27:04,691 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224691
2025-06-04T16:27:04,691 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:27:04,691 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029224691
2025-06-04T16:27:04,691 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224691
2025-06-04T16:27:04,691 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029224691
2025-06-04T16:27:04,713 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:27:04,774 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:04,775 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:04,775 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:05,987 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:05,987 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:05,987 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:05,987 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:05,987 [INFO ] nioEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:05,987 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:05,987 [INFO ] nioEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:05,988 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:05,988 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:05,988 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:05,988 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:05,988 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:27:05,988 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:27:05,988 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:05,988 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:05,988 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:05,988 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:05,988 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:05,989 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:05,989 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:05,989 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:05,989 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:05,989 [INFO ] nioEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:05,989 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:05,989 [INFO ] nioEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:05,989 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:05,989 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:05,989 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:05,989 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:05,989 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:05,989 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:05,989 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:05,989 [INFO ] nioEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:05,989 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:05,989 [INFO ] nioEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:05,989 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:05,989 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:05,990 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:05,990 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:05,989 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:05,990 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:05,990 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:05,990 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:27:05,990 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:05,990 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:05,990 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:27:05,990 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:05,990 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:05,990 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:05,990 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:05,990 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:05,990 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:05,990 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:05,990 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:05,990 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:05,990 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:27:05,990 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:05,990 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:05,990 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:05,990 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:05,990 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:05,990 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:05,991 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2025-06-04T16:27:05,990 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:27:05,991 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:05,991 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2025-06-04T16:27:05,991 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:05,991 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:05,991 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:05,991 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:05,991 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:05,991 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:05,991 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:05,991 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:05,991 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:05,991 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:27:05,991 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:05,991 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2025-06-04T16:27:05,991 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:05,991 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2025-06-04T16:27:05,991 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:05,991 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:05,991 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:27:05,991 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:05,991 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:05,992 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:05,992 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:05,992 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:05,992 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:05,992 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:05,992 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:05,992 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:05,992 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:05,992 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:05,992 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:05,992 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:05,992 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:05,992 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:05,992 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:27:05,992 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:05,992 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:05,992 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:27:05,992 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:27:05,992 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:05,992 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:05,994 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:05,994 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:05,994 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:05,992 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:05,992 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:27:05,992 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:05,994 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:05,994 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:05,994 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:05,994 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:05,994 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:05,994 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:05,994 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:05,995 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:05,994 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:05,995 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:05,995 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:27:05,995 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:05,995 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:05,995 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:27:05,995 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:05,995 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:05,995 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:05,995 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:05,995 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:05,995 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:05,996 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:05,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:05,996 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:05,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:05,996 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:05,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:05,996 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:05,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:05,996 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:05,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:05,996 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:05,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:05,996 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:05,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:05,996 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:05,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:05,996 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:05,997 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:27:05,997 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:27:05,997 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:27:06,008 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:06,008 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:06,008 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:06,008 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:06,008 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:06,008 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:06,008 [INFO ] nioEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:06,008 [INFO ] nioEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:06,008 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:06,008 [INFO ] nioEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:06,009 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:06,009 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:06,009 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:06,008 [INFO ] nioEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:06,009 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:06,009 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:06,009 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:06,009 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:06,009 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:06,009 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:06,009 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:06,009 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:06,009 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:06,009 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:06,009 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:27:06,009 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:06,009 [INFO ] nioEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:06,009 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:06,009 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:06,009 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:27:06,010 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:27:06,010 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:06,009 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:06,010 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:06,010 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:06,010 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:06,009 [INFO ] nioEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:06,010 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:06,010 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:06,010 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:06,010 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:06,010 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:06,010 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:06,010 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:27:06,010 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:06,010 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:06,010 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:06,010 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:06,010 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:06,010 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:06,010 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:06,010 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2025-06-04T16:27:06,010 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:06,010 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:06,010 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:06,010 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:06,010 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2025-06-04T16:27:06,011 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:06,010 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:06,010 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:06,011 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:06,011 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:06,010 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:06,011 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:27:06,011 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:06,011 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:06,011 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:06,011 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:06,011 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:06,011 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:06,011 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:06,011 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2025-06-04T16:27:06,011 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:06,011 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:06,011 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:06,011 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:06,011 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:06,011 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:06,011 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:06,013 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:06,013 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:06,013 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:06,013 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:06,013 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:06,013 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:06,013 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:06,013 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:06,013 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:27:06,013 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:27:06,013 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:27:06,013 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:06,013 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:27:06,013 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:06,013 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:06,013 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:27:06,013 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:06,014 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:06,014 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:06,014 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:06,013 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:27:06,014 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:06,014 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:06,014 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:06,014 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:06,014 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:06,014 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:06,014 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:06,014 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:06,014 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:06,014 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:06,014 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:06,015 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:06,015 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:06,015 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:06,015 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:06,015 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:06,015 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:06,015 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:06,015 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:06,015 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:06,015 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:06,015 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:06,015 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:06,015 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:06,015 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:06,015 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:06,015 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:06,015 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:06,015 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:06,015 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:06,015 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:06,015 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:06,015 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:06,015 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:06,016 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:06,016 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:06,016 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:06,016 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:06,016 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:06,015 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:06,016 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:06,016 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:06,016 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:06,016 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:06,016 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:06,016 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:06,016 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:06,016 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:06,016 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:06,016 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:06,016 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:06,016 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:06,016 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:06,016 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:06,016 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:06,016 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:06,016 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:06,017 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:06,016 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:06,017 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:06,017 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:06,017 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:06,017 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:06,017 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:06,017 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:06,017 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:06,017 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:06,017 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:27:06,017 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:27:06,017 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:06,017 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:27:06,017 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:27:06,017 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:27:06,017 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:27:27,005 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,005 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,005 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,005 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,005 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,005 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,019 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,019 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,019 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,019 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,019 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:27,019 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:27:28,391 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:27:28,391 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:27:28,392 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:27:28,392 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:27:28,393 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:27:28,395 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:27:28,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:28,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]17876
2025-06-04T16:27:28,396 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,396 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:28,396 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,397 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:28,397 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:28,397 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:27:28,397 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]26976
2025-06-04T16:27:28,397 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:27:28,397 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:28,397 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,397 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:28,397 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,397 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:27:28,397 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:27:28,397 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:28,397 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]32928
2025-06-04T16:27:28,398 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:28,398 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,398 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:28,398 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,398 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:27:28,398 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:28,398 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:27:28,398 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]13288
2025-06-04T16:27:28,398 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248398
2025-06-04T16:27:28,398 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248398
2025-06-04T16:27:28,398 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:27:28,398 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,398 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248398
2025-06-04T16:27:28,398 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:27:28,398 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248398
2025-06-04T16:27:28,398 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248398
2025-06-04T16:27:28,398 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248398
2025-06-04T16:27:28,398 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,398 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:28,398 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248398
2025-06-04T16:27:28,398 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248398
2025-06-04T16:27:28,399 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:27:28,399 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:28,399 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:27:28,401 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:27:28,401 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:28,401 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]23188
2025-06-04T16:27:28,401 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:28,401 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,401 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248401
2025-06-04T16:27:28,401 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:28,401 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,402 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:27:28,401 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248401
2025-06-04T16:27:28,402 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248402
2025-06-04T16:27:28,402 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:27:28,402 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248402
2025-06-04T16:27:28,404 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248404
2025-06-04T16:27:28,404 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248404
2025-06-04T16:27:28,404 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248404
2025-06-04T16:27:28,404 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248404
2025-06-04T16:27:28,404 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248404
2025-06-04T16:27:28,404 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248404
2025-06-04T16:27:28,404 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:27:28,404 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:27:28,405 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248405
2025-06-04T16:27:28,404 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:27:28,405 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248405
2025-06-04T16:27:28,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]29832
2025-06-04T16:27:28,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:27:28,406 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:27:28,406 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:27:28,406 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:27:28,406 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:27:28,408 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248408
2025-06-04T16:27:28,408 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029248408
2025-06-04T16:27:28,421 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:27:28,422 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248422
2025-06-04T16:27:28,422 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029248422
2025-06-04T16:27:28,422 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:27:28,422 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:27:28,437 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:27:28,437 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:27:28,437 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:27:28,441 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:27:28,484 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:28,484 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:28,484 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:28,485 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:28,486 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:28,486 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:28,498 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:28,498 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:28,498 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:28,498 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:28,498 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:28,498 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:28,499 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:28,499 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:28,499 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:28,500 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:27:28,500 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:27:28,500 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:27:29,896 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:29,896 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,896 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:29,896 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:29,896 [INFO ] nioEventLoopGroup-5-50 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,896 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:29,896 [INFO ] nioEventLoopGroup-5-50 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,896 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:29,896 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,896 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,896 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,896 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,896 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,896 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,897 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:29,897 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:27:29,897 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:29,897 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,897 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:29,897 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,897 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,898 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:27:29,899 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:27:29,899 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:29,899 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,899 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:29,899 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:29,899 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:29,899 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:29,899 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,900 [INFO ] nioEventLoopGroup-5-53 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,900 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,900 [INFO ] nioEventLoopGroup-5-53 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,900 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,900 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,900 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,900 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:29,900 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,900 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,900 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,900 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:29,900 [INFO ] nioEventLoopGroup-5-49 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,900 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:29,900 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,900 [INFO ] nioEventLoopGroup-5-49 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,900 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:27:29,900 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,900 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:27:29,900 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:29,900 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,901 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:29,900 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,900 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:29,901 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,900 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,901 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,901 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:29,901 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,901 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:29,901 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,901 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,901 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,901 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,901 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:27:29,901 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2025-06-04T16:27:29,901 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:27:29,901 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,901 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2025-06-04T16:27:29,901 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,901 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:29,901 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:29,902 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:29,902 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:29,902 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:29,902 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:27:29,904 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,903 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:27:29,903 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:29,904 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:27:29,904 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:27:29,904 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:29,904 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:29,904 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,904 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:29,904 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:29,905 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:27:29,905 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:27:29,916 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:29,916 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,916 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:29,916 [INFO ] nioEventLoopGroup-5-52 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,916 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:29,916 [INFO ] nioEventLoopGroup-5-52 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,916 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:29,916 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:29,916 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,916 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,916 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,916 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,916 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,916 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,917 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:29,917 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:29,917 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,917 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,917 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:29,917 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:29,917 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,918 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2025-06-04T16:27:29,918 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2025-06-04T16:27:29,918 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:29,918 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,918 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,918 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:29,918 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:29,918 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,919 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,919 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,919 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:29,919 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:29,920 [INFO ] nioEventLoopGroup-5-54 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,919 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:29,920 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:27:29,920 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:29,920 [INFO ] nioEventLoopGroup-5-54 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,920 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:27:29,920 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:29,920 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,920 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:27:29,920 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:27:29,920 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,920 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,920 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,920 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,920 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,920 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,920 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,920 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:29,920 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:27:29,920 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:29,920 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:27:29,920 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,920 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:29,920 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,921 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,921 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:29,921 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:29,923 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,924 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,924 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:27:29,924 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,924 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:27:29,924 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:29,924 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:29,924 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:27:29,924 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:27:29,933 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:27:29,933 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,933 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:27:29,933 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:27:29,934 [INFO ] nioEventLoopGroup-5-51 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,934 [INFO ] nioEventLoopGroup-5-51 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,934 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,934 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:27:29,934 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,934 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,934 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:27:29,934 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:27:29,934 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:27:29,934 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:27:29,934 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:27:29,934 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:27:29,934 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:27:29,935 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:27:29,936 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:28:03,903 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,903 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,915 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,915 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,915 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,915 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,930 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,930 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,930 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,930 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,946 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:03,946 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:28:05,205 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:28:05,207 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:28:05,211 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:28:05,211 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]17996
2025-06-04T16:28:05,211 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:28:05,211 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,211 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:28:05,211 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,211 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:28:05,211 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:28:05,212 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:28:05,214 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285214
2025-06-04T16:28:05,214 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285214
2025-06-04T16:28:05,214 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285214
2025-06-04T16:28:05,214 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285214
2025-06-04T16:28:05,214 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:28:05,217 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]9904
2025-06-04T16:28:05,217 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:28:05,217 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,217 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:28:05,217 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,217 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:28:05,217 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:28:05,219 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285219
2025-06-04T16:28:05,219 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285219
2025-06-04T16:28:05,219 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285219
2025-06-04T16:28:05,219 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:28:05,219 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285219
2025-06-04T16:28:05,236 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:28:05,236 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:28:05,236 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:28:05,236 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:28:05,237 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]4524
2025-06-04T16:28:05,236 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:28:05,236 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:28:05,236 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:28:05,237 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,237 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]11160
2025-06-04T16:28:05,236 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:28:05,237 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:28:05,237 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,237 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:28:05,237 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,237 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]29052
2025-06-04T16:28:05,237 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:28:05,237 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:28:05,237 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,237 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:28:05,237 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,237 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:28:05,237 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:28:05,237 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:28:05,237 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,237 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:28:05,238 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:28:05,237 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:28:05,238 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:28:05,251 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:28:05,251 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]19252
2025-06-04T16:28:05,251 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:28:05,251 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,251 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:28:05,251 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:28:05,252 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:28:05,252 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:28:05,252 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:28:05,252 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285252
2025-06-04T16:28:05,252 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285252
2025-06-04T16:28:05,252 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285252
2025-06-04T16:28:05,252 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285252
2025-06-04T16:28:05,252 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285252
2025-06-04T16:28:05,252 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285252
2025-06-04T16:28:05,252 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285252
2025-06-04T16:28:05,252 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285252
2025-06-04T16:28:05,252 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285252
2025-06-04T16:28:05,252 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285252
2025-06-04T16:28:05,253 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285253
2025-06-04T16:28:05,252 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:28:05,252 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285252
2025-06-04T16:28:05,253 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029285253
2025-06-04T16:28:05,253 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285253
2025-06-04T16:28:05,253 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:28:05,252 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285252
2025-06-04T16:28:05,252 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:28:05,253 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029285253
2025-06-04T16:28:05,253 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:28:05,253 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:28:05,253 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:28:05,253 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:28:05,253 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:28:05,297 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:28:05,297 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:28:05,298 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:28:05,313 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:28:05,313 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:28:05,313 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:28:05,314 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:28:05,314 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:28:05,314 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:28:05,314 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:28:05,314 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:28:05,314 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:28:05,314 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:28:05,315 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:28:05,315 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:28:05,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:28:05,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:28:05,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:28:06,622 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:28:06,622 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,622 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:28:06,623 [INFO ] nioEventLoopGroup-5-55 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:28:06,623 [INFO ] nioEventLoopGroup-5-55 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,623 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,623 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:28:06,623 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:28:06,623 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:28:06,623 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,623 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:28:06,623 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,623 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,623 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,623 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:28:06,623 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:28:06,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:28:06,625 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:28:06,626 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:28:06,626 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:28:06,626 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:28:06,626 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:28:06,644 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:28:06,645 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:28:06,645 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:28:06,645 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:28:06,645 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,645 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,645 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:28:06,645 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:28:06,645 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:28:06,645 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:28:06,646 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,646 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,646 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:28:06,646 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:28:06,646 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:28:06,647 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:28:06,647 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:28:06,647 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:28:06,647 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,647 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:28:06,647 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:28:06,647 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,647 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:28:06,647 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:28:06,647 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,647 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:28:06,647 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:28:06,647 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,647 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:28:06,647 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,647 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:28:06,647 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,647 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,647 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:28:06,647 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,647 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:28:06,647 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,647 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:28:06,647 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:28:06,648 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,647 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,647 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,648 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,648 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,648 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,648 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,648 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,648 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:28:06,648 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:28:06,648 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:28:06,648 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,648 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:28:06,648 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:28:06,648 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,648 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:28:06,649 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,649 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:28:06,649 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:28:06,649 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:28:06,649 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:28:06,650 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:28:06,651 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:28:06,651 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,651 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:28:06,651 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:28:06,653 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:28:06,653 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:28:06,653 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,653 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,653 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,653 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,653 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:28:06,653 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:28:06,653 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:28:06,653 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,653 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,653 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,653 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:28:06,654 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,656 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,656 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:28:06,656 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:28:06,656 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:28:06,656 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:28:06,656 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:28:06,656 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:28:06,665 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:28:06,665 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,665 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:28:06,665 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,665 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:28:06,665 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:28:06,665 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,665 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,665 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:28:06,666 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,666 [INFO ] nioEventLoopGroup-5-56 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,666 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:28:06,666 [INFO ] nioEventLoopGroup-5-56 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:28:06,666 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:28:06,666 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,666 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,666 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:28:06,666 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,666 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:28:06,666 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:28:06,666 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,666 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,666 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,666 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,666 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:28:06,666 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,666 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:28:06,666 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:28:06,666 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,667 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:28:06,666 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,666 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:28:06,667 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,666 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,667 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:28:06,667 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:28:06,667 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,667 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:28:06,667 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:28:06,667 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,667 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:28:06,667 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:28:06,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:28:06,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:28:06,667 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2025-06-04T16:28:06,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,667 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2025-06-04T16:28:06,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:28:06,667 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:28:06,668 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:28:06,668 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,669 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,670 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:28:06,669 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:28:06,670 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:28:06,670 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:28:06,670 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:28:06,670 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:28:06,670 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:28:06,670 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:28:06,670 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:28:06,670 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:28:06,670 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:28:06,670 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:28:06,670 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:29:01,630 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,630 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,661 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,661 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,661 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,661 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,661 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,661 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,675 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,675 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,675 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:01,675 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:29:02,919 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:29:02,924 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:29:02,924 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]25760
2025-06-04T16:29:02,925 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,924 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:29:02,925 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,925 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:29:02,925 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:29:02,925 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:29:02,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342926
2025-06-04T16:29:02,926 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342926
2025-06-04T16:29:02,926 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342926
2025-06-04T16:29:02,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:29:02,926 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342926
2025-06-04T16:29:02,926 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:29:02,953 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:29:02,958 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:29:02,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:29:02,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]31432
2025-06-04T16:29:02,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:29:02,960 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,960 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,960 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:29:02,960 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:29:02,960 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:29:02,961 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342961
2025-06-04T16:29:02,961 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342961
2025-06-04T16:29:02,961 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:29:02,961 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342961
2025-06-04T16:29:02,961 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342961
2025-06-04T16:29:02,961 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:29:02,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:29:02,963 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:29:02,964 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:29:02,964 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]2752
2025-06-04T16:29:02,964 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,964 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:29:02,964 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,964 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:29:02,964 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:29:02,964 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:29:02,964 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:29:02,965 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:29:02,965 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342965
2025-06-04T16:29:02,965 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342965
2025-06-04T16:29:02,965 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342965
2025-06-04T16:29:02,965 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342965
2025-06-04T16:29:02,966 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:29:02,968 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:29:02,968 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]31276
2025-06-04T16:29:02,968 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,968 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:29:02,968 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,968 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:29:02,968 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:29:02,968 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:29:02,969 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342969
2025-06-04T16:29:02,969 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342969
2025-06-04T16:29:02,969 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342969
2025-06-04T16:29:02,969 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342969
2025-06-04T16:29:02,969 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:29:02,969 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:29:02,970 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:29:02,970 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]18252
2025-06-04T16:29:02,970 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,970 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:29:02,970 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,970 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:29:02,971 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:29:02,971 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:29:02,971 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:29:02,971 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]22708
2025-06-04T16:29:02,971 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:29:02,972 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,972 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:29:02,972 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342972
2025-06-04T16:29:02,972 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:29:02,972 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:29:02,972 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:29:02,972 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342972
2025-06-04T16:29:02,972 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:29:02,972 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342972
2025-06-04T16:29:02,972 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342972
2025-06-04T16:29:02,973 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342973
2025-06-04T16:29:02,973 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:29:02,973 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:29:02,973 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029342973
2025-06-04T16:29:02,973 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342973
2025-06-04T16:29:02,973 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029342973
2025-06-04T16:29:02,974 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:29:02,984 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:29:02,985 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:29:02,985 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:29:03,024 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:29:03,024 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:29:03,024 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:29:03,027 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:29:03,028 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:29:03,028 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:29:03,029 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:29:03,029 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:29:03,030 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:29:03,031 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:29:03,032 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:29:03,032 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:29:03,032 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:29:03,032 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:29:03,032 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:29:04,265 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:29:04,266 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,266 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:29:04,266 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:29:04,266 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,266 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,266 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:29:04,266 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,266 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,266 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:29:04,266 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,266 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,266 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,266 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,266 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,266 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,267 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:29:04,267 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:29:04,267 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:29:04,267 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,267 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:29:04,267 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:29:04,267 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,268 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:29:04,269 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:29:04,404 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:29:04,404 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,404 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:29:04,405 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:29:04,405 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,405 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,405 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:29:04,405 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,405 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,405 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,405 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:29:04,405 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,405 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,405 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:29:04,405 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:29:04,405 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:29:04,406 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:29:04,407 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:29:04,411 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:29:04,412 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,412 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,412 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,412 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,412 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:29:04,412 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,412 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:29:04,413 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:29:04,413 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:29:04,413 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,413 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,413 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:29:04,413 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:29:04,413 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:29:04,415 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:29:04,419 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:29:04,419 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,419 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:29:04,419 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:29:04,419 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,419 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,419 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:29:04,419 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:29:04,419 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,419 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,419 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,419 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,419 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,420 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:29:04,420 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:29:04,420 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:29:04,420 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,420 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:29:04,420 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:29:04,420 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,421 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:29:04,423 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:29:04,428 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:29:04,428 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,428 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:29:04,429 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:29:04,429 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:29:04,429 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,429 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,429 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,429 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:29:04,429 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:29:04,429 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:29:04,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:29:04,429 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:29:04,429 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,429 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,429 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,429 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:29:04,429 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,429 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,429 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,429 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:29:04,429 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:29:04,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:29:04,430 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2025-06-04T16:29:04,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:29:04,430 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:29:04,430 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:29:04,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,430 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:29:04,430 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:29:04,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,430 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:29:04,430 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:29:04,430 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,430 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:29:04,430 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:29:04,431 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:29:04,431 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:29:04,433 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:29:04,433 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:29:04,433 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:29:04,433 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:29:04,433 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:29:04,433 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:29:04,433 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:29:04,433 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,433 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:29:04,433 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:29:04,434 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:29:04,434 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:29:04,434 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:29:04,434 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:29:04,434 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:30:33,283 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,283 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,419 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,419 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,419 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,419 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,435 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,435 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,435 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,435 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,435 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:33,435 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:30:34,552 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:30:34,558 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:30:34,558 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]16264
2025-06-04T16:30:34,558 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,558 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:30:34,558 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,558 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:30:34,558 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:30:34,558 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:30:34,559 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434559
2025-06-04T16:30:34,559 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434559
2025-06-04T16:30:34,559 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:30:34,559 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434559
2025-06-04T16:30:34,559 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434559
2025-06-04T16:30:34,559 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:30:34,618 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:30:34,618 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:30:34,619 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:30:34,744 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:30:34,747 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:30:34,751 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:30:34,751 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]21916
2025-06-04T16:30:34,751 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,751 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:30:34,751 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,751 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:30:34,751 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:30:34,751 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:30:34,752 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434752
2025-06-04T16:30:34,752 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:30:34,752 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434752
2025-06-04T16:30:34,752 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434752
2025-06-04T16:30:34,752 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434752
2025-06-04T16:30:34,752 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:30:34,753 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:30:34,753 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:30:34,753 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]9924
2025-06-04T16:30:34,753 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:30:34,753 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,753 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:30:34,753 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,753 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:30:34,753 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:30:34,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:30:34,754 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434754
2025-06-04T16:30:34,754 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434754
2025-06-04T16:30:34,754 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434754
2025-06-04T16:30:34,754 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:30:34,754 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434754
2025-06-04T16:30:34,755 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:30:34,759 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:30:34,759 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]31288
2025-06-04T16:30:34,759 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,759 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:30:34,759 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,759 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:30:34,759 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:30:34,759 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:30:34,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:30:34,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]20348
2025-06-04T16:30:34,760 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:30:34,760 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:30:34,760 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:30:34,760 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:30:34,760 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434760
2025-06-04T16:30:34,760 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434760
2025-06-04T16:30:34,760 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434760
2025-06-04T16:30:34,760 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434760
2025-06-04T16:30:34,760 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:30:34,760 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434760
2025-06-04T16:30:34,760 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434760
2025-06-04T16:30:34,760 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:30:34,760 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434760
2025-06-04T16:30:34,760 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434760
2025-06-04T16:30:34,760 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:30:34,761 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:30:34,764 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:30:34,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:30:34,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]6916
2025-06-04T16:30:34,772 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,770 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:30:34,772 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:30:34,772 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:30:34,772 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:30:34,772 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:30:34,773 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:30:34,773 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434773
2025-06-04T16:30:34,773 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029434773
2025-06-04T16:30:34,773 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434773
2025-06-04T16:30:34,773 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029434773
2025-06-04T16:30:34,773 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:30:34,813 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:30:34,813 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:30:34,813 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:30:34,813 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:30:34,813 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:30:34,814 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:30:34,821 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:30:34,821 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:30:34,821 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:30:34,822 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:30:34,822 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:30:34,822 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:30:34,832 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:30:34,833 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:30:34,833 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:30:35,872 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:30:35,873 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:30:35,873 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:35,873 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:30:35,873 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:30:35,873 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:35,873 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:35,873 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:30:35,873 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:30:35,873 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:30:35,874 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:30:35,874 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:35,874 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:30:35,874 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 144 seconds.
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 144 seconds.
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:30:35,874 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:30:35,875 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:30:35,877 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:30:35,877 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:30:35,877 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:30:35,877 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,186 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:30:36,186 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:30:36,186 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:30:36,186 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,186 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,186 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,187 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:30:36,186 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:30:36,187 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:30:36,187 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:30:36,187 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,187 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:30:36,187 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 144 seconds.
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 144 seconds.
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:30:36,188 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:30:36,189 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:30:36,191 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:30:36,191 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,191 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:30:36,191 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:30:36,191 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,191 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:30:36,191 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,191 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:30:36,192 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,192 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,192 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,192 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:30:36,192 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:30:36,192 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:30:36,192 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,192 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,192 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,192 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:30:36,192 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 144 seconds.
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 144 seconds.
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:30:36,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:30:36,194 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:30:36,199 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:30:36,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:30:36,200 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:30:36,200 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:30:36,200 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,200 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:30:36,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,200 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,200 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,200 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:30:36,200 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:30:36,200 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,200 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,201 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:30:36,201 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:30:36,201 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:30:36,201 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:30:36,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:30:36,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:30:36,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:30:36,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:30:36,202 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:30:36,202 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,202 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:30:36,202 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:30:36,202 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:30:36,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:30:36,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:30:36,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,202 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:30:36,203 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:30:36,203 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:30:36,203 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,203 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:30:36,203 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,203 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:30:36,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:30:36,203 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,203 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,203 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,203 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,203 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,203 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 144 seconds.
2025-06-04T16:30:36,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:30:36,203 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:30:36,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 144 seconds.
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:30:36,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:30:36,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:30:36,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:30:36,204 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,204 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:30:36,204 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,205 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:30:36,206 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:30:36,208 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:30:36,208 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,208 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:30:36,208 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:30:36,209 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:30:36,209 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,209 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,209 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,209 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,209 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,209 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:30:36,209 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:30:36,209 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,209 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:30:36,209 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:30:36,209 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 144 seconds.
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 144 seconds.
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:30:36,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:30:36,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:30:36,212 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:30:36,212 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:30:36,212 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:30:36,212 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:32:33,945 [INFO ] nioEventLoopGroup-3-1 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:59876 "GET /models HTTP/1.1" 200 2
2025-06-04T16:32:33,945 [INFO ] nioEventLoopGroup-3-1 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:DESKTOP-G57G3K8,timestamp:1749029553
2025-06-04T16:32:59,884 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:32:59,884 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,197 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,197 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,197 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,197 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,212 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,212 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,212 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,212 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,212 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:00,212 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:33:01,188 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:33:01,194 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:33:01,194 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]27244
2025-06-04T16:33:01,194 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,194 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:33:01,194 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,194 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:33:01,194 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:33:01,194 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:33:01,195 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581195
2025-06-04T16:33:01,195 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:33:01,195 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581195
2025-06-04T16:33:01,196 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581196
2025-06-04T16:33:01,196 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581196
2025-06-04T16:33:01,196 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:33:01,257 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:33:01,257 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:33:01,258 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:33:01,503 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:33:01,509 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:33:01,510 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]15824
2025-06-04T16:33:01,510 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,510 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:33:01,510 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,510 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:33:01,510 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:33:01,510 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:33:01,511 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581511
2025-06-04T16:33:01,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:33:01,511 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581511
2025-06-04T16:33:01,511 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581511
2025-06-04T16:33:01,511 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581511
2025-06-04T16:33:01,511 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:33:01,517 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:33:01,520 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:33:01,522 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:33:01,522 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:33:01,524 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:33:01,524 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]28272
2025-06-04T16:33:01,524 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:33:01,524 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,524 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,524 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:33:01,524 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:33:01,524 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:33:01,525 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581525
2025-06-04T16:33:01,525 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:33:01,525 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581525
2025-06-04T16:33:01,526 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581526
2025-06-04T16:33:01,526 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581526
2025-06-04T16:33:01,526 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:33:01,526 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:33:01,526 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]16108
2025-06-04T16:33:01,526 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,526 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:33:01,526 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,526 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:33:01,526 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:33:01,526 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:33:01,527 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581527
2025-06-04T16:33:01,527 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581527
2025-06-04T16:33:01,527 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581527
2025-06-04T16:33:01,527 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:33:01,527 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581527
2025-06-04T16:33:01,527 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:33:01,528 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:33:01,528 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]22152
2025-06-04T16:33:01,528 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,528 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:33:01,528 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,528 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:33:01,528 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:33:01,528 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:33:01,529 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581529
2025-06-04T16:33:01,529 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581529
2025-06-04T16:33:01,529 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581529
2025-06-04T16:33:01,529 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:33:01,529 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581529
2025-06-04T16:33:01,529 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:33:01,529 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]31676
2025-06-04T16:33:01,529 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:33:01,529 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,529 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:33:01,529 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:33:01,530 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:33:01,529 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:33:01,530 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:33:01,530 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581530
2025-06-04T16:33:01,530 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029581530
2025-06-04T16:33:01,530 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:33:01,530 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581530
2025-06-04T16:33:01,530 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029581530
2025-06-04T16:33:01,530 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:33:01,577 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:33:01,577 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:33:01,577 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:33:01,591 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:33:01,591 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:33:01,592 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:33:01,592 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:33:01,592 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:33:01,592 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:33:01,592 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:33:01,593 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:33:01,593 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:33:01,593 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:33:01,593 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:33:01,593 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:33:02,543 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:33:02,543 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,543 [INFO ] nioEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,543 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:33:02,543 [INFO ] nioEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,543 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:33:02,543 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,543 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:33:02,543 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,544 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:33:02,544 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,544 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,544 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,544 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,544 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:33:02,544 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,544 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:33:02,544 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,544 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,544 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,544 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,544 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,544 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\7e9adab9eb1942aeaa99a75c75237b6c\yolo_handler.py", line 3, in <module>
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,545 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,546 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:33:02,547 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,547 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,547 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:33:02,547 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:33:02,547 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:33:02,547 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:33:02,878 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:33:02,878 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,878 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:33:02,878 [INFO ] nioEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,878 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:33:02,878 [INFO ] nioEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,878 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:33:02,879 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:33:02,879 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,879 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,879 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,879 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:33:02,879 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:33:02,879 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:33:02,879 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,879 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:33:02,879 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\9878fd5b2887444b86223a7fa332477b\yolo_handler.py", line 3, in <module>
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,879 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,880 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:33:02,881 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:33:02,881 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:33:02,881 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:33:02,881 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:33:02,881 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:33:02,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:33:02,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:33:02,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:33:02,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:33:02,901 [INFO ] nioEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:33:02,901 [INFO ] nioEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,901 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,901 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,901 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,901 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,901 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,902 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:33:02,902 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:33:02,902 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:33:02,902 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,902 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,902 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\50e8297142a1403291b8257f7fb0ec02\yolo_handler.py", line 3, in <module>
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:33:02,902 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:33:02,903 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:33:02,904 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:33:02,904 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:33:02,904 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:33:02,904 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:33:02,918 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:33:02,918 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,918 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:33:02,918 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:33:02,918 [INFO ] nioEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,918 [INFO ] nioEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,918 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:33:02,918 [INFO ] nioEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,918 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:33:02,918 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,918 [INFO ] nioEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,918 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,918 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,918 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,918 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:33:02,918 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,918 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,918 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,918 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,918 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,918 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:33:02,919 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:33:02,918 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,919 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:33:02,919 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:33:02,919 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,919 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:33:02,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,919 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:33:02,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,919 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,919 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,919 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:33:02,919 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:33:02,919 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:33:02,919 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,919 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,919 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,919 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:33:02,919 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:33:02,919 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,919 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,919 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\df3799d85dc649cba8129ee405236972\yolo_handler.py", line 3, in <module>
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\52386e81786345eaab57d37faaeca75f\yolo_handler.py", line 3, in <module>
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:33:02,920 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:33:02,920 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,921 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,921 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,923 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,923 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:33:02,923 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:33:02,923 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,927 [INFO ] nioEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,927 [INFO ] nioEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,927 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,927 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:33:02,927 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:33:02,927 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:33:02,927 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,927 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:33:02,927 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\0e7a22012f54417b8571a1e9564231fd\yolo_handler.py", line 3, in <module>
2025-06-04T16:33:02,927 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:33:02,927 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,927 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:33:02,927 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:33:02,928 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:33:02,929 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:33:02,930 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:33:02,930 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:33:02,930 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:33:02,930 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:33:02,930 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:33:02,930 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:33:02,930 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:33:02,930 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:33:22,125 [INFO ] W-9005-xuoc_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:59892 "GET /ping HTTP/1.1" 500 2
2025-06-04T16:33:22,125 [INFO ] W-9005-xuoc_1.0 TS_METRICS - Requests5XX.Count:1.0|#Level:Host|#hostname:DESKTOP-G57G3K8,timestamp:1749029602
2025-06-04T16:33:22,925 [INFO ] nioEventLoopGroup-3-3 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:59893 "GET /favicon.ico HTTP/1.1" 404 0
2025-06-04T16:33:22,925 [INFO ] nioEventLoopGroup-3-3 TS_METRICS - Requests4XX.Count:1.0|#Level:Host|#hostname:DESKTOP-G57G3K8,timestamp:1749029602
2025-06-04T16:33:31,418 [INFO ] nioEventLoopGroup-3-4 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:59910 "GET /models HTTP/1.1" 200 0
2025-06-04T16:33:31,418 [INFO ] nioEventLoopGroup-3-4 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:DESKTOP-G57G3K8,timestamp:1749029611
2025-06-04T16:33:32,203 [INFO ] nioEventLoopGroup-3-4 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:59910 "GET /favicon.ico HTTP/1.1" 404 0
2025-06-04T16:33:32,203 [INFO ] nioEventLoopGroup-3-4 TS_METRICS - Requests4XX.Count:1.0|#Level:Host|#hostname:DESKTOP-G57G3K8,timestamp:1749029612
2025-06-04T16:37:50,123 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-06-04T16:37:50,123 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-06-04T16:37:50,125 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-06-04T16:37:50,125 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-06-04T16:37:50,160 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
2025-06-04T16:37:50,160 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
2025-06-04T16:37:50,317 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.11.0
TS Home: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages
Current directory: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve
Temp directory: C:\Users\1\AppData\Local\Temp
Metrics config path: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 28
Max heap size: 8128 M
Python executable: C:\Users\1\anaconda3\envs\ts_yolo12\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
Initial Models: all
Log dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Metrics dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: true
Workflow Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2025-06-04T16:37:50,317 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.11.0
TS Home: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages
Current directory: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve
Temp directory: C:\Users\1\AppData\Local\Temp
Metrics config path: C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 28
Max heap size: 8128 M
Python executable: C:\Users\1\anaconda3\envs\ts_yolo12\python.exe
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
Initial Models: all
Log dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Metrics dir: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: true
Workflow Store: C:\Users\1\MeikoAI\SonCode\TestCycletimeMeiko\torchserve\model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
2025-06-04T16:37:50,321 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-06-04T16:37:50,321 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-06-04T16:37:50,330 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: bamdinh.mar
2025-06-04T16:37:50,330 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: bamdinh.mar
2025-06-04T16:37:50,510 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model bamdinh
2025-06-04T16:37:50,510 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model bamdinh
2025-06-04T16:37:50,510 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model bamdinh
2025-06-04T16:37:50,510 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model bamdinh
2025-06-04T16:37:50,511 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model bamdinh loaded.
2025-06-04T16:37:50,511 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model bamdinh loaded.
2025-06-04T16:37:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: bamdinh, count: 1
2025-06-04T16:37:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: bamdinh, count: 1
2025-06-04T16:37:50,515 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: divatma.mar
2025-06-04T16:37:50,515 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: divatma.mar
2025-06-04T16:37:50,517 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:50,517 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:50,665 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model divatma
2025-06-04T16:37:50,665 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model divatma
2025-06-04T16:37:50,666 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model divatma
2025-06-04T16:37:50,666 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model divatma
2025-06-04T16:37:50,666 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model divatma loaded.
2025-06-04T16:37:50,666 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model divatma loaded.
2025-06-04T16:37:50,666 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: divatma, count: 1
2025-06-04T16:37:50,666 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: divatma, count: 1
2025-06-04T16:37:50,666 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: nganmach.mar
2025-06-04T16:37:50,666 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: nganmach.mar
2025-06-04T16:37:50,668 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:50,668 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:50,814 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nganmach
2025-06-04T16:37:50,814 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model nganmach
2025-06-04T16:37:50,814 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nganmach
2025-06-04T16:37:50,814 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model nganmach
2025-06-04T16:37:50,814 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nganmach loaded.
2025-06-04T16:37:50,814 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model nganmach loaded.
2025-06-04T16:37:50,814 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nganmach, count: 1
2025-06-04T16:37:50,814 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: nganmach, count: 1
2025-06-04T16:37:50,814 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: thieudong.mar
2025-06-04T16:37:50,814 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: thieudong.mar
2025-06-04T16:37:50,815 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:50,815 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:50,955 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model thieudong
2025-06-04T16:37:50,955 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model thieudong
2025-06-04T16:37:50,956 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model thieudong
2025-06-04T16:37:50,956 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model thieudong
2025-06-04T16:37:50,956 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model thieudong loaded.
2025-06-04T16:37:50,956 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model thieudong loaded.
2025-06-04T16:37:50,956 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: thieudong, count: 1
2025-06-04T16:37:50,956 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: thieudong, count: 1
2025-06-04T16:37:50,956 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: vetlom.mar
2025-06-04T16:37:50,956 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: vetlom.mar
2025-06-04T16:37:50,957 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:50,957 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:51,099 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vetlom
2025-06-04T16:37:51,099 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vetlom
2025-06-04T16:37:51,100 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vetlom
2025-06-04T16:37:51,100 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vetlom
2025-06-04T16:37:51,100 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vetlom loaded.
2025-06-04T16:37:51,100 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vetlom loaded.
2025-06-04T16:37:51,100 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vetlom, count: 1
2025-06-04T16:37:51,100 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vetlom, count: 1
2025-06-04T16:37:51,100 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: xuoc.mar
2025-06-04T16:37:51,100 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: xuoc.mar
2025-06-04T16:37:51,101 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:51,101 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:51,250 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model xuoc
2025-06-04T16:37:51,250 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model xuoc
2025-06-04T16:37:51,250 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model xuoc
2025-06-04T16:37:51,250 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model xuoc
2025-06-04T16:37:51,250 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model xuoc loaded.
2025-06-04T16:37:51,250 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model xuoc loaded.
2025-06-04T16:37:51,251 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: xuoc, count: 1
2025-06-04T16:37:51,251 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: xuoc, count: 1
2025-06-04T16:37:51,252 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:51,252 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:51,253 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2025-06-04T16:37:51,253 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2025-06-04T16:37:51,407 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-06-04T16:37:51,407 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-06-04T16:37:51,408 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2025-06-04T16:37:51,408 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2025-06-04T16:37:51,409 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2025-06-04T16:37:51,409 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2025-06-04T16:37:51,409 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2025-06-04T16:37:51,409 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2025-06-04T16:37:51,409 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2025-06-04T16:37:51,409 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2025-06-04T16:37:51,828 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:37:51,835 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:51,835 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]25892
2025-06-04T16:37:51,835 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:51,835 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:51,836 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:51,836 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:51,838 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:37:51,838 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:37:51,843 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:37:51,844 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029871844
2025-06-04T16:37:51,844 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029871844
2025-06-04T16:37:51,846 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029871846
2025-06-04T16:37:51,846 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029871846
2025-06-04T16:37:51,861 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:37:51,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:51,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:51,923 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:51,969 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:37:51,975 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:51,975 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]28220
2025-06-04T16:37:51,976 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:51,976 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:51,976 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:51,976 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:37:51,976 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:37:51,976 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:51,977 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029871977
2025-06-04T16:37:51,977 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029871977
2025-06-04T16:37:51,977 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:37:51,978 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029871978
2025-06-04T16:37:51,978 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029871978
2025-06-04T16:37:51,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:37:52,049 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:52,050 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:52,050 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:52,116 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:37:52,122 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:52,122 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]8292
2025-06-04T16:37:52,122 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:52,122 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:52,122 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:52,122 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:37:52,122 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:37:52,122 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:52,124 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029872124
2025-06-04T16:37:52,124 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029872124
2025-06-04T16:37:52,124 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:37:52,124 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029872124
2025-06-04T16:37:52,124 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029872124
2025-06-04T16:37:52,134 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:37:52,196 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:52,196 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:52,196 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:52,254 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:37:52,260 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:52,261 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]27936
2025-06-04T16:37:52,261 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:52,261 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:52,261 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:52,261 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:52,261 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:37:52,261 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:37:52,262 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029872262
2025-06-04T16:37:52,262 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029872262
2025-06-04T16:37:52,262 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029872262
2025-06-04T16:37:52,262 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:37:52,262 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029872262
2025-06-04T16:37:52,276 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:37:52,336 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:52,337 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:52,337 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:52,399 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:37:52,405 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:52,406 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]23164
2025-06-04T16:37:52,406 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:52,406 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:52,406 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:52,406 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:52,406 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:37:52,406 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:37:52,408 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029872408
2025-06-04T16:37:52,408 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029872408
2025-06-04T16:37:52,408 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:37:52,408 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029872408
2025-06-04T16:37:52,408 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029872408
2025-06-04T16:37:52,432 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:37:52,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:52,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:52,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:52,558 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:37:52,564 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:52,564 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]18436
2025-06-04T16:37:52,564 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:52,564 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:52,564 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change null -> WORKER_STARTED
2025-06-04T16:37:52,564 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:52,565 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:37:52,565 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:37:52,566 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:37:52,566 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029872566
2025-06-04T16:37:52,566 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029872566
2025-06-04T16:37:52,567 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029872566
2025-06-04T16:37:52,567 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029872566
2025-06-04T16:37:52,589 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:37:52,653 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:52,653 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:52,653 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:53,263 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:53,263 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,263 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:53,263 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:53,263 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:53,263 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:53,263 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,263 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,263 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,263 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,264 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,264 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,264 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,264 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,264 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:53,264 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:53,264 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:53,264 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,265 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:53,265 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:53,265 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:53,265 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,265 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:53,265 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,266 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,266 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:53,266 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:53,266 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:53,266 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:53,266 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:53,267 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:53,267 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:53,267 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:53,267 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:53,268 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:53,268 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:53,268 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:53,268 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,268 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,268 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,268 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,269 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:53,269 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,269 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,270 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,270 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:53,270 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:53,264 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,264 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,275 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:37:53,275 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:37:53,275 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,275 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,275 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873275
2025-06-04T16:37:53,275 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873275
2025-06-04T16:37:53,277 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:37:53,277 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:37:53,279 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:37:53,279 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:37:53,279 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:37:53,279 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:37:53,361 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:53,361 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,361 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:53,361 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,361 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:53,361 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,362 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,362 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,362 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:53,362 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,362 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:53,362 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,362 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,362 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,363 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,363 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:37:53,363 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,363 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873363
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873363
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:37:53,363 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:53,364 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:53,364 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:53,364 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,364 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:53,364 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,364 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:37:53,365 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:53,366 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:53,366 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:53,366 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,366 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,366 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,366 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,366 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:53,366 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,366 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,367 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,367 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:53,367 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:53,367 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:37:53,367 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:37:53,479 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:53,479 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,479 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:53,479 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,479 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:53,479 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:53,479 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,479 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,479 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:53,479 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,480 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,480 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,480 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,480 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,480 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:37:53,480 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:37:53,480 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,480 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,480 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,480 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,480 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873480
2025-06-04T16:37:53,480 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:53,480 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873480
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:53,481 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:53,482 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:37:53,483 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:37:53,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:53,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:53,623 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:53,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:53,623 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,623 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:53,623 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,623 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,623 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,623 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,624 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,624 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:37:53,624 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,624 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873624
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873624
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:53,624 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:53,625 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,626 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,627 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,627 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:53,627 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:53,627 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:37:53,627 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:37:53,763 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:53,764 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,764 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,764 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,764 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,764 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:53,764 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,764 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:53,764 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,764 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:53,764 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,764 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:53,765 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:37:53,765 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:37:53,765 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,765 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,765 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,765 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873765
2025-06-04T16:37:53,765 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,765 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873765
2025-06-04T16:37:53,765 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,765 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:53,766 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,767 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,767 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:53,767 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:37:53,767 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:53,767 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:37:53,767 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:53,768 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:53,768 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:53,768 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:53,768 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:53,768 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:53,768 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:53,768 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:53,768 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:53,769 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:53,769 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,769 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,769 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,769 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,769 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:53,769 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,769 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,769 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,770 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:53,770 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:53,770 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:37:53,770 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:37:53,885 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:53,885 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,885 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,885 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:53,885 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:53,886 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:53,886 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:53,886 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,886 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:53,886 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:53,886 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,886 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,886 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,886 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:53,886 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,886 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:37:53,886 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:37:53,886 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,887 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:53,887 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873887
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1749029873887
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:53,887 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:53,888 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:53,889 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:53,889 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:53,889 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:53,889 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:53,889 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:37:53,889 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:37:54,295 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,295 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,370 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,370 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,495 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,495 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,636 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,636 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,775 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,775 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,902 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:54,902 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:55,570 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:37:55,576 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:55,577 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]11168
2025-06-04T16:37:55,577 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:55,577 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:55,577 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:55,577 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:37:55,577 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:55,577 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:37:55,579 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029875579
2025-06-04T16:37:55,579 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:37:55,579 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029875579
2025-06-04T16:37:55,579 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029875579
2025-06-04T16:37:55,579 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029875579
2025-06-04T16:37:55,604 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:37:55,605 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:37:55,609 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:55,609 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]4004
2025-06-04T16:37:55,609 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:55,609 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:55,609 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:55,609 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:55,609 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:37:55,609 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:37:55,611 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029875611
2025-06-04T16:37:55,611 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029875611
2025-06-04T16:37:55,611 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:37:55,611 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029875611
2025-06-04T16:37:55,611 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029875611
2025-06-04T16:37:55,636 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:37:55,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:55,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:55,667 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:55,697 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:55,697 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:55,698 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:55,745 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:37:55,750 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:55,751 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]10132
2025-06-04T16:37:55,751 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:55,751 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:55,751 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:55,751 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:37:55,751 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:55,751 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:37:55,752 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029875752
2025-06-04T16:37:55,752 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:37:55,752 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029875752
2025-06-04T16:37:55,752 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029875752
2025-06-04T16:37:55,752 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029875752
2025-06-04T16:37:55,777 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:37:55,834 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:55,835 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:55,835 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:55,888 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:37:55,894 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:55,894 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]3060
2025-06-04T16:37:55,894 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:55,894 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:55,894 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:55,894 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:55,894 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:37:55,894 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:37:55,896 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029875896
2025-06-04T16:37:55,896 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:37:55,896 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029875896
2025-06-04T16:37:55,896 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029875896
2025-06-04T16:37:55,896 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029875896
2025-06-04T16:37:55,918 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:37:55,977 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:55,978 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:55,978 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:56,043 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:37:56,049 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:56,049 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]22640
2025-06-04T16:37:56,049 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:56,049 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:56,049 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:56,049 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:56,050 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:37:56,050 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:37:56,051 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029876051
2025-06-04T16:37:56,051 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:37:56,051 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029876051
2025-06-04T16:37:56,051 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029876051
2025-06-04T16:37:56,051 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029876051
2025-06-04T16:37:56,073 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:37:56,137 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:56,137 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:56,137 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:56,187 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:37:56,193 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:56,193 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]15740
2025-06-04T16:37:56,193 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:56,193 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:56,193 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:56,194 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:37:56,193 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:56,194 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:37:56,195 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029876195
2025-06-04T16:37:56,195 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029876195
2025-06-04T16:37:56,195 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029876195
2025-06-04T16:37:56,195 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:37:56,195 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029876195
2025-06-04T16:37:56,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:37:56,272 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:56,273 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:56,273 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:56,957 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:56,957 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:56,957 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:56,957 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:56,957 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:56,957 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:56,957 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:56,958 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:56,957 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:56,958 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:56,957 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:56,957 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:56,958 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:56,958 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:56,958 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:56,958 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:56,958 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:56,958 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:56,958 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:56,958 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:56,958 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:56,958 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:56,958 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:37:56,958 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:37:56,958 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:56,958 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:56,958 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:37:56,958 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:56,958 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:56,958 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:56,958 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:37:56,958 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:56,958 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:56,958 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:56,960 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:56,958 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:56,960 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:56,958 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:56,960 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:56,960 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:56,960 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:56,960 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:56,960 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:56,960 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:37:56,960 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:56,960 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:56,960 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-06-04T16:37:56,960 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:37:56,960 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:56,960 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:56,960 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:56,960 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-06-04T16:37:56,960 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:56,960 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:56,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:56,961 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:56,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:56,961 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:56,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:56,961 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:56,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:56,961 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:56,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:56,961 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:56,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:56,961 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:56,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:56,961 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:56,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:56,961 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:56,962 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:56,961 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:56,962 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:56,962 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:56,962 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:56,962 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:56,962 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:56,962 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:56,962 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:56,962 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:56,962 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:37:56,962 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:56,962 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:37:56,962 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:37:56,962 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:37:56,962 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:56,963 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:56,963 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:56,963 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:56,963 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:56,963 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:56,963 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:56,963 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:56,963 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:56,963 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:56,963 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:56,963 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:56,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:56,964 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:56,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:56,964 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:56,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:56,964 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:56,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:56,964 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:56,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:56,964 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:56,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:56,964 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:56,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:56,965 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:56,965 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:56,965 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:56,965 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:56,965 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:56,965 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:56,965 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:56,965 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:56,965 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:37:56,965 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:37:56,965 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:37:56,965 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:37:57,098 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:57,099 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:57,099 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:57,099 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:57,099 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:57,099 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:57,099 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:57,099 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:57,099 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:57,099 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:57,099 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:57,099 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:57,099 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:57,099 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,099 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:57,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,100 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:37:57,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:57,100 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:37:57,100 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:57,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:57,100 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:57,100 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:57,100 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:57,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:57,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:57,101 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:37:57,100 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:57,101 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-06-04T16:37:57,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:57,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:57,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:57,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:57,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:57,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:57,102 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:57,102 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:57,102 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:57,102 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:57,102 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:57,102 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:57,102 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:57,102 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:57,102 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,103 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,104 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:57,104 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:57,104 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:37:57,104 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:37:57,218 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:57,218 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:57,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:57,220 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:57,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:57,220 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:57,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:57,220 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:57,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:57,220 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:57,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:57,220 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:57,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:57,220 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:57,220 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:37:57,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,220 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:37:57,220 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:57,220 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:57,220 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:57,220 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,220 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:57,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:57,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:57,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:57,221 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:37:57,221 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-06-04T16:37:57,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:57,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:57,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:57,221 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:37:57,223 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,222 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:37:57,223 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:57,223 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:57,223 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:37:57,223 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:37:57,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:57,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:57,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:57,364 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:57,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:57,364 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:57,364 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:57,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:57,364 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:57,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:57,364 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:57,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:57,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:57,364 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:57,365 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:37:57,365 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:37:57,365 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:57,365 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,365 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:57,365 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:57,365 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,365 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:57,365 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:57,365 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:37:57,365 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:57,366 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,367 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:37:57,368 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,368 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:57,368 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:57,368 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,368 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,368 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:57,368 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:57,368 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:37:57,368 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:37:57,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:37:57,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:57,488 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:57,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:37:57,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:37:57,488 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:37:57,489 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:37:57,489 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:57,489 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,489 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,489 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:37:57,489 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:37:57,489 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:37:57,489 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:37:57,489 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:57,489 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:37:57,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:37:57,490 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:37:57,491 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:37:57,492 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:37:57,492 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:37:57,492 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:37:57,492 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:37:57,979 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:57,980 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:57,979 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:57,980 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:58,102 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:58,102 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:58,225 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:58,225 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:58,366 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:58,366 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:58,506 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:58,506 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:37:59,241 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:37:59,244 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:37:59,248 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:59,248 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]21132
2025-06-04T16:37:59,248 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,248 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:59,248 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,248 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:59,249 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:37:59,249 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:37:59,250 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:59,250 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879250
2025-06-04T16:37:59,250 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879250
2025-06-04T16:37:59,250 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:37:59,251 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879251
2025-06-04T16:37:59,251 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879251
2025-06-04T16:37:59,251 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]16692
2025-06-04T16:37:59,251 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:59,251 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,251 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,251 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:59,253 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:37:59,253 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:37:59,255 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879255
2025-06-04T16:37:59,255 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879255
2025-06-04T16:37:59,255 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:37:59,255 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879255
2025-06-04T16:37:59,255 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879255
2025-06-04T16:37:59,269 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:37:59,284 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:37:59,330 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:59,330 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:59,331 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:59,343 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:59,343 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:59,343 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:59,348 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:37:59,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:59,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]21140
2025-06-04T16:37:59,353 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:59,353 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,354 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:59,354 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:37:59,354 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:37:59,355 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879355
2025-06-04T16:37:59,355 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879355
2025-06-04T16:37:59,355 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879355
2025-06-04T16:37:59,355 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:37:59,355 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879355
2025-06-04T16:37:59,377 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:37:59,435 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:59,435 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:59,436 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:59,463 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:37:59,468 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:59,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]20212
2025-06-04T16:37:59,469 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:59,469 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,469 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:59,469 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:37:59,469 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:37:59,470 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879470
2025-06-04T16:37:59,470 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:37:59,470 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879470
2025-06-04T16:37:59,471 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879471
2025-06-04T16:37:59,471 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879471
2025-06-04T16:37:59,488 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:37:59,545 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:59,545 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:59,545 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:59,624 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:37:59,629 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:59,630 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]29836
2025-06-04T16:37:59,630 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:59,630 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,630 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,630 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:59,630 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:37:59,630 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:37:59,631 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879631
2025-06-04T16:37:59,631 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:37:59,631 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879631
2025-06-04T16:37:59,631 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879631
2025-06-04T16:37:59,631 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879631
2025-06-04T16:37:59,647 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:37:59,705 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:59,705 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:59,706 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:37:59,776 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:37:59,782 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:37:59,783 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]12016
2025-06-04T16:37:59,783 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:37:59,783 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,783 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:37:59,783 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:37:59,783 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:37:59,783 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:37:59,785 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879785
2025-06-04T16:37:59,785 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029879785
2025-06-04T16:37:59,785 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879785
2025-06-04T16:37:59,785 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:37:59,785 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029879785
2025-06-04T16:37:59,804 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:37:59,863 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:37:59,863 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:37:59,863 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:00,728 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:00,728 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:00,728 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:00,728 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:00,728 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:00,728 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:00,728 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:00,728 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:00,728 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:00,729 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:00,729 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:00,729 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:00,729 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:00,729 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:00,729 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:00,730 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:00,729 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:00,730 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:00,730 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:00,730 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:00,730 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:00,731 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:00,733 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:00,733 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:00,733 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:00,733 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:00,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:00,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:00,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:00,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:00,753 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:00,753 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:00,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:00,753 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:00,753 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:00,753 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:00,753 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:00,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:00,753 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:00,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:00,753 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:00,753 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:00,753 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,753 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:00,753 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,754 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:00,754 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:00,754 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,753 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:00,753 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:00,754 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:00,754 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:00,754 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:00,754 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:00,754 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:00,754 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:00,754 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:00,754 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:00,754 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:00,754 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:00,754 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:00,754 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:00,754 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:00,754 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:00,754 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:00,754 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:00,755 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:00,755 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:00,754 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:00,754 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:00,755 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-06-04T16:38:00,755 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:00,755 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:00,755 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:00,755 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:00,755 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-06-04T16:38:00,755 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:00,755 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-06-04T16:38:00,755 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:00,755 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-06-04T16:38:00,755 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:00,755 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:00,755 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:00,755 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:00,755 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:00,756 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:00,756 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:00,758 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:00,758 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:00,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:00,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:00,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:00,758 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:00,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:00,758 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:00,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:00,758 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:00,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,758 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,758 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:00,758 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:00,758 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:00,759 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:00,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,759 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:00,759 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,759 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:00,759 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:00,759 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:00,759 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:00,759 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:00,760 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:00,760 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:00,795 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:00,795 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:00,796 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:00,796 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:00,796 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:00,796 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,796 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,796 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:00,797 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:00,796 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:00,797 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:00,797 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:00,797 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:00,797 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:00,797 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:00,797 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:00,798 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:00,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:00,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:00,799 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:00,799 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:00,799 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:00,799 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:00,799 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:01,446 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:01,446 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:01,446 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:01,446 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:01,447 [INFO ] nioEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:01,447 [INFO ] nioEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:01,447 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:01,447 [INFO ] nioEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:01,447 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:01,447 [INFO ] nioEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:01,447 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:01,447 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:01,447 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:01,447 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:01,447 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:01,447 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:01,447 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:01,447 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:01,447 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:01,447 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:01,448 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:01,447 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:01,448 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:01,447 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:01,448 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:01,448 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:01,448 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:01,448 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:01,448 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:01,448 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:01,448 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:01,448 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:01,448 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-06-04T16:38:01,448 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:01,448 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:01,448 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-06-04T16:38:01,448 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:01,448 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-06-04T16:38:01,448 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-06-04T16:38:01,448 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:01,448 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:01,449 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:01,449 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:01,450 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:01,451 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:01,451 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:01,451 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:01,451 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:01,451 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:01,450 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:01,451 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:01,451 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:01,451 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:01,451 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:01,451 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:01,451 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:01,451 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:02,743 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:02,743 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:02,759 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:02,759 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:02,759 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:02,759 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:02,805 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:02,805 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:03,461 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:03,461 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:03,461 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:03,461 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:03,999 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:38:04,000 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:38:04,001 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:38:04,005 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:04,005 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]19128
2025-06-04T16:38:04,005 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:04,005 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,005 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,005 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:04,005 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:04,005 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:04,006 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:04,007 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]18136
2025-06-04T16:38:04,007 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,007 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:04,007 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,007 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:04,007 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884007
2025-06-04T16:38:04,007 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:04,007 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:38:04,007 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884007
2025-06-04T16:38:04,007 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:04,007 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884007
2025-06-04T16:38:04,007 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884007
2025-06-04T16:38:04,010 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:04,010 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]11872
2025-06-04T16:38:04,010 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,010 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:04,010 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,010 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:04,010 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:04,010 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:04,010 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884010
2025-06-04T16:38:04,010 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884010
2025-06-04T16:38:04,011 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884011
2025-06-04T16:38:04,011 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:38:04,011 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884011
2025-06-04T16:38:04,012 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884012
2025-06-04T16:38:04,012 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884012
2025-06-04T16:38:04,012 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:38:04,012 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884012
2025-06-04T16:38:04,012 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884012
2025-06-04T16:38:04,038 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:38:04,038 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:38:04,038 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:38:04,051 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:38:04,057 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:04,058 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]19596
2025-06-04T16:38:04,058 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:04,058 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,058 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,058 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:04,058 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:04,058 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:04,059 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884059
2025-06-04T16:38:04,059 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:38:04,059 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884059
2025-06-04T16:38:04,060 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884060
2025-06-04T16:38:04,060 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884060
2025-06-04T16:38:04,085 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:38:04,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:04,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:04,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:04,101 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:04,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:04,101 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:04,101 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:04,101 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:04,103 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:04,144 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:04,145 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:04,145 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:04,745 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:38:04,745 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:38:04,751 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:04,751 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]25308
2025-06-04T16:38:04,751 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:04,751 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,751 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:04,751 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:04,751 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,752 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:04,752 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]7456
2025-06-04T16:38:04,752 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:04,752 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:04,752 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,752 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:04,752 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:04,752 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:04,752 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:04,753 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884753
2025-06-04T16:38:04,753 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:38:04,753 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884753
2025-06-04T16:38:04,753 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884753
2025-06-04T16:38:04,753 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884753
2025-06-04T16:38:04,753 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029884753
2025-06-04T16:38:04,753 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884753
2025-06-04T16:38:04,753 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884753
2025-06-04T16:38:04,753 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:38:04,753 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029884753
2025-06-04T16:38:04,772 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:38:04,772 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:38:04,833 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:04,833 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:04,833 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:04,833 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:04,834 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:04,834 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:05,435 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:05,435 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:05,435 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:05,435 [INFO ] nioEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:05,435 [INFO ] nioEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:05,435 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:05,435 [INFO ] nioEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:05,435 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:05,435 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:05,435 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:05,435 [INFO ] nioEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:05,435 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:05,436 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:05,435 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:05,436 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:05,435 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:05,436 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:05,436 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:05,436 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:05,436 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:05,436 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:05,436 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:05,436 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:05,436 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:05,436 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:05,436 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:05,436 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:05,436 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:05,437 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:05,436 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:05,437 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:05,437 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:05,437 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,437 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,437 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:05,437 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:05,437 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:05,437 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:05,437 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:05,437 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,437 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,437 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:05,437 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:05,437 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-06-04T16:38:05,437 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:05,437 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:05,437 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:05,437 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:05,437 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-06-04T16:38:05,437 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:05,437 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-06-04T16:38:05,437 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:05,437 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-06-04T16:38:05,437 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:05,438 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:05,438 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:05,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:05,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:05,439 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:05,439 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:05,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:05,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:05,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:05,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:05,439 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:05,439 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:05,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:05,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:05,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:05,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:05,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:05,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:05,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:05,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:05,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:05,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:05,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,440 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:05,441 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,440 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,441 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:05,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:05,441 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:05,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,441 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:05,441 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:05,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:05,441 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:05,441 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:05,443 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:05,443 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:05,459 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:05,459 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:05,460 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:05,460 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:05,460 [INFO ] nioEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:05,460 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:05,460 [INFO ] nioEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:05,460 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:05,460 [INFO ] nioEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:05,460 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:05,460 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:05,460 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:05,460 [INFO ] nioEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:05,460 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:05,460 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:05,460 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:05,460 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:05,460 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:05,460 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:05,460 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:05,460 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,460 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:05,460 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:05,461 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,460 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:05,460 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:05,461 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:05,461 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:05,460 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:05,461 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:05,461 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:05,461 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:05,461 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:05,461 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:05,461 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:05,461 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:05,461 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:05,461 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:05,461 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:05,461 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:05,461 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:05,461 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:05,461 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:05,461 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:05,461 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,461 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:05,461 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,461 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:05,461 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-06-04T16:38:05,461 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:05,461 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:05,462 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:05,462 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:05,463 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:05,463 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:05,464 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:05,464 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:05,464 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,464 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:05,464 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,464 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:05,464 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:05,464 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:05,464 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:05,464 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:05,464 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,464 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:05,464 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,464 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,464 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:05,464 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,464 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:05,465 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:05,465 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:05,465 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:05,465 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:05,465 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:05,465 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:05,465 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:05,465 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:05,465 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:05,465 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:06,239 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:06,239 [INFO ] nioEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:06,239 [INFO ] nioEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:06,239 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:06,239 [INFO ] nioEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:06,240 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:06,239 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:06,239 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:06,239 [INFO ] nioEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:06,240 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:06,240 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:06,240 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:06,240 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:06,240 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:06,240 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:06,240 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:06,240 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:06,240 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:06,241 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:06,240 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:06,241 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:06,240 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:06,241 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:06,241 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:06,240 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:06,241 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:06,241 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:06,241 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:06,241 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:06,241 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:06,241 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:06,241 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:06,241 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:06,241 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:06,241 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:06,243 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:06,243 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:06,244 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:06,244 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:06,244 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:06,244 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:06,244 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:06,244 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:06,244 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:06,244 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:06,244 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:06,244 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:06,244 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:06,244 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:06,244 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:06,244 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:06,244 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:06,244 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:06,244 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:06,244 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:06,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:06,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:06,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:06,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:06,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:06,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:06,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:06,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:06,245 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:06,245 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:06,246 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:06,246 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:06,246 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:06,246 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:06,246 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:06,246 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:06,246 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:08,441 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:08,441 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:08,441 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:08,441 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:08,471 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:08,471 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:08,471 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:08,471 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:09,253 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:09,253 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:09,254 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:09,254 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:09,693 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:38:09,693 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:38:09,699 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:09,699 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]27268
2025-06-04T16:38:09,699 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:09,699 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:09,699 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:09,699 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:09,699 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:09,700 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:09,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]4752
2025-06-04T16:38:09,700 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:09,700 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:09,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:09,700 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:09,700 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:09,700 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:09,700 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:09,701 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029889701
2025-06-04T16:38:09,701 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029889701
2025-06-04T16:38:09,701 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:38:09,701 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029889701
2025-06-04T16:38:09,701 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029889701
2025-06-04T16:38:09,702 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029889702
2025-06-04T16:38:09,702 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029889702
2025-06-04T16:38:09,701 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:38:09,702 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029889702
2025-06-04T16:38:09,702 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029889702
2025-06-04T16:38:09,721 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:38:09,721 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:38:09,722 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:09,722 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]20736
2025-06-04T16:38:09,722 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:09,722 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:09,722 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:09,722 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:09,723 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:09,723 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:09,735 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:09,735 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]32712
2025-06-04T16:38:09,736 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:09,736 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:09,736 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:09,736 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:09,736 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:09,736 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:38:09,736 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:09,736 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:38:09,737 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029889737
2025-06-04T16:38:09,737 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029889737
2025-06-04T16:38:09,737 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029889737
2025-06-04T16:38:09,737 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029889737
2025-06-04T16:38:09,737 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:38:09,739 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:38:09,739 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029889739
2025-06-04T16:38:09,739 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029889739
2025-06-04T16:38:09,740 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029889740
2025-06-04T16:38:09,740 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029889740
2025-06-04T16:38:09,749 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:38:09,755 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:38:09,805 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:09,805 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:09,806 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:09,806 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:09,806 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:09,806 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:09,814 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:09,815 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:09,815 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:09,819 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:09,820 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:09,820 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:10,581 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:38:10,583 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:38:10,588 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:10,588 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]31856
2025-06-04T16:38:10,588 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:10,588 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:10,588 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:10,588 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:10,588 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:10,588 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:10,589 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:10,589 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]3872
2025-06-04T16:38:10,589 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:10,589 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:10,589 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:10,589 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:10,589 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:10,589 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:10,590 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029890590
2025-06-04T16:38:10,590 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029890590
2025-06-04T16:38:10,590 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:38:10,590 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029890590
2025-06-04T16:38:10,590 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029890590
2025-06-04T16:38:10,592 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:38:10,592 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029890592
2025-06-04T16:38:10,592 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029890592
2025-06-04T16:38:10,592 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029890592
2025-06-04T16:38:10,592 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029890592
2025-06-04T16:38:10,615 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:38:10,615 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:38:10,675 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:10,675 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:10,675 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:10,675 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:10,675 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:10,676 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:13,188 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:13,188 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,188 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:13,188 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,188 [INFO ] nioEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,188 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:13,188 [INFO ] nioEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,188 [INFO ] nioEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,188 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:13,188 [INFO ] nioEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,188 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:13,189 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,188 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:13,188 [INFO ] nioEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,189 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,188 [INFO ] nioEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,189 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,189 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,189 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,189 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,189 [INFO ] nioEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,189 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:13,189 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,189 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,189 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:13,189 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:13,190 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:13,189 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,189 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,190 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:13,190 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,189 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:13,190 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:13,190 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,190 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,189 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:13,189 [INFO ] nioEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,190 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,190 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,190 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:13,190 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,190 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:13,190 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,190 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,191 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:13,189 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,191 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:13,190 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,190 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,190 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:13,190 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,191 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,190 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:13,191 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:13,191 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2025-06-04T16:38:13,191 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2025-06-04T16:38:13,191 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,191 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:13,191 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,191 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,191 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:13,191 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,191 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,191 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,191 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,191 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:13,191 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:13,191 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,191 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,191 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:13,191 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,191 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:13,191 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,191 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,191 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,191 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2025-06-04T16:38:13,191 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:13,191 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:13,193 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,191 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:13,191 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:13,191 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2025-06-04T16:38:13,191 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,191 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,193 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:13,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,193 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-06-04T16:38:13,193 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,193 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:13,193 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:13,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,193 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-06-04T16:38:13,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,193 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:13,193 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:13,193 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,193 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,193 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,193 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:13,194 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2025-06-04T16:38:13,194 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:13,194 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:13,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:13,194 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2025-06-04T16:38:13,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:13,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:13,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:13,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,194 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:13,194 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:13,194 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:13,194 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:13,194 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,194 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:13,194 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:13,194 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:13,195 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:13,194 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:13,195 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,195 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:13,195 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:13,195 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:13,195 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,195 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,195 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:13,195 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,196 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:13,195 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:13,195 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:13,196 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,196 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:13,196 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:13,196 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,196 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:13,196 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:13,196 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:13,196 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:13,196 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:13,197 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:13,197 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:13,197 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,197 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:13,197 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:13,197 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:13,197 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:13,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:13,197 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:13,197 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:13,197 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:13,197 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:13,197 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:13,197 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:13,197 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:13,197 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,198 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:13,198 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:13,197 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:13,198 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:13,198 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:13,198 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:13,198 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:13,198 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:13,198 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:13,198 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:13,198 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:13,198 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:13,198 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:13,198 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:13,198 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:13,198 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:13,198 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:13,199 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:13,199 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:13,199 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:13,199 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:13,199 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,199 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:13,199 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:13,199 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,199 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,199 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:13,199 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:13,199 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,199 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:13,199 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,199 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,199 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:13,199 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:13,199 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,199 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:13,199 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:13,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:13,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,200 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:13,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,200 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,200 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,200 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:13,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:13,200 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:13,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,200 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,200 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:13,200 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,200 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:13,200 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:13,200 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,202 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:13,202 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:13,202 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:13,202 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,202 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:13,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:13,202 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:13,202 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:13,202 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:13,202 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:13,202 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:13,202 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:13,852 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:13,852 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,853 [INFO ] nioEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,853 [INFO ] nioEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,853 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:13,852 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:13,853 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:13,853 [INFO ] nioEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,853 [INFO ] nioEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:13,853 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,853 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:13,853 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,853 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,853 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:13,853 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,853 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:13,853 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,853 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:13,853 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,853 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:13,853 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,854 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,853 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:13,854 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:13,853 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:13,854 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:13,854 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,854 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,854 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,854 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,854 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,853 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:13,854 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,854 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:13,854 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:13,854 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,854 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:13,854 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2025-06-04T16:38:13,854 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:13,854 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:13,854 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2025-06-04T16:38:13,854 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,854 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:13,855 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:13,857 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:13,855 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:13,857 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:13,857 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:13,857 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:13,857 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:13,857 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:13,857 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:13,857 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:13,857 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:13,857 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,857 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:13,857 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,857 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:13,857 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,857 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:13,857 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:13,858 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,858 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,858 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:13,858 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:13,858 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:13,858 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:13,858 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:13,858 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:13,858 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:18,199 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,199 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,199 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,199 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,199 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,199 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,199 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,199 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,867 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,867 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,868 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:18,868 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:19,520 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:38:19,525 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:38:19,525 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:38:19,525 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:38:19,527 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:19,527 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]15656
2025-06-04T16:38:19,527 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:19,527 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:19,527 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:19,527 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:19,527 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:19,527 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:19,528 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:38:19,528 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029899528
2025-06-04T16:38:19,528 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029899528
2025-06-04T16:38:19,529 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029899529
2025-06-04T16:38:19,529 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029899529
2025-06-04T16:38:19,533 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:19,534 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:19,534 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]17480
2025-06-04T16:38:19,534 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:19,534 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]22520
2025-06-04T16:38:19,534 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:19,534 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:19,534 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:19,534 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:19,534 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:19,534 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:19,535 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:19,534 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:19,535 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]13160
2025-06-04T16:38:19,535 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:19,535 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:19,535 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:19,535 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:19,535 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:19,535 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:19,535 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:19,535 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:19,535 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:19,535 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:19,554 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:38:19,554 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:38:19,554 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029899554
2025-06-04T16:38:19,554 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029899554
2025-06-04T16:38:19,554 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029899554
2025-06-04T16:38:19,554 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029899554
2025-06-04T16:38:19,554 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029899554
2025-06-04T16:38:19,554 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029899554
2025-06-04T16:38:19,554 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029899554
2025-06-04T16:38:19,554 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029899554
2025-06-04T16:38:19,554 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029899554
2025-06-04T16:38:19,554 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:38:19,554 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029899554
2025-06-04T16:38:19,554 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029899554
2025-06-04T16:38:19,554 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029899554
2025-06-04T16:38:19,555 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:38:19,573 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:38:19,573 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:38:19,573 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:38:19,616 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:19,616 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:19,616 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:19,634 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:19,634 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:19,634 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:19,634 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:19,635 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:19,635 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:19,635 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:19,635 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:19,635 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:20,158 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:38:20,160 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:38:20,163 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:20,164 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]3096
2025-06-04T16:38:20,164 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:20,164 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:20,164 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:20,164 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:20,164 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:20,164 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:20,165 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029900165
2025-06-04T16:38:20,165 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:38:20,165 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029900165
2025-06-04T16:38:20,166 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029900166
2025-06-04T16:38:20,166 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029900166
2025-06-04T16:38:20,169 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:20,169 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]29028
2025-06-04T16:38:20,169 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:20,169 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:20,169 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:20,169 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:20,169 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:20,169 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:20,171 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029900171
2025-06-04T16:38:20,171 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029900171
2025-06-04T16:38:20,171 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029900171
2025-06-04T16:38:20,171 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:38:20,171 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029900171
2025-06-04T16:38:20,194 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:38:20,194 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:38:20,254 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:20,254 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:20,254 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:20,254 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:20,255 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:20,255 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:21,321 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:21,321 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:21,321 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,321 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,322 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:21,322 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:21,322 [INFO ] nioEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,322 [INFO ] nioEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,322 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:21,322 [INFO ] nioEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,322 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,322 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:21,322 [INFO ] nioEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,322 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:21,322 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,322 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:21,322 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,322 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,322 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:21,322 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,322 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,322 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,323 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,323 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:21,323 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,323 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:21,323 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:21,323 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,323 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,323 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,323 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,323 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:21,323 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,323 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,323 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,323 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,323 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:21,323 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:21,323 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,323 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,323 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,323 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,324 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,323 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:21,324 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,324 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,324 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:21,325 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:21,325 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,326 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,326 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:21,327 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,327 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:21,327 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:21,327 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:21,327 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:21,327 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:21,327 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:21,327 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:21,352 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:21,352 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,353 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,353 [INFO ] nioEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:21,353 [INFO ] nioEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,353 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:21,353 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:21,353 [INFO ] nioEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:21,353 [INFO ] nioEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,353 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:21,353 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,353 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:21,353 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,353 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,353 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,353 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,353 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,353 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,353 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,353 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,353 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,353 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,353 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:21,353 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:21,353 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,353 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,353 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:21,353 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,353 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,354 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,353 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,353 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:21,353 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,354 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,354 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:21,354 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,354 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,354 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:21,354 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:21,354 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:21,354 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:21,354 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,354 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2025-06-04T16:38:21,354 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2025-06-04T16:38:21,354 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,354 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2025-06-04T16:38:21,354 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2025-06-04T16:38:21,354 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:21,354 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:21,354 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:21,354 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:21,354 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:21,355 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:21,355 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,355 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,355 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:21,355 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:21,355 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,355 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,355 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,355 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,355 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:21,355 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:21,355 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:21,355 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:21,355 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:21,355 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:21,355 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:21,355 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:21,356 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:21,356 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:21,356 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:21,356 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:21,356 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:21,356 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:21,356 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:21,356 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:21,356 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:21,356 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:21,356 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:21,356 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:21,356 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:21,356 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:21,357 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,357 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,357 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,357 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,357 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:21,357 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:21,357 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:21,357 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,357 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,358 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,358 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,357 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:21,358 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,358 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:21,358 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:21,358 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:21,358 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:21,358 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:21,358 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:21,358 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:21,358 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:21,689 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:21,689 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,689 [INFO ] nioEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,689 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:21,689 [INFO ] nioEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,690 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:21,690 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,690 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:21,690 [INFO ] nioEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,690 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,690 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:21,690 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,690 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:21,690 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,690 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,690 [INFO ] nioEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:21,690 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,690 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:21,690 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,690 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,690 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,690 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:21,690 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,690 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:21,690 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,690 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:21,690 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,690 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:21,690 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:21,690 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:21,690 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,690 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,690 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:21,690 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:21,690 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:21,692 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:21,690 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,690 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,692 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:21,692 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:21,692 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2025-06-04T16:38:21,692 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,692 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2025-06-04T16:38:21,692 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,692 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,692 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,692 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,692 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:21,692 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:21,692 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,692 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:21,692 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:21,692 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:21,692 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,692 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:21,692 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:21,692 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:21,693 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:21,693 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:21,693 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2025-06-04T16:38:21,693 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:21,693 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,693 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2025-06-04T16:38:21,693 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,693 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:21,693 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:21,693 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,693 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:21,693 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,694 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:21,693 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:21,694 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:21,694 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:21,694 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:21,694 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:21,694 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:21,694 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:21,694 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:21,694 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:21,694 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:21,694 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:21,694 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:21,694 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:21,695 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:21,695 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:21,695 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:21,695 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:21,695 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:21,695 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:21,695 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:21,695 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:21,695 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:21,695 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:21,695 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:21,696 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,696 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:21,696 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,696 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:21,696 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,696 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,696 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:21,696 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:21,696 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:21,696 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:21,696 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,696 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,696 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:21,697 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,697 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,697 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:21,697 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:21,697 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:21,697 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:29,327 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,327 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,328 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,328 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,355 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,355 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,355 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,355 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,700 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,700 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,700 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:29,700 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:30,608 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:38:30,609 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:38:30,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:30,614 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:30,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]23188
2025-06-04T16:38:30,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:30,614 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,614 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:30,614 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]9852
2025-06-04T16:38:30,614 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,615 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:30,615 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:30,615 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,615 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:30,615 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,615 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:30,615 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:30,615 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:30,616 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910616
2025-06-04T16:38:30,616 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:38:30,616 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910616
2025-06-04T16:38:30,616 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910616
2025-06-04T16:38:30,616 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910616
2025-06-04T16:38:30,616 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910616
2025-06-04T16:38:30,616 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910616
2025-06-04T16:38:30,617 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910617
2025-06-04T16:38:30,616 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:38:30,617 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910617
2025-06-04T16:38:30,635 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:38:30,635 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:38:30,635 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:38:30,635 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:38:30,640 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:30,641 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]12148
2025-06-04T16:38:30,641 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:30,641 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,641 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,641 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:30,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:30,641 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:30,641 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:30,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]4672
2025-06-04T16:38:30,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:30,641 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,641 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:30,641 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:30,641 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:30,643 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910643
2025-06-04T16:38:30,643 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910643
2025-06-04T16:38:30,643 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910643
2025-06-04T16:38:30,643 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910643
2025-06-04T16:38:30,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:38:30,643 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910643
2025-06-04T16:38:30,643 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910643
2025-06-04T16:38:30,643 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:38:30,643 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910643
2025-06-04T16:38:30,643 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910643
2025-06-04T16:38:30,667 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:38:30,667 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:38:30,706 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:30,706 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:30,706 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:30,707 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:30,707 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:30,707 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:30,731 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:30,732 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:30,732 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:30,732 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:30,732 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:30,732 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:30,990 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:38:30,995 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:38:30,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:30,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]9320
2025-06-04T16:38:30,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:30,996 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,996 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:30,996 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:30,996 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:30,996 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:30,998 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:38:30,998 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910998
2025-06-04T16:38:30,998 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029910998
2025-06-04T16:38:30,998 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910998
2025-06-04T16:38:30,998 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029910998
2025-06-04T16:38:31,003 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:31,003 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]24816
2025-06-04T16:38:31,003 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:31,003 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:31,003 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:31,003 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:31,003 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:31,003 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:31,006 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029911006
2025-06-04T16:38:31,006 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029911006
2025-06-04T16:38:31,007 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029911007
2025-06-04T16:38:31,007 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:38:31,007 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029911007
2025-06-04T16:38:31,026 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:38:31,029 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:38:31,088 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:31,088 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:31,089 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:31,089 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:31,089 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:31,089 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:32,203 [INFO ] nioEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:32,203 [INFO ] nioEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,203 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,203 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,203 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,203 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,203 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:32,204 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:32,204 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:32,204 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,204 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,204 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,204 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,204 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,205 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:32,206 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:32,207 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:32,207 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:32,207 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,207 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,207 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:32,207 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:32,207 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:32,207 [INFO ] nioEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,207 [INFO ] nioEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,207 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:32,207 [INFO ] nioEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,207 [INFO ] nioEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,207 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,208 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,207 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:32,208 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,207 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:32,208 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:32,207 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,208 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,208 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:32,208 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,208 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,208 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,208 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:32,208 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,208 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:32,208 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,208 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:32,208 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,208 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,208 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:32,208 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,208 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,208 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,208 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,208 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,208 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,209 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,208 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,208 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,209 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,209 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:32,209 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2025-06-04T16:38:32,209 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,209 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2025-06-04T16:38:32,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:32,209 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:32,209 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2025-06-04T16:38:32,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:32,209 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2025-06-04T16:38:32,209 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:32,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,209 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:32,209 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:32,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:32,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:32,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:32,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:32,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:32,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:32,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:32,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:32,210 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:32,210 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,211 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,211 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:32,213 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:32,213 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:32,323 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:32,324 [INFO ] nioEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:32,324 [INFO ] nioEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,324 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,324 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:32,324 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:32,324 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:32,324 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,324 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:32,324 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:32,324 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,324 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:32,324 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,324 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,325 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:32,326 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,326 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,326 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,326 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:32,326 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:32,326 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:32,326 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:32,326 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:32,326 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:32,684 [INFO ] nioEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:32,684 [INFO ] nioEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,684 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,684 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:32,684 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,684 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:32,684 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,685 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:32,684 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:32,685 [INFO ] nioEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,685 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:32,685 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,685 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:32,685 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,685 [INFO ] nioEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:32,685 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,685 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,685 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:32,685 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:32,685 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:32,685 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:32,685 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:32,685 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,685 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,685 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:32,685 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:32,685 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,685 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:32,685 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,685 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:32,685 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:32,685 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:32,685 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2025-06-04T16:38:32,686 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,686 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2025-06-04T16:38:32,685 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:32,686 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,686 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,686 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,686 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:32,686 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:32,686 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:32,686 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:32,686 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:32,686 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,686 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:32,687 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:32,688 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:32,687 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:32,688 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:32,688 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:45,218 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,218 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,219 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,218 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,219 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,218 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,341 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,341 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,699 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,699 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,699 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:45,699 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:38:46,552 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:38:46,555 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:38:46,557 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:38:46,558 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:46,558 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]22076
2025-06-04T16:38:46,559 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:46,558 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:46,559 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:46,559 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:46,559 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:46,559 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:38:46,560 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029926560
2025-06-04T16:38:46,560 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029926560
2025-06-04T16:38:46,560 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:38:46,560 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029926560
2025-06-04T16:38:46,560 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029926560
2025-06-04T16:38:46,563 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:46,563 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]14088
2025-06-04T16:38:46,563 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:46,563 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:46,563 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:46,563 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:46,564 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:46,564 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:38:46,565 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029926565
2025-06-04T16:38:46,565 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:46,565 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029926565
2025-06-04T16:38:46,566 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]18796
2025-06-04T16:38:46,566 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029926566
2025-06-04T16:38:46,566 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:38:46,566 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:46,566 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:46,566 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029926566
2025-06-04T16:38:46,566 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:46,566 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:46,566 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:46,566 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:38:46,577 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029926577
2025-06-04T16:38:46,577 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029926577
2025-06-04T16:38:46,578 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029926578
2025-06-04T16:38:46,578 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029926578
2025-06-04T16:38:46,578 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:38:46,591 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:38:46,591 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:38:46,596 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:38:46,651 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:38:46,655 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:46,656 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:46,656 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:46,656 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:46,656 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:46,656 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:46,656 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:46,656 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:46,656 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:46,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:46,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]27812
2025-06-04T16:38:46,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:46,657 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:46,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:46,657 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:46,657 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:46,657 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:38:46,659 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029926659
2025-06-04T16:38:46,659 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029926659
2025-06-04T16:38:46,659 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029926659
2025-06-04T16:38:46,659 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029926659
2025-06-04T16:38:46,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:38:46,670 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:38:46,732 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:46,732 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:46,732 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:47,020 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:38:47,022 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:38:47,026 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:47,026 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]19116
2025-06-04T16:38:47,026 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:47,026 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:47,026 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:47,026 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:47,027 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:47,027 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:38:47,027 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:38:47,028 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029927028
2025-06-04T16:38:47,028 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029927028
2025-06-04T16:38:47,028 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029927028
2025-06-04T16:38:47,028 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:38:47,028 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029927028
2025-06-04T16:38:47,028 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]31552
2025-06-04T16:38:47,028 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:47,028 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:38:47,028 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:38:47,028 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:38:47,031 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:47,031 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:38:47,033 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029927031
2025-06-04T16:38:47,031 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:38:47,033 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029927031
2025-06-04T16:38:47,033 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029927033
2025-06-04T16:38:47,033 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029927033
2025-06-04T16:38:47,061 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:38:47,061 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:38:47,123 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:47,123 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:47,124 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:47,124 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:38:47,124 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:38:47,125 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:38:48,110 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:48,110 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,110 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:48,110 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:48,110 [INFO ] nioEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,110 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:48,110 [INFO ] nioEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,110 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,110 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:48,110 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:48,110 [INFO ] nioEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,110 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,110 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,110 [INFO ] nioEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,111 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,110 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,111 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,111 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:48,111 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:48,111 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,112 [INFO ] nioEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,111 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,112 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,111 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:48,112 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,112 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,111 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,111 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,112 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:48,112 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:48,112 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:48,112 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,112 [INFO ] nioEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,112 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:48,112 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,112 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:48,112 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:38:48,112 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,112 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:48,112 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,112 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,112 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:48,112 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,112 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,112 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,112 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:38:48,113 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,112 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,112 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:48,113 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:48,112 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,112 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:48,113 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,113 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,113 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,113 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,113 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2025-06-04T16:38:48,112 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,113 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:48,113 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,113 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:48,113 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,113 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:38:48,113 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2025-06-04T16:38:48,113 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2025-06-04T16:38:48,113 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,113 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,113 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,113 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,113 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,113 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,113 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2025-06-04T16:38:48,113 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2025-06-04T16:38:48,113 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2025-06-04T16:38:48,113 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:48,113 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,113 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:48,113 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,114 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:48,113 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:48,114 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,114 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:48,114 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:48,114 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:48,114 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:48,114 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:48,114 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:48,114 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,114 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,114 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,114 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,114 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:48,114 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:48,114 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:48,114 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:48,114 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:48,114 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:48,114 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:48,114 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:48,114 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:48,115 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,115 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:48,115 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:48,115 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:48,115 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:48,115 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,115 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:48,115 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:38:48,115 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:38:48,115 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:48,115 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,115 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,115 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:38:48,115 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:48,115 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,115 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:48,115 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:48,115 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,116 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:48,116 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:48,116 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:48,116 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:48,116 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:48,116 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:48,116 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:48,116 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:48,116 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:48,116 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:48,116 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:48,116 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:48,116 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:48,116 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:48,117 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:48,117 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:48,117 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:48,117 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:48,117 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:48,117 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:48,117 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:48,117 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,117 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:48,117 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:48,117 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,117 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:48,118 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,118 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:48,118 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:48,118 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:48,118 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,118 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,118 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:48,118 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:48,118 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,118 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:48,118 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,118 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,118 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,119 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,118 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,119 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:48,119 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:48,119 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:48,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,119 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:48,119 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,119 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:48,119 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,119 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:38:48,119 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:48,119 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:48,119 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:48,119 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:48,120 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:48,120 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:48,120 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:38:48,120 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:48,161 [INFO ] nioEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:48,161 [INFO ] nioEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:48,161 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,161 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,161 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,161 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,161 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:48,163 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:48,163 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:48,163 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,163 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,163 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,163 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,163 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:38:48,164 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:38:48,485 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:48,485 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,485 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:48,487 [INFO ] nioEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:48,487 [INFO ] nioEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:48,487 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:48,487 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,487 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,487 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:48,487 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:48,487 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:48,487 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,487 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,487 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:48,487 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:48,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:48,488 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:48,489 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:38:48,491 [INFO ] nioEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:38:48,491 [INFO ] nioEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,491 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,491 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,491 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:38:48,491 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,491 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:38:48,492 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:38:48,492 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:38:48,492 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:38:48,492 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:38:48,492 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:38:48,492 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2025-06-04T16:38:48,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:38:48,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:38:48,494 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:48,494 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:38:48,494 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:38:48,494 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:39:09,131 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,131 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,131 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,131 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,131 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,131 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,176 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,176 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,501 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,501 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,501 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:09,501 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:10,469 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:39:10,469 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:39:10,474 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:39:10,475 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:10,475 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]18560
2025-06-04T16:39:10,475 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,475 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:10,475 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,475 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:10,475 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:39:10,475 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:39:10,475 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:10,475 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]11720
2025-06-04T16:39:10,476 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,476 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:10,476 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,476 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:39:10,476 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:10,476 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:39:10,476 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950476
2025-06-04T16:39:10,476 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:39:10,476 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950476
2025-06-04T16:39:10,476 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950476
2025-06-04T16:39:10,476 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950476
2025-06-04T16:39:10,479 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:39:10,479 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950479
2025-06-04T16:39:10,479 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950479
2025-06-04T16:39:10,479 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950479
2025-06-04T16:39:10,479 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950479
2025-06-04T16:39:10,484 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:10,486 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]20212
2025-06-04T16:39:10,486 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,486 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:10,486 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,486 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:39:10,486 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:10,486 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:39:10,498 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:39:10,498 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:39:10,498 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:10,499 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]19152
2025-06-04T16:39:10,499 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950499
2025-06-04T16:39:10,499 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,499 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:10,499 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,499 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950499
2025-06-04T16:39:10,499 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:39:10,499 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:10,499 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:39:10,499 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950499
2025-06-04T16:39:10,499 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:39:10,499 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:39:10,499 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950499
2025-06-04T16:39:10,500 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950500
2025-06-04T16:39:10,500 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950500
2025-06-04T16:39:10,500 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950500
2025-06-04T16:39:10,500 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950500
2025-06-04T16:39:10,500 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:39:10,530 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:39:10,530 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:39:10,564 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:10,564 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:10,564 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:10,564 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:10,565 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:10,565 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:10,583 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:10,583 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:10,583 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:10,590 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:10,590 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:10,590 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:10,812 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:39:10,815 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:39:10,818 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:10,818 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]19004
2025-06-04T16:39:10,818 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,818 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:10,818 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,818 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:10,818 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:39:10,818 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:39:10,820 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950820
2025-06-04T16:39:10,820 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:39:10,820 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950820
2025-06-04T16:39:10,820 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950820
2025-06-04T16:39:10,820 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950820
2025-06-04T16:39:10,823 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:10,824 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]13528
2025-06-04T16:39:10,824 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:10,824 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,824 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:10,824 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:10,824 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:39:10,824 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:39:10,826 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950826
2025-06-04T16:39:10,826 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029950826
2025-06-04T16:39:10,826 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950826
2025-06-04T16:39:10,826 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:39:10,826 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029950826
2025-06-04T16:39:10,842 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:39:10,856 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:39:10,903 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:10,903 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:10,903 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:10,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:10,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:10,916 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:11,967 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:11,968 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:11,968 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:11,968 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:11,968 [INFO ] nioEventLoopGroup-5-52 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:11,968 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:11,968 [INFO ] nioEventLoopGroup-5-51 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:11,968 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:11,968 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:11,968 [INFO ] nioEventLoopGroup-5-51 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:11,968 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:11,968 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:11,968 [INFO ] nioEventLoopGroup-5-52 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:11,969 [INFO ] nioEventLoopGroup-5-49 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:11,968 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:11,968 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:11,969 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:11,968 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:11,969 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:11,969 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:11,969 [INFO ] nioEventLoopGroup-5-49 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:11,969 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:11,969 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:11,969 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:11,969 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:11,969 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:11,969 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:11,969 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:11,969 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:39:11,969 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:11,969 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:39:11,969 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:11,969 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:11,969 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:11,970 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:39:11,969 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:11,969 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:11,970 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:39:11,970 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:39:11,970 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:11,970 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:11,970 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:11,970 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:39:11,970 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:11,969 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:11,969 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:11,970 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:11,970 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:11,969 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:11,970 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:11,970 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:11,970 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:11,970 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:11,970 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:11,970 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:11,970 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:11,970 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,970 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:11,970 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:11,971 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,971 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2025-06-04T16:39:11,971 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2025-06-04T16:39:11,971 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2025-06-04T16:39:11,971 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,971 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:11,971 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2025-06-04T16:39:11,971 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2025-06-04T16:39:11,971 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2025-06-04T16:39:11,971 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,971 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:11,971 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,971 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,971 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:11,971 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:11,971 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:11,971 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:11,971 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:11,971 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:11,972 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:11,972 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:11,972 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:11,972 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:11,972 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:11,972 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:11,972 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:11,972 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:11,972 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:11,972 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:11,972 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:11,972 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:11,972 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:11,972 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:11,972 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:11,972 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:11,972 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:11,972 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:11,972 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:11,972 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:11,972 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:11,973 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:11,973 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:11,973 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:11,973 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:11,973 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:11,973 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:11,973 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:11,973 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:11,973 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:11,973 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:11,973 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:11,973 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:11,973 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:11,973 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:39:11,973 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:11,973 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:39:11,973 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:39:11,973 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:39:11,973 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:11,973 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:39:11,973 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:11,973 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:11,973 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:39:11,974 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:11,973 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:11,974 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:11,974 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:11,974 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:11,974 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:11,974 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:11,974 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:11,974 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:11,974 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:11,974 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:11,974 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:11,974 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:11,974 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:11,974 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:11,974 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:11,974 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:11,975 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:11,975 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:11,975 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:11,975 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:11,975 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:11,975 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,975 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:11,975 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:11,975 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,975 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:11,975 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:11,975 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:11,975 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:11,975 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,975 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:11,975 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,975 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:11,976 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:11,976 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:11,976 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,976 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:11,976 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:11,976 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,976 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:39:11,976 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:11,976 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:11,976 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:39:11,976 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,976 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:11,976 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,976 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,977 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:11,977 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,977 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:11,977 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:11,977 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,977 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:11,977 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:39:11,977 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,977 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:39:11,977 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:11,977 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:11,977 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:39:11,977 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,986 [INFO ] nioEventLoopGroup-5-50 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:11,986 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,986 [INFO ] nioEventLoopGroup-5-50 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:11,987 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:11,987 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:11,987 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:11,987 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:11,987 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:11,987 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:39:11,987 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:11,987 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:11,987 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:11,988 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:11,988 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:11,988 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:11,989 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:11,989 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:11,989 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:11,990 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:39:11,990 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:39:11,990 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:39:11,990 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:39:12,210 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:12,210 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:12,211 [INFO ] nioEventLoopGroup-5-53 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:12,211 [INFO ] nioEventLoopGroup-5-53 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:12,211 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:12,211 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:12,211 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:12,211 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:12,211 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:39:12,211 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:39:12,211 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:12,211 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:12,212 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:12,211 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:12,212 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:12,212 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:12,213 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:12,215 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:39:12,215 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:39:12,215 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:39:12,215 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:12,226 [INFO ] nioEventLoopGroup-5-54 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:12,226 [INFO ] nioEventLoopGroup-5-54 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:12,226 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:12,226 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:12,226 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:12,226 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:12,227 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:39:12,226 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:12,227 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:39:12,227 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:12,227 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:12,227 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:12,227 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2025-06-04T16:39:12,227 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:12,228 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:39:12,229 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:39:45,974 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:45,974 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:45,974 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:45,974 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:45,974 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:45,974 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:46,004 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:46,004 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:46,221 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:46,221 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:46,237 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:46,237 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:39:47,235 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:39:47,238 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:39:47,242 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:47,242 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]29008
2025-06-04T16:39:47,242 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,242 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:47,242 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,242 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:47,242 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:39:47,242 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:39:47,243 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987243
2025-06-04T16:39:47,243 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987243
2025-06-04T16:39:47,243 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:39:47,243 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987243
2025-06-04T16:39:47,243 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987243
2025-06-04T16:39:47,243 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:47,246 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]11888
2025-06-04T16:39:47,247 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,247 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:47,247 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:47,247 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,247 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:39:47,247 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:39:47,249 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987249
2025-06-04T16:39:47,249 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987249
2025-06-04T16:39:47,249 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987249
2025-06-04T16:39:47,249 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:39:47,249 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987249
2025-06-04T16:39:47,285 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:39:47,285 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:39:47,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:39:47,307 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:47,307 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]3596
2025-06-04T16:39:47,307 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,307 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:47,307 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,307 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:39:47,307 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:47,307 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:39:47,308 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987308
2025-06-04T16:39:47,308 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987308
2025-06-04T16:39:47,308 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:39:47,308 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987308
2025-06-04T16:39:47,308 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987308
2025-06-04T16:39:47,309 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:39:47,311 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:39:47,318 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:47,318 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]27404
2025-06-04T16:39:47,318 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:47,318 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,318 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:47,318 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,318 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:39:47,318 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:39:47,319 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987319
2025-06-04T16:39:47,319 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987319
2025-06-04T16:39:47,319 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:39:47,319 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987319
2025-06-04T16:39:47,319 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987319
2025-06-04T16:39:47,320 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:39:47,345 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:47,346 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:47,346 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:47,346 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:47,346 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:47,346 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:47,367 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:47,367 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:47,367 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:47,379 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:47,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:47,380 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:47,486 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:39:47,487 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:39:47,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:47,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]5292
2025-06-04T16:39:47,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:47,492 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,492 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,492 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:47,493 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:39:47,493 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:39:47,493 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:39:47,493 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]18384
2025-06-04T16:39:47,493 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,493 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:39:47,493 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:39:47,493 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:39:47,493 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:39:47,493 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:39:47,493 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987493
2025-06-04T16:39:47,493 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987493
2025-06-04T16:39:47,493 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:39:47,493 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987493
2025-06-04T16:39:47,493 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987493
2025-06-04T16:39:47,494 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987494
2025-06-04T16:39:47,494 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:39:47,494 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749029987494
2025-06-04T16:39:47,494 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987494
2025-06-04T16:39:47,494 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:39:47,494 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749029987494
2025-06-04T16:39:47,494 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:39:47,555 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:47,555 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:39:47,555 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:47,556 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:39:47,556 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:47,556 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:39:48,640 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,641 [INFO ] nioEventLoopGroup-5-56 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,641 [INFO ] nioEventLoopGroup-5-56 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,641 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,641 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:48,641 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:48,641 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:48,641 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:39:48,641 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:39:48,641 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,641 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,641 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,641 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:48,641 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:48,643 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:39:48,644 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:39:48,654 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:48,654 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,654 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:48,654 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,654 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:48,654 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,654 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:48,655 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,654 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:48,655 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,655 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,655 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,655 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:39:48,655 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:48,655 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:48,655 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,655 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:48,655 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2025-06-04T16:39:48,655 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:48,655 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:48,656 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,656 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,656 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:48,656 [INFO ] nioEventLoopGroup-5-55 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,656 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:48,656 [INFO ] nioEventLoopGroup-5-55 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,656 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:48,656 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,656 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,656 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,656 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:48,656 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,656 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:48,656 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,656 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:48,656 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:48,656 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,656 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,657 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:39:48,657 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,657 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:39:48,657 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,657 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,657 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,657 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:48,657 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:48,657 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2025-06-04T16:39:48,657 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2025-06-04T16:39:48,657 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:48,657 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,657 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:48,657 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:48,658 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:39:48,658 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,659 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:48,659 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,659 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:48,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:48,659 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:48,659 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:48,659 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:39:48,659 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:48,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:48,659 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:39:48,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:48,659 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:48,659 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:48,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:48,659 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,659 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:48,659 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:48,659 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,659 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:48,659 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:48,659 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,659 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,659 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,660 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:48,660 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,660 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,660 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:39:48,660 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,660 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:39:48,660 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,660 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,660 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:48,660 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,660 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,660 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,660 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:48,660 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,660 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:48,660 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,660 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:48,660 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,660 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,660 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,660 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:48,660 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2025-06-04T16:39:48,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:48,661 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:48,661 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,661 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,661 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:39:48,663 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:39:48,778 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:48,778 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,778 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,778 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:48,778 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,778 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:48,778 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,778 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,778 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:48,778 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:48,778 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,778 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,779 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:48,779 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:39:48,779 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:48,779 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,779 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:48,779 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,779 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:48,780 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:48,781 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:39:48,781 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:39:48,781 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:39:48,781 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:39:48,789 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:39:48,789 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,790 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:39:48,790 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:39:48,790 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:39:48,790 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,790 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:39:48,790 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:39:48,790 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:39:48,790 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,790 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:39:48,791 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,791 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:39:48,791 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:39:48,791 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,791 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:39:48,791 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:39:48,791 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:39:48,791 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,791 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:39:48,792 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:39:48,793 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:40:43,657 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,657 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,671 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,671 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,672 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,672 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,672 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,672 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,796 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,796 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,796 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:43,796 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [C:\Users\1\anaconda3\envs\ts_yolo12\python.exe, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml]
2025-06-04T16:40:44,930 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-06-04T16:40:44,935 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:40:44,935 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - [PID]19848
2025-06-04T16:40:44,935 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:44,935 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:40:44,935 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:44,935 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:40:44,935 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:40:44,935 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-06-04T16:40:44,936 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-06-04T16:40:44,936 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030044936
2025-06-04T16:40:44,936 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030044936
2025-06-04T16:40:44,937 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030044937
2025-06-04T16:40:44,937 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030044937
2025-06-04T16:40:44,937 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - model_name: nganmach, batchSize: 1
2025-06-04T16:40:44,958 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-06-04T16:40:44,960 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-06-04T16:40:44,960 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-06-04T16:40:44,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:40:44,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - [PID]4112
2025-06-04T16:40:44,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:40:44,964 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:44,964 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:40:44,964 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:44,964 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:40:44,964 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-06-04T16:40:44,965 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:40:44,965 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - [PID]18372
2025-06-04T16:40:44,965 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-06-04T16:40:44,965 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030044965
2025-06-04T16:40:44,965 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:40:44,965 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030044965
2025-06-04T16:40:44,965 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:44,965 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:40:44,965 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030044965
2025-06-04T16:40:44,965 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:44,965 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:40:44,965 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030044965
2025-06-04T16:40:44,965 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-06-04T16:40:44,966 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:40:44,966 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - model_name: bamdinh, batchSize: 1
2025-06-04T16:40:44,966 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - [PID]28256
2025-06-04T16:40:44,966 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:44,966 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:40:44,966 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:44,966 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:40:44,966 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:40:44,966 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-06-04T16:40:44,966 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030044966
2025-06-04T16:40:44,966 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030044966
2025-06-04T16:40:44,966 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030044966
2025-06-04T16:40:44,967 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030044967
2025-06-04T16:40:44,966 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030044966
2025-06-04T16:40:44,967 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030044967
2025-06-04T16:40:44,966 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-06-04T16:40:44,967 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030044967
2025-06-04T16:40:44,967 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-06-04T16:40:44,967 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030044967
2025-06-04T16:40:44,967 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - model_name: divatma, batchSize: 1
2025-06-04T16:40:44,967 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - model_name: thieudong, batchSize: 1
2025-06-04T16:40:44,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:40:44,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:40:44,997 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:40:45,027 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:40:45,027 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:40:45,027 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:40:45,027 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:40:45,028 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:40:45,028 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:40:45,028 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:40:45,028 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:40:45,028 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:40:45,059 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-06-04T16:40:45,060 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-06-04T16:40:45,065 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:40:45,065 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - [PID]2232
2025-06-04T16:40:45,066 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:45,066 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:40:45,066 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:45,066 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:40:45,066 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:40:45,066 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-06-04T16:40:45,066 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Successfully loaded C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages/ts/configs/metrics.yaml.
2025-06-04T16:40:45,067 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - [PID]31528
2025-06-04T16:40:45,067 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch worker started.
2025-06-04T16:40:45,067 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:45,067 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030045067
2025-06-04T16:40:45,067 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-06-04T16:40:45,067 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-06-04T16:40:45,067 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:40:45,067 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-06-04T16:40:45,067 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030045067
2025-06-04T16:40:45,067 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030045067
2025-06-04T16:40:45,067 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-06-04T16:40:45,067 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030045067
2025-06-04T16:40:45,067 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - model_name: vetlom, batchSize: 1
2025-06-04T16:40:45,068 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030045068
2025-06-04T16:40:45,068 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1749030045068
2025-06-04T16:40:45,068 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030045068
2025-06-04T16:40:45,068 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1749030045068
2025-06-04T16:40:45,068 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-06-04T16:40:45,068 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - model_name: xuoc, batchSize: 1
2025-06-04T16:40:45,131 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:40:45,131 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-06-04T16:40:45,131 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:40:45,131 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-06-04T16:40:45,131 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:40:45,132 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-06-04T16:40:46,253 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:40:46,253 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,253 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,253 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,253 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:40:46,253 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,253 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,253 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:40:46,253 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,253 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,253 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:40:46,253 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:40:46,253 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: nganmach, error: Worker died.
2025-06-04T16:40:46,253 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,253 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:40:46,253 [DEBUG] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-nganmach_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,253 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,253 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,253 [WARN ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\2d2b31de56b24df7be26f166d4807342\yolo_handler.py", line 3, in <module>
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:40:46,254 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stderr
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,255 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,256 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:40:46,256 [INFO ] W-9002-nganmach_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:40:46,256 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:40:46,256 [INFO ] W-9002-nganmach_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-nganmach_1.0-stdout
2025-06-04T16:40:46,297 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:40:46,297 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,297 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,297 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,297 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:40:46,298 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:40:46,298 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:40:46,298 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:40:46,298 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,298 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:40:46,298 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: thieudong, error: Worker died.
2025-06-04T16:40:46,298 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,298 [DEBUG] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-thieudong_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,298 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,298 [WARN ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,298 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\d2282ee37eca4f6182403bb5e092f57b\yolo_handler.py", line 3, in <module>
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:40:46,299 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stderr
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:40:46,300 [INFO ] W-9003-thieudong_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-thieudong_1.0-stdout
2025-06-04T16:40:46,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:40:46,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:40:46,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:40:46,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:40:46,301 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:40:46,301 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,301 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,301 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,301 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,301 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:40:46,301 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:40:46,303 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:40:46,303 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: bamdinh, error: Worker died.
2025-06-04T16:40:46,303 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,303 [DEBUG] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bamdinh_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,303 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\646e17cca1ed4fd4a3a0c2684787ebc3\yolo_handler.py", line 3, in <module>
2025-06-04T16:40:46,303 [WARN ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2025-06-04T16:40:46,303 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:40:46,304 [INFO ] W-9000-bamdinh_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:40:46,305 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:40:46,305 [INFO ] W-9000-bamdinh_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stdout
2025-06-04T16:40:46,305 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:40:46,305 [INFO ] W-9000-bamdinh_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-bamdinh_1.0-stderr
2025-06-04T16:40:46,313 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:40:46,313 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,313 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:40:46,313 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:40:46,313 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,313 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:40:46,313 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,313 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:40:46,314 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,314 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,314 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,314 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,314 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:40:46,314 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: divatma, error: Worker died.
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:40:46,314 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,314 [DEBUG] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-divatma_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,314 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:40:46,314 [WARN ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\8d2a7b6916984b159ef5c5fc57513ab3\yolo_handler.py", line 3, in <module>
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:40:46,314 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:40:46,315 [INFO ] W-9001-divatma_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:40:46,316 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:40:46,316 [INFO ] W-9001-divatma_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stdout
2025-06-04T16:40:46,316 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:40:46,316 [INFO ] W-9001-divatma_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-divatma_1.0-stderr
2025-06-04T16:40:46,362 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:40:46,363 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,363 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,363 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,363 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,363 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,363 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,363 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,363 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: vetlom, error: Worker died.
2025-06-04T16:40:46,363 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,363 [DEBUG] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vetlom_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,363 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:40:46,363 [WARN ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:40:46,363 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\920163841f694fd19f07ab71f477fd8a\yolo_handler.py", line 3, in <module>
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,364 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:40:46,365 [INFO ] W-9004-vetlom_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:40:46,365 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:40:46,365 [INFO ] W-9004-vetlom_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stdout
2025-06-04T16:40:46,365 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:40:46,365 [INFO ] W-9004-vetlom_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-vetlom_1.0-stderr
2025-06-04T16:40:46,377 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,377 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Backend worker process died.
2025-06-04T16:40:46,377 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-06-04T16:40:46,381 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,381 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,381 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 108, in load
2025-06-04T16:40:46,381 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-06-04T16:40:46,381 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 153, in _load_handler_file
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-06-04T16:40:46,382 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,382 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1686) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:229) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2025-06-04T16:40:46,382 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,382 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: xuoc, error: Worker died.
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,382 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,382 [DEBUG] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-xuoc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-06-04T16:40:46,382 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,382 [WARN ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\AppData\Local\Temp\models\024f7abc6e1b48efb8118ae46a66fdca\yolo_handler.py", line 3, in <module>
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     from ultralytics.yolo.utils import ops
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ultralytics.yolo'
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - 
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 263, in <module>
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     worker.run_server()
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 231, in run_server
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 194, in handle_connection
2025-06-04T16:40:46,382 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\Lib\site-packages\ts\model_service_worker.py", line 131, in load_model
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 110, in load
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\site-packages\ts\model_loader.py", line 159, in _load_default_handler
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "C:\Users\1\anaconda3\envs\ts_yolo12\lib\importlib\__init__.py", line 126, in import_module
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.yolo_handler'
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:40:46,384 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
2025-06-04T16:40:46,383 [INFO ] W-9005-xuoc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stderr
2025-06-04T16:40:46,384 [INFO ] W-9005-xuoc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-xuoc_1.0-stdout
