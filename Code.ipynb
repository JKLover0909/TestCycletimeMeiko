{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028f53cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T√¨m th·∫•y 6 file .pt trong th∆∞ m·ª•c C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\n",
      "ƒêang x·ª≠ l√Ω: bamdinh.pt\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.7.0+cpu CPU (Intel Core(TM) i7-14700K)\n",
      " ProTip: Export to OpenVINO format for best performance on Intel CPUs. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\bamdinh.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.7.0+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.7s, saved as 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\bamdinh.torchscript' (10.5 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\bamdinh.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\bamdinh.torchscript imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Bamdinhkhongtot_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Kh√¥ng t√¨m th·∫•y file xu·∫•t: runs\\export\\bamdinh_torchscript.pt\n",
      "ƒêang x·ª≠ l√Ω: divatma.pt\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.7.0+cpu CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\divatma.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.7.0+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.8s, saved as 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\divatma.torchscript' (10.5 MB)\n",
      "\n",
      "Export complete (2.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\divatma.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\divatma.torchscript imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Divatma_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Kh√¥ng t√¨m th·∫•y file xu·∫•t: runs\\export\\divatma_torchscript.pt\n",
      "ƒêang x·ª≠ l√Ω: nganmach.pt\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.7.0+cpu CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\nganmach.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.7.0+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.8s, saved as 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\nganmach.torchscript' (10.5 MB)\n",
      "\n",
      "Export complete (2.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\nganmach.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\nganmach.torchscript imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Ngan_Mach_Annotation.v2i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Kh√¥ng t√¨m th·∫•y file xu·∫•t: runs\\export\\nganmach_torchscript.pt\n",
      "ƒêang x·ª≠ l√Ω: thieudong.pt\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.7.0+cpu CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\thieudong.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.7.0+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.7s, saved as 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\thieudong.torchscript' (10.5 MB)\n",
      "\n",
      "Export complete (2.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\thieudong.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\thieudong.torchscript imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Thieudong_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Kh√¥ng t√¨m th·∫•y file xu·∫•t: runs\\export\\thieudong_torchscript.pt\n",
      "ƒêang x·ª≠ l√Ω: vetlom.pt\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.7.0+cpu CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\vetlom.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.7.0+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.7s, saved as 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\vetlom.torchscript' (10.5 MB)\n",
      "\n",
      "Export complete (1.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\vetlom.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\vetlom.torchscript imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Vetlom_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Kh√¥ng t√¨m th·∫•y file xu·∫•t: runs\\export\\vetlom_torchscript.pt\n",
      "ƒêang x·ª≠ l√Ω: xuoc.pt\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.7.0+cpu CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\xuoc.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.7.0+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.7s, saved as 'C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\xuoc.torchscript' (10.5 MB)\n",
      "\n",
      "Export complete (2.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\xuoc.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\\xuoc.torchscript imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Xuoc_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Kh√¥ng t√¨m th·∫•y file xu·∫•t: runs\\export\\xuoc_torchscript.pt\n",
      "Chuy·ªÉn ƒë·ªïi ho√†n t·∫•t\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def convert_folder_to_torchscript(input_folder, output_folder):\n",
    "    # T·∫°o th∆∞ m·ª•c ƒë·∫ßu ra n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # T√¨m t·∫•t c·∫£ file .pt trong th∆∞ m·ª•c ƒë·∫ßu v√†o\n",
    "    pt_files = [f for f in os.listdir(input_folder) if f.endswith('.pt')]\n",
    "    \n",
    "    print(f\"T√¨m th·∫•y {len(pt_files)} file .pt trong th∆∞ m·ª•c {input_folder}\")\n",
    "    \n",
    "    for pt_file in pt_files:\n",
    "        input_path = os.path.join(input_folder, pt_file)\n",
    "        output_name = os.path.splitext(pt_file)[0] + '.torchscript.pt'\n",
    "        output_path = os.path.join(output_folder, output_name)\n",
    "        \n",
    "        print(f\"ƒêang x·ª≠ l√Ω: {pt_file}\")\n",
    "        \n",
    "        try:\n",
    "            # C√°ch 1: S·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c export t√≠ch h·ª£p\n",
    "            model = YOLO(input_path)\n",
    "            model.export(format=\"torchscript\", imgsz=640, simplify=True)\n",
    "            \n",
    "            # T√¨m file xu·∫•t ra (th∆∞·ªùng trong th∆∞ m·ª•c runs/detect/train/weights/)\n",
    "            export_path = Path(\"runs/export\") / f\"{os.path.splitext(pt_file)[0]}_torchscript.pt\"\n",
    "            if export_path.exists():\n",
    "                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "                os.replace(str(export_path), output_path)\n",
    "                print(f\"ƒê√£ l∆∞u m√¥ h√¨nh TorchScript v√†o: {output_path}\")\n",
    "            else:\n",
    "                print(f\"Kh√¥ng t√¨m th·∫•y file xu·∫•t: {export_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"L·ªói khi s·ª≠ d·ª•ng export: {e}\")\n",
    "            \n",
    "            try:\n",
    "                # C√°ch 2: S·ª≠ d·ª•ng trace thay v√¨ script\n",
    "                print(f\"Th·ª≠ ph∆∞∆°ng ph√°p trace cho {pt_file}...\")\n",
    "                model = YOLO(input_path)\n",
    "                traced_model = model.model.eval().cpu()\n",
    "                \n",
    "                # T·∫°o input m·∫´u cho trace\n",
    "                example_input = torch.rand(1, 3, 640, 640)\n",
    "                \n",
    "                # √Åp d·ª•ng trace\n",
    "                with torch.no_grad():\n",
    "                    traced_model = torch.jit.trace(traced_model, example_input)\n",
    "                    \n",
    "                # L∆∞u m√¥ h√¨nh\n",
    "                traced_model.save(output_path)\n",
    "                print(f\"ƒê√£ l∆∞u m√¥ h√¨nh TorchScript (trace) v√†o: {output_path}\")\n",
    "            except Exception as e2:\n",
    "                print(f\"L·ªói khi s·ª≠ d·ª•ng trace: {e2}\")\n",
    "    \n",
    "    print(\"Chuy·ªÉn ƒë·ªïi ho√†n t·∫•t\")\n",
    "\n",
    "# Ch·ªâ ƒë·ªãnh th∆∞ m·ª•c ƒë·∫ßu v√†o v√† ƒë·∫ßu ra\n",
    "input_folder = r\"C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\ModelYolov12n\"\n",
    "output_folder = r\"C:\\Users\\1\\MeikoAI\\SonCode\\TestCycletimeMeiko\\models\\torchscript\"\n",
    "\n",
    "# Th·ª±c hi·ªán chuy·ªÉn ƒë·ªïi\n",
    "convert_folder_to_torchscript(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8714c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_32758/4034301104.py\", line 3, in <module>\n",
      "    from ultralytics import YOLO\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ultralytics/__init__.py\", line 11, in <module>\n",
      "    from ultralytics.models import NAS, RTDETR, SAM, YOLO, YOLOE, FastSAM, YOLOWorld\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ultralytics/models/__init__.py\", line 3, in <module>\n",
      "    from .fastsam import FastSAM\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ultralytics/models/fastsam/__init__.py\", line 3, in <module>\n",
      "    from .model import FastSAM\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ultralytics/models/fastsam/model.py\", line 6, in <module>\n",
      "    from ultralytics.engine.model import Model\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 8, in <module>\n",
      "    import torch\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è user config directory '/root/.config/Ultralytics' is not writeable, defaulting to '/tmp' or CWD.Alternatively you can define a YOLO_CONFIG_DIR environment variable for this path.\n",
      "ƒêang chuy·ªÉn ƒë·ªïi: /root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.pt\n",
      "Ultralytics 8.3.150 üöÄ Python-3.10.18 torch-2.2.1 CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 4.4s, saved as '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (4.7s)\n",
      "Results saved to \u001b[1m/root/Code/TestCycletimeMeiko/ModelYolov12n_PT\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.onnx imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Bamdinhkhongtot_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ƒê√£ l∆∞u m√¥ h√¨nh ONNX v√†o: /root/Code/TestCycletimeMeiko/ModelYolov12n_ONNX/bamdinh.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def convert_to_onnx(input_path, output_path=None, imgsz=640, opset=12):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi m√¥ h√¨nh YOLOv12 t·ª´ ƒë·ªãnh d·∫°ng .pt sang ONNX\n",
    "    \n",
    "    Args:\n",
    "        input_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file .pt\n",
    "        output_path: ƒê∆∞·ªùng d·∫´n l∆∞u file .onnx (t√πy ch·ªçn)\n",
    "        imgsz: K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o\n",
    "        opset: Phi√™n b·∫£n ONNX opset\n",
    "    \n",
    "    Returns:\n",
    "        Path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ONNX ƒë√£ ƒë∆∞·ª£c t·∫°o\n",
    "    \"\"\"\n",
    "    print(f\"ƒêang chuy·ªÉn ƒë·ªïi: {input_path}\")\n",
    "    \n",
    "    # T·∫°o th∆∞ m·ª•c ch·ª©a output_path n·∫øu ƒë∆∞·ª£c cung c·∫•p\n",
    "    if output_path:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # T·∫£i m√¥ h√¨nh\n",
    "        model = YOLO(input_path)\n",
    "        \n",
    "        # Xu·∫•t sang ONNX\n",
    "        onnx_path = model.export(\n",
    "            format=\"onnx\",\n",
    "            imgsz=imgsz,\n",
    "            opset=opset,\n",
    "            simplify=True,\n",
    "            dynamic=True\n",
    "        )\n",
    "        \n",
    "        # Di chuy·ªÉn file n·∫øu output_path ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh\n",
    "        if output_path and os.path.exists(onnx_path):\n",
    "            os.replace(str(onnx_path), output_path)\n",
    "            onnx_path = output_path\n",
    "            \n",
    "        print(f\"ƒê√£ l∆∞u m√¥ h√¨nh ONNX v√†o: {onnx_path}\")\n",
    "        return onnx_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói khi chuy·ªÉn ƒë·ªïi m√¥ h√¨nh sang ONNX: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ƒê∆∞·ªùng d·∫´n file .pt ƒë·∫ßu v√†o (c·∫ßn thay ƒë·ªïi theo m√¥i tr∆∞·ªùng Linux c·ªßa b·∫°n)\n",
    "    input_path = \"/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.pt\"\n",
    "    \n",
    "    # ƒê∆∞·ªùng d·∫´n l∆∞u file ONNX ƒë·∫ßu ra\n",
    "    output_path = \"/root/Code/TestCycletimeMeiko/ModelYolov12n_ONNX/bamdinh.onnx\"\n",
    "    \n",
    "    # Th·ª±c hi·ªán chuy·ªÉn ƒë·ªïi\n",
    "    convert_to_onnx(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdca9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (1.17.0)\n",
      "Requirement already satisfied: onnxruntime in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (1.22.0)\n",
      "Collecting onnxruntime-gpu\n",
      "  Downloading onnxruntime_gpu-1.22.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: onnxslim in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (0.1.56)\n",
      "Requirement already satisfied: numpy>=1.20 in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (from onnx) (2.2.6)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (from onnx) (6.31.1)\n",
      "Requirement already satisfied: coloredlogs in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/ts_yolo12/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime_gpu-1.22.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (283.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m283.2/283.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnxruntime-gpu\n",
      "Successfully installed onnxruntime-gpu-1.22.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxruntime onnxruntime-gpu onnxslim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65212643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T√¨m th·∫•y 6 file .pt trong th∆∞ m·ª•c /root/Code/TestCycletimeMeiko/ModelYolov12n_PT\n",
      "ƒêang x·ª≠ l√Ω: nganmach.pt\n",
      "ƒêang chuy·ªÉn ƒë·ªïi: /root/Code/TestCycletimeMeiko/ModelYolov12n_PT/nganmach.pt\n",
      "Ultralytics 8.3.150 üöÄ Python-3.10.18 torch-2.2.1 CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/nganmach.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 3.9s, saved as '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/nganmach.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (4.2s)\n",
      "Results saved to \u001b[1m/root/Code/TestCycletimeMeiko/ModelYolov12n_PT\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/nganmach.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/nganmach.onnx imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Ngan_Mach_Annotation.v2i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ƒê√£ l∆∞u m√¥ h√¨nh ONNX v√†o: /root/Code/TestCycletimeMeiko/ModelYolov12n_ONNX/nganmach.onnx\n",
      "ƒêang x·ª≠ l√Ω: xuoc.pt\n",
      "ƒêang chuy·ªÉn ƒë·ªïi: /root/Code/TestCycletimeMeiko/ModelYolov12n_PT/xuoc.pt\n",
      "Ultralytics 8.3.150 üöÄ Python-3.10.18 torch-2.2.1 CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/xuoc.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 3.9s, saved as '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/xuoc.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (4.1s)\n",
      "Results saved to \u001b[1m/root/Code/TestCycletimeMeiko/ModelYolov12n_PT\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/xuoc.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/xuoc.onnx imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Xuoc_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ƒê√£ l∆∞u m√¥ h√¨nh ONNX v√†o: /root/Code/TestCycletimeMeiko/ModelYolov12n_ONNX/xuoc.onnx\n",
      "ƒêang x·ª≠ l√Ω: vetlom.pt\n",
      "ƒêang chuy·ªÉn ƒë·ªïi: /root/Code/TestCycletimeMeiko/ModelYolov12n_PT/vetlom.pt\n",
      "Ultralytics 8.3.150 üöÄ Python-3.10.18 torch-2.2.1 CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/vetlom.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 3.9s, saved as '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/vetlom.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (4.1s)\n",
      "Results saved to \u001b[1m/root/Code/TestCycletimeMeiko/ModelYolov12n_PT\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/vetlom.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/vetlom.onnx imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Vetlom_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ƒê√£ l∆∞u m√¥ h√¨nh ONNX v√†o: /root/Code/TestCycletimeMeiko/ModelYolov12n_ONNX/vetlom.onnx\n",
      "ƒêang x·ª≠ l√Ω: divatma.pt\n",
      "ƒêang chuy·ªÉn ƒë·ªïi: /root/Code/TestCycletimeMeiko/ModelYolov12n_PT/divatma.pt\n",
      "Ultralytics 8.3.150 üöÄ Python-3.10.18 torch-2.2.1 CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/divatma.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 3.9s, saved as '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/divatma.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (4.0s)\n",
      "Results saved to \u001b[1m/root/Code/TestCycletimeMeiko/ModelYolov12n_PT\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/divatma.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/divatma.onnx imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Divatma_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ƒê√£ l∆∞u m√¥ h√¨nh ONNX v√†o: /root/Code/TestCycletimeMeiko/ModelYolov12n_ONNX/divatma.onnx\n",
      "ƒêang x·ª≠ l√Ω: bamdinh.pt\n",
      "ƒêang chuy·ªÉn ƒë·ªïi: /root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.pt\n",
      "Ultralytics 8.3.150 üöÄ Python-3.10.18 torch-2.2.1 CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 3.9s, saved as '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (4.1s)\n",
      "Results saved to \u001b[1m/root/Code/TestCycletimeMeiko/ModelYolov12n_PT\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/bamdinh.onnx imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Bamdinhkhongtot_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ƒê√£ l∆∞u m√¥ h√¨nh ONNX v√†o: /root/Code/TestCycletimeMeiko/ModelYolov12n_ONNX/bamdinh.onnx\n",
      "ƒêang x·ª≠ l√Ω: thieudong.pt\n",
      "ƒêang chuy·ªÉn ƒë·ªïi: /root/Code/TestCycletimeMeiko/ModelYolov12n_PT/thieudong.pt\n",
      "Ultralytics 8.3.150 üöÄ Python-3.10.18 torch-2.2.1 CPU (Intel Core(TM) i7-14700K)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/thieudong.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 4.0s, saved as '/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/thieudong.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (4.1s)\n",
      "Results saved to \u001b[1m/root/Code/TestCycletimeMeiko/ModelYolov12n_PT\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/thieudong.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/root/Code/TestCycletimeMeiko/ModelYolov12n_PT/thieudong.onnx imgsz=640 data=D:\\aoi_inspection\\data\\Datasets\\VRS_Thieudong_Annotation.v1i.yolov12\\data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ƒê√£ l∆∞u m√¥ h√¨nh ONNX v√†o: /root/Code/TestCycletimeMeiko/ModelYolov12n_ONNX/thieudong.onnx\n",
      "Chuy·ªÉn ƒë·ªïi ho√†n t·∫•t. ƒê√£ chuy·ªÉn ƒë·ªïi 6/6 file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def convert_to_onnx(input_path, output_path=None, imgsz=640, opset=12):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi m√¥ h√¨nh YOLOv12 t·ª´ ƒë·ªãnh d·∫°ng .pt sang ONNX\n",
    "    \n",
    "    Args:\n",
    "        input_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file .pt\n",
    "        output_path: ƒê∆∞·ªùng d·∫´n l∆∞u file .onnx (t√πy ch·ªçn)\n",
    "        imgsz: K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o\n",
    "        opset: Phi√™n b·∫£n ONNX opset\n",
    "    \n",
    "    Returns:\n",
    "        Path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ONNX ƒë√£ ƒë∆∞·ª£c t·∫°o\n",
    "    \"\"\"\n",
    "    print(f\"ƒêang chuy·ªÉn ƒë·ªïi: {input_path}\")\n",
    "    \n",
    "    # T·∫°o th∆∞ m·ª•c ch·ª©a output_path n·∫øu ƒë∆∞·ª£c cung c·∫•p\n",
    "    if output_path:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # T·∫£i m√¥ h√¨nh\n",
    "        model = YOLO(input_path)\n",
    "        \n",
    "        # Xu·∫•t sang ONNX\n",
    "        onnx_path = model.export(\n",
    "            format=\"onnx\",\n",
    "            imgsz=imgsz,\n",
    "            opset=opset,\n",
    "            simplify=True,\n",
    "            dynamic=True\n",
    "        )\n",
    "        \n",
    "        # Di chuy·ªÉn file n·∫øu output_path ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh\n",
    "        if output_path and os.path.exists(onnx_path):\n",
    "            os.replace(str(onnx_path), output_path)\n",
    "            onnx_path = output_path\n",
    "            \n",
    "        print(f\"ƒê√£ l∆∞u m√¥ h√¨nh ONNX v√†o: {onnx_path}\")\n",
    "        return onnx_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói khi chuy·ªÉn ƒë·ªïi m√¥ h√¨nh sang ONNX: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_folder_to_onnx(input_folder, output_folder, imgsz=640, opset=12):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ m√¥ h√¨nh YOLOv12 t·ª´ ƒë·ªãnh d·∫°ng .pt sang ONNX trong m·ªôt th∆∞ m·ª•c\n",
    "    \n",
    "    Args:\n",
    "        input_folder: ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a c√°c file .pt\n",
    "        output_folder: ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ƒë·ªÉ l∆∞u c√°c file .onnx\n",
    "        imgsz: K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o\n",
    "        opset: Phi√™n b·∫£n ONNX opset\n",
    "    \n",
    "    Returns:\n",
    "        list: Danh s√°ch c√°c ƒë∆∞·ªùng d·∫´n ƒë·∫øn file ONNX ƒë√£ ƒë∆∞·ª£c t·∫°o\n",
    "    \"\"\"\n",
    "    # T·∫°o th∆∞ m·ª•c ƒë·∫ßu ra n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # T√¨m t·∫•t c·∫£ file .pt trong th∆∞ m·ª•c ƒë·∫ßu v√†o\n",
    "    pt_files = [f for f in os.listdir(input_folder) if f.endswith('.pt')]\n",
    "    \n",
    "    print(f\"T√¨m th·∫•y {len(pt_files)} file .pt trong th∆∞ m·ª•c {input_folder}\")\n",
    "    \n",
    "    converted_files = []\n",
    "    for pt_file in pt_files:\n",
    "        input_path = os.path.join(input_folder, pt_file)\n",
    "        output_name = os.path.splitext(pt_file)[0] + '.onnx'\n",
    "        output_path = os.path.join(output_folder, output_name)\n",
    "        \n",
    "        print(f\"ƒêang x·ª≠ l√Ω: {pt_file}\")\n",
    "        \n",
    "        # Th·ª±c hi·ªán chuy·ªÉn ƒë·ªïi\n",
    "        result = convert_to_onnx(input_path, output_path, imgsz, opset)\n",
    "        if result:\n",
    "            converted_files.append(result)\n",
    "    \n",
    "    print(f\"Chuy·ªÉn ƒë·ªïi ho√†n t·∫•t. ƒê√£ chuy·ªÉn ƒë·ªïi {len(converted_files)}/{len(pt_files)} file\")\n",
    "    return converted_files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a c√°c file .pt ƒë·∫ßu v√†o\n",
    "    input_folder = \"/root/Code/TestCycletimeMeiko/ModelYolov12n_PT\"\n",
    "    \n",
    "    # ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ƒë·ªÉ l∆∞u c√°c file ONNX ƒë·∫ßu ra\n",
    "    output_folder = \"/root/Code/TestCycletimeMeiko/ModelYolov12n_ONNX\"\n",
    "    \n",
    "    # Th·ª±c hi·ªán chuy·ªÉn ƒë·ªïi c·∫£ th∆∞ m·ª•c\n",
    "    convert_folder_to_onnx(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_yolo12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
